From steve.dower at python.org  Thu Nov  1 11:38:24 2018
From: steve.dower at python.org (Steve Dower)
Date: Thu, 1 Nov 2018 08:38:24 -0700
Subject: [Python-Dev] Rename Include/internals/ to Include/pycore/
In-Reply-To: <CALFfu7BrLThnaMXQEd+wSsmzka8o+OkcGhwzktamLzNpF=OkZg@mail.gmail.com>
References: <CA+3bQGE7UriagGc_FYuM7ge5oGX+6+_w2c3HY1WDj8JY=6FuzQ@mail.gmail.com>
 <CALFfu7DFq=9QEaTT=sy-XK=B+X1f+qjo7YnMD37HVGRGKu54mg@mail.gmail.com>
 <CA+3bQGFpcUiu_oyZWrU9POKSVhKYh98F-caoFk1xnhQgR6frMA@mail.gmail.com>
 <CA+3bQGEgMc1T+UTavAcONFxTsq=ERsCjmZYP7W_3W_yJTAhosQ@mail.gmail.com>
 <CALFfu7DqTYquUpv1Rk2Q8+Mi+OKoQsuKxWKOaC5Mk+Ffj+i2HQ@mail.gmail.com>
 <CA+3bQGEE8Ji+CWNx-LL2ambgyqa2MQz781f+WX=yWbqLkWA=nA@mail.gmail.com>
 <CALFfu7Atg1TZzGjAdaRVzXAdhG5MZ4o81AbKwK5G-N84qn8N5g@mail.gmail.com>
 <CA+3bQGHoe9hoqXX146Uc=7WABLG+8vZ=33Lc63ONiM9jQ54OCw@mail.gmail.com>
 <CALFfu7BrLThnaMXQEd+wSsmzka8o+OkcGhwzktamLzNpF=OkZg@mail.gmail.com>
Message-ID: <67172f5d-ca9e-c924-5970-b28d6876ce33@python.org>

I assume the redundancy was there to handle the naming collision 
problem, but a better way to do that is to have only header files that 
users should ever use in "include/", and put the rest inside 
"include/python/" and "include/internal/" (and if possible, we don't 
distribute the internal directory as part of -develop packages, which 
only really impacts the Windows installer as far as we're concerned, but 
I assume some distros will care).

That would mean a layout like:

include/
   Python.h
   typeslots.h
   Python/
     abstract.h
     ...
   internal/
     pycore_atomic.h
     ...

End users/distutils should only -Iinclude, while our build can 
-Iinclude/Python and -Iinclude/internal as well. Or we can update all of 
our includes to specify the directory (which I'd prefer - #include 
"name.h" should look adjacent to the file first, while #include <name.h> 
looks at search paths first, which should be able to deal with collisions).

Any change here is an improvement, though. I'll be happy for 
Py_BUILD_CORE to go away (or at least only imply -Iinclude/internal, 
rather than actual preprocessor work), no matter where files land 
precisely :)

Cheers,
Steve

On 31Oct2018 1835, Eric Snow wrote:
> On the one hand dropping redundancy in the filename is fine.? On the 
> other having the names mirror the public header files is valuable.? How 
> about leaving the base names alone and change the directory to "pyinternal"?
> 
> -eric
> 
> On Wed, Oct 31, 2018, 17:36 Victor Stinner <vstinner at redhat.com 
> <mailto:vstinner at redhat.com> wrote:
> 
>     Ok, thanks. I decided to remove the redundant "py", so I renamed
>     "pystate.h" to "pycore_state.h" (single "py", instead of
>     "pycore_pystate.h", double "py py").
> 
>     I updated my PR:
>     https://github.com/python/cpython/pull/10263
> 
>     * Rename Include/internal/ header files:
> 
>      ? * pyatomic.h -> pycore_atomic.h
>      ? * ceval.h -> pycore_ceval.h
>      ? * condvar.h -> pycore_condvar.h
>      ? * context.h -> pycore_context.h
>      ? * pygetopt.h -> pycore_getopt.h
>      ? * gil.h -> pycore_gil.h
>      ? * hamt.h -> pycore_hamt.h
>      ? * hash.h -> pycore_hash.h
>      ? * mem.h -> pycore_mem.h
>      ? * pystate.h -> pycore_state.h
>      ? * warnings.h -> pycore_warnings.h
> 
>     * PCbuild project, Makefile.pre.in <http://Makefile.pre.in>,
>     Modules/Setup: add the
>      ? Include/internal/ directory to the search paths of header files.
>     * Update include. For example, replace #include "internal/mem.h"
>      ? with #include "pycore_mem.h".
> 
>     Victor
>     Le mer. 31 oct. 2018 ? 23:38, Eric Snow <ericsnowcurrently at gmail.com
>     <mailto:ericsnowcurrently at gmail.com>> a ?crit :
>      >
>      > B
>      > On Wed, Oct 31, 2018 at 4:28 PM Victor Stinner
>     <vstinner at redhat.com <mailto:vstinner at redhat.com>> wrote:
>      > >
>      > > Le mer. 31 oct. 2018 ? 22:19, Eric Snow
>     <ericsnowcurrently at gmail.com <mailto:ericsnowcurrently at gmail.com>> a
>     ?crit :
>      > > > > Maybe we can keep "Include/internal/" directory name, but add
>      > > > > "pycore_" rather than "internal_" to header filenames?
>      > > >
>      > > > this sounds good to me.? thanks for chasing this down.
>      > >
>      > > What do you prefer?
>      > >
>      > > (A Include/internal/internal_pystate.h
>      > > (B) Include/internal/pycore_pystate.h
>      > > (C) Include/pycore/pycore_pystate.h
>      > >
>      > > Victor
> 


From vstinner at redhat.com  Thu Nov  1 14:19:51 2018
From: vstinner at redhat.com (Victor Stinner)
Date: Thu, 1 Nov 2018 19:19:51 +0100
Subject: [Python-Dev] Rename Include/internals/ to Include/pycore/
In-Reply-To: <67172f5d-ca9e-c924-5970-b28d6876ce33@python.org>
References: <CA+3bQGE7UriagGc_FYuM7ge5oGX+6+_w2c3HY1WDj8JY=6FuzQ@mail.gmail.com>
 <CALFfu7DFq=9QEaTT=sy-XK=B+X1f+qjo7YnMD37HVGRGKu54mg@mail.gmail.com>
 <CA+3bQGFpcUiu_oyZWrU9POKSVhKYh98F-caoFk1xnhQgR6frMA@mail.gmail.com>
 <CA+3bQGEgMc1T+UTavAcONFxTsq=ERsCjmZYP7W_3W_yJTAhosQ@mail.gmail.com>
 <CALFfu7DqTYquUpv1Rk2Q8+Mi+OKoQsuKxWKOaC5Mk+Ffj+i2HQ@mail.gmail.com>
 <CA+3bQGEE8Ji+CWNx-LL2ambgyqa2MQz781f+WX=yWbqLkWA=nA@mail.gmail.com>
 <CALFfu7Atg1TZzGjAdaRVzXAdhG5MZ4o81AbKwK5G-N84qn8N5g@mail.gmail.com>
 <CA+3bQGHoe9hoqXX146Uc=7WABLG+8vZ=33Lc63ONiM9jQ54OCw@mail.gmail.com>
 <CALFfu7BrLThnaMXQEd+wSsmzka8o+OkcGhwzktamLzNpF=OkZg@mail.gmail.com>
 <67172f5d-ca9e-c924-5970-b28d6876ce33@python.org>
Message-ID: <CA+3bQGF0V93i+YA_tgfAfiPVXiSMqf-W16Q9rVU5M=q-KGbwnw@mail.gmail.com>

Le jeu. 1 nov. 2018 ? 16:38, Steve Dower <steve.dower at python.org> a ?crit :
> I assume the redundancy was there to handle the naming collision
> problem, but a better way to do that is to have only header files that
> users should ever use in "include/", and put the rest inside
> "include/python/" and "include/internal/" (and if possible, we don't
> distribute the internal directory as part of -develop packages, which
> only really impacts the Windows installer as far as we're concerned, but
> I assume some distros will care).

Aha, I didn't try this approach. I counted 41 Include/ header files
which are not included by Python.h:

Python-ast.h
abstract.h
asdl.h
ast.h
bitset.h
bytes_methods.h
bytesobject.h
code.h
codecs.h
datetime.h
dictobject.h
dynamic_annotations.h
errcode.h
fileobject.h
frameobject.h
graminit.h
grammar.h
longintrepr.h
marshal.h
metagrammar.h
node.h
opcode.h
osdefs.h
parsetok.h
patchlevel.h
pgen.h
pgenheaders.h
py_curses.h
pydtrace.h
pyexpat.h
pystrhex.h
pythonrun.h
pythread.h
pytime.h
setobject.h
structmember.h
symtable.h
token.h
ucnhash.h
unicodeobject.h

For Py_BUILD_CORE, there is at least datetime.h which may be a
Include/internal/ twin header.

Now I'm not sure how it's going to fit with the second step, "Move
!Py_LIMITED_API to Include/pycapi/":
https://bugs.python.org/issue35134

Victor

From status at bugs.python.org  Fri Nov  2 13:09:58 2018
From: status at bugs.python.org (Python tracker)
Date: Fri,  2 Nov 2018 18:09:58 +0100 (CET)
Subject: [Python-Dev] Summary of Python tracker Issues
Message-ID: <20181102170958.3043456D39@psf.upfronthosting.co.za>


ACTIVITY SUMMARY (2018-10-26 - 2018-11-02)
Python tracker at https://bugs.python.org/

To view or respond to any of the issues listed below, click on the issue.
Do NOT respond to this message.

Issues counts and deltas:
  open    6828 ( +5)
  closed 40071 (+66)
  total  46899 (+71)

Open issues with patches: 2720 


Issues opened (41)
==================

#35034: Add closing and iteration to threading.Queue
https://bugs.python.org/issue35034  reopened by hemflit

#35078: Allow customization of CSS class name of a month in calendar m
https://bugs.python.org/issue35078  opened by thatiparthy

#35081: Move internal headers to Include/internal/
https://bugs.python.org/issue35081  opened by vstinner

#35082: Mock.__dir__ lists deleted attributes
https://bugs.python.org/issue35082  opened by mariocj89

#35083: Fix documentation for __instancecheck__
https://bugs.python.org/issue35083  opened by joydiamond

#35084: binascii.Error: Incorrect padding
https://bugs.python.org/issue35084  opened by Tester

#35091: Objects/listobject.c: gallop functions rely on signed integer 
https://bugs.python.org/issue35091  opened by izbyshev

#35097: IDLE add doc subsection for editor windows
https://bugs.python.org/issue35097  opened by terry.reedy

#35099: Improve the IDLE - console differences doc
https://bugs.python.org/issue35099  opened by terry.reedy

#35100: urllib.parse.unquote_to_bytes: needs "escape plus" option
https://bugs.python.org/issue35100  opened by Henry Zhu

#35101: inspect.findsource breaks on class frame objects
https://bugs.python.org/issue35101  opened by orlnub123

#35103: format_exception() doesn't work with PyErr_Fetch
https://bugs.python.org/issue35103  opened by tomasheran

#35104: IDLE: On macOS, Command-M minimizes & opens "Open Module..."
https://bugs.python.org/issue35104  opened by taleinat

#35105: Document that CPython accepts "invalid" identifiers
https://bugs.python.org/issue35105  opened by vstinner

#35107: untokenize() fails on tokenize output when a newline is missin
https://bugs.python.org/issue35107  opened by gregory.p.smith

#35108: inspect.getmembers passes exceptions from object's properties 
https://bugs.python.org/issue35108  opened by rominf

#35109: Doctest in CI uses python binary built from master causing Dep
https://bugs.python.org/issue35109  opened by xtreak

#35111: Make Custom Object Classes JSON Serializable
https://bugs.python.org/issue35111  opened by andrewchap

#35113: inspect.getsource returns incorrect source for classes when cl
https://bugs.python.org/issue35113  opened by xtreak

#35114: ssl.RAND_status docs describe it as returning True/False; actu
https://bugs.python.org/issue35114  opened by josh.r

#35118: Add peek() or first() method in queue
https://bugs.python.org/issue35118  opened by Windson Yang

#35120: SSH tunnel support to ftp lib
https://bugs.python.org/issue35120  opened by msharma

#35121: Cookie domain check returns incorrect results
https://bugs.python.org/issue35121  opened by ????????????

#35122: Process not exiting on unhandled exception when using multipro
https://bugs.python.org/issue35122  opened by akhi singhania

#35123: Add style guide for sentinel usage
https://bugs.python.org/issue35123  opened by madman bob

#35124: Add style guide for unit tests
https://bugs.python.org/issue35124  opened by madman bob

#35125: asyncio shield: remove inner callback on outer cancellation
https://bugs.python.org/issue35125  opened by mainro

#35126: Mistake in FAQ about converting number to string.
https://bugs.python.org/issue35126  opened by grottrumsel

#35127: pyurandom() fails if user does not have an entropy device
https://bugs.python.org/issue35127  opened by pehdrah

#35131: Cannot access to customized paths within .pth file
https://bugs.python.org/issue35131  opened by Valentin Zhao

#35132: python-gdb error: Python Exception <class 'RuntimeError'> Type
https://bugs.python.org/issue35132  opened by Dylan Cali

#35133: Bugs in concatenating string literals on different lines
https://bugs.python.org/issue35133  opened by serhiy.storchaka

#35134: Move !Py_LIMITED_API to Include/pycapi/
https://bugs.python.org/issue35134  opened by vstinner

#35136: test_ssl fails in AMD64 FreeBSD CURRENT Shared 3.6 buildbot
https://bugs.python.org/issue35136  opened by pablogsal

#35138: timeit documentation should have example with function argumen
https://bugs.python.org/issue35138  opened by davidak

#35140: encoding problem: coding:gbk cause syntaxError
https://bugs.python.org/issue35140  opened by anmikf

#35143: Annotations future requires unparse, but not accessible from P
https://bugs.python.org/issue35143  opened by kayhayen

#35144: TemporaryDirectory can't be cleaned up if there are unsearchab
https://bugs.python.org/issue35144  opened by lilydjwg

#35145: sqlite3: "select *" should autoconvert datetime fields
https://bugs.python.org/issue35145  opened by jondo

#35147: _Py_NO_RETURN is always empty on GCC
https://bugs.python.org/issue35147  opened by izbyshev

#35148: cannot activate a venv environment on a Swiss German windows
https://bugs.python.org/issue35148  opened by Martin Bijl-Schwab



Most recent 15 issues with no replies (15)
==========================================

#35148: cannot activate a venv environment on a Swiss German windows
https://bugs.python.org/issue35148

#35143: Annotations future requires unparse, but not accessible from P
https://bugs.python.org/issue35143

#35132: python-gdb error: Python Exception <class 'RuntimeError'> Type
https://bugs.python.org/issue35132

#35131: Cannot access to customized paths within .pth file
https://bugs.python.org/issue35131

#35127: pyurandom() fails if user does not have an entropy device
https://bugs.python.org/issue35127

#35125: asyncio shield: remove inner callback on outer cancellation
https://bugs.python.org/issue35125

#35114: ssl.RAND_status docs describe it as returning True/False; actu
https://bugs.python.org/issue35114

#35103: format_exception() doesn't work with PyErr_Fetch
https://bugs.python.org/issue35103

#35100: urllib.parse.unquote_to_bytes: needs "escape plus" option
https://bugs.python.org/issue35100

#35082: Mock.__dir__ lists deleted attributes
https://bugs.python.org/issue35082

#35063: Checking for abstractmethod implementation fails to consider M
https://bugs.python.org/issue35063

#35061: Specify libffi.so soname for ctypes
https://bugs.python.org/issue35061

#35048: Can't reassign __class__ despite the assigned class having ide
https://bugs.python.org/issue35048

#35018: Sax parser provides no user access to lexical handlers
https://bugs.python.org/issue35018

#35009: argparse throws UnicodeEncodeError for printing help with unic
https://bugs.python.org/issue35009



Most recent 15 issues waiting for review (15)
=============================================

#35147: _Py_NO_RETURN is always empty on GCC
https://bugs.python.org/issue35147

#35138: timeit documentation should have example with function argumen
https://bugs.python.org/issue35138

#35134: Move !Py_LIMITED_API to Include/pycapi/
https://bugs.python.org/issue35134

#35133: Bugs in concatenating string literals on different lines
https://bugs.python.org/issue35133

#35125: asyncio shield: remove inner callback on outer cancellation
https://bugs.python.org/issue35125

#35121: Cookie domain check returns incorrect results
https://bugs.python.org/issue35121

#35118: Add peek() or first() method in queue
https://bugs.python.org/issue35118

#35101: inspect.findsource breaks on class frame objects
https://bugs.python.org/issue35101

#35097: IDLE add doc subsection for editor windows
https://bugs.python.org/issue35097

#35091: Objects/listobject.c: gallop functions rely on signed integer 
https://bugs.python.org/issue35091

#35082: Mock.__dir__ lists deleted attributes
https://bugs.python.org/issue35082

#35081: Move internal headers to Include/internal/
https://bugs.python.org/issue35081

#35078: Allow customization of CSS class name of a month in calendar m
https://bugs.python.org/issue35078

#35077: Make TypeError message less ambiguous
https://bugs.python.org/issue35077

#35065: Reading received data from a closed TCP stream using `StreamRe
https://bugs.python.org/issue35065



Top 10 most discussed issues (10)
=================================

#35081: Move internal headers to Include/internal/
https://bugs.python.org/issue35081  19 msgs

#35070: test_posix fails on macOS 10.14 Mojave
https://bugs.python.org/issue35070  14 msgs

#34160: ElementTree not preserving attribute order
https://bugs.python.org/issue34160  13 msgs

#35059: Convert Py_INCREF() and PyObject_INIT() to inlined functions
https://bugs.python.org/issue35059  13 msgs

#35084: binascii.Error: Incorrect padding
https://bugs.python.org/issue35084  12 msgs

#1154351: add get_current_dir_name() to os module
https://bugs.python.org/issue1154351  10 msgs

#35140: encoding problem: coding:gbk cause syntaxError
https://bugs.python.org/issue35140   8 msgs

#35077: Make TypeError message less ambiguous
https://bugs.python.org/issue35077   7 msgs

#19376: document that strptime() does not support the Feb 29 if the fo
https://bugs.python.org/issue19376   6 msgs

#35052: Coverity scan: copy/paste error in Lib/xml/dom/minidom.py
https://bugs.python.org/issue35052   6 msgs



Issues closed (64)
==================

#9263: Try to print repr() when an C-level assert fails (in the garba
https://bugs.python.org/issue9263  closed by vstinner

#27200: make doctest in CPython has failures
https://bugs.python.org/issue27200  closed by mdk

#27741: datetime.datetime.strptime functionality description incorrect
https://bugs.python.org/issue27741  closed by vstinner

#28015: configure --with-lto builds fail when CC=clang on Linux, requi
https://bugs.python.org/issue28015  closed by vstinner

#29174: 'NoneType' object is not callable in subprocess.py
https://bugs.python.org/issue29174  closed by vstinner

#31544: gettext.Catalog title is not flagged as a class
https://bugs.python.org/issue31544  closed by serhiy.storchaka

#31680: Expose curses library name and version on Python level
https://bugs.python.org/issue31680  closed by serhiy.storchaka

#31880: subprocess process interaction with IDLEX GUI causes pygnuplot
https://bugs.python.org/issue31880  closed by roger.serwy

#32804: urllib.retrieve documentation doesn't mention context paramete
https://bugs.python.org/issue32804  closed by xiang.zhang

#33138: Improve standard error for uncopyable types
https://bugs.python.org/issue33138  closed by serhiy.storchaka

#33236: MagicMock().__iter__.return_value is different from MagicMock(
https://bugs.python.org/issue33236  closed by michael.foord

#33237: Improve AttributeError message for partially initialized modul
https://bugs.python.org/issue33237  closed by serhiy.storchaka

#33331: Clean modules in the reversed order
https://bugs.python.org/issue33331  closed by serhiy.storchaka

#33710: Deprecate gettext.lgettext()
https://bugs.python.org/issue33710  closed by serhiy.storchaka

#33826: enable discovery of class source code in IPython interactively
https://bugs.python.org/issue33826  closed by t-vi

#33940: datetime.strptime have no directive to convert date values wit
https://bugs.python.org/issue33940  closed by belopolsky

#34198: Additional encoding options to tkinter.filedialog
https://bugs.python.org/issue34198  closed by narito

#34576: [EASY doc] http.server, SimpleHTTPServer: warn users on securi
https://bugs.python.org/issue34576  closed by orsenthil

#34794: Memory leak in Tkinter
https://bugs.python.org/issue34794  closed by serhiy.storchaka

#34866: CGI DOS vulnerability via long post list
https://bugs.python.org/issue34866  closed by vstinner

#34876: Python3.8 changes how decorators are traced
https://bugs.python.org/issue34876  closed by serhiy.storchaka

#34945: regression with ./python -m test and pdb
https://bugs.python.org/issue34945  closed by pablogsal

#35007: Minor change to weakref docs
https://bugs.python.org/issue35007  closed by mdk

#35042: Use the role :pep: for the PEP \d+
https://bugs.python.org/issue35042  closed by mdk

#35047: Better error messages in unittest.mock
https://bugs.python.org/issue35047  closed by vstinner

#35054: Add more index entries for symbols
https://bugs.python.org/issue35054  closed by serhiy.storchaka

#35062: io.IncrementalNewlineDecoder assign out-of-range value to bitw
https://bugs.python.org/issue35062  closed by xiang.zhang

#35064: COUNT_ALLOCS build export inc_count() and dec_count() function
https://bugs.python.org/issue35064  closed by pablogsal

#35067: Use vswhere instead of _distutils_findvs
https://bugs.python.org/issue35067  closed by steve.dower

#35068: [2.7] Possible crashes due to incorrect error handling in pyex
https://bugs.python.org/issue35068  closed by serhiy.storchaka

#35074: source install [3.7.1] on debian jessie
https://bugs.python.org/issue35074  closed by xtreak

#35075: Doc: pprint example uses dead URL
https://bugs.python.org/issue35075  closed by inada.naoki

#35076: FAIL: test_min_max_version (test.test_ssl.ContextTests) with l
https://bugs.python.org/issue35076  closed by terry.reedy

#35079: difflib.SequenceMatcher.get_matching_blocks omits common strin
https://bugs.python.org/issue35079  closed by terry.reedy

#35080: The tests for the `dis` module can be too rigid when changing 
https://bugs.python.org/issue35080  closed by Maxime Belanger

#35085: FileNotFoundError: [Errno 2] No such file or directory:
https://bugs.python.org/issue35085  closed by steven.daprano

#35086: tkinter docs: errors in A Simple Hello World Program
https://bugs.python.org/issue35086  closed by serhiy.storchaka

#35087: IDLE: update idlelib help files for current doc build
https://bugs.python.org/issue35087  closed by terry.reedy

#35088: Update idlelib.help.copy_string docstring
https://bugs.python.org/issue35088  closed by terry.reedy

#35089: Remove typing.io and typing.re from documentation
https://bugs.python.org/issue35089  closed by levkivskyi

#35090: Potential division by zero and integer overflow in allocator w
https://bugs.python.org/issue35090  closed by vstinner

#35092: test_socket fails in MacOS High Sierra when running with -Werr
https://bugs.python.org/issue35092  closed by ned.deily

#35093: IDLE: document the help document viewer
https://bugs.python.org/issue35093  closed by terry.reedy

#35094: Improved algorithms for random.sample
https://bugs.python.org/issue35094  closed by rhettinger

#35095: Implement pathlib.Path.append_bytes and pathlib.Path.append_te
https://bugs.python.org/issue35095  closed by pablogsal

#35096: Change _PY_VERSION to derive from sys.version_info in sysconfi
https://bugs.python.org/issue35096  closed by ned.deily

#35098: Deleting __new__ does not restore previous behavior
https://bugs.python.org/issue35098  closed by josh.r

#35102: Struct pack()
https://bugs.python.org/issue35102  closed by mark.dickinson

#35106: Add documentation for `type.__subclasses__` to docs.python.org
https://bugs.python.org/issue35106  closed by joydiamond

#35110: Fix more spaces around hyphens and dashes
https://bugs.python.org/issue35110  closed by serhiy.storchaka

#35112: SpooledTemporaryFile and seekable() method
https://bugs.python.org/issue35112  closed by nubirstein

#35115: UUID objects can't be casted by `hex()`
https://bugs.python.org/issue35115  closed by fcurella

#35116: Doc/library entries for cgi.FieldStorage max_num_fields
https://bugs.python.org/issue35116  closed by vstinner

#35117: set.discard should return True or False based on if element ex
https://bugs.python.org/issue35117  closed by rhettinger

#35119: Customizing module attribute access example raises RecursionEr
https://bugs.python.org/issue35119  closed by levkivskyi

#35128: warning.warn messages with spacing issues
https://bugs.python.org/issue35128  closed by scorphus

#35129: Different behaviour comparing versions (distutils.version.Loos
https://bugs.python.org/issue35129  closed by eric.araujo

#35130: add same file name to zipfile ,result two files and same md5
https://bugs.python.org/issue35130  closed by serhiy.storchaka

#35135: pip install --download option does not exist
https://bugs.python.org/issue35135  closed by zach.ware

#35137: Exception in isinstance when __class__ property raises
https://bugs.python.org/issue35137  closed by brett.cannon

#35139: Statically linking pyexpat in Modules/Setup fails to compile o
https://bugs.python.org/issue35139  closed by benjamin.peterson

#35141: encoding problem: gbk
https://bugs.python.org/issue35141  closed by xtreak

#35142: html.entities.html5 should require a trailing semicolon
https://bugs.python.org/issue35142  closed by serhiy.storchaka

#35146: Bad Regular Expression Broke re.findall()
https://bugs.python.org/issue35146  closed by steven.daprano

From nas-python at arctrix.com  Fri Nov  2 13:22:38 2018
From: nas-python at arctrix.com (Neil Schemenauer)
Date: Fri, 2 Nov 2018 11:22:38 -0600
Subject: [Python-Dev] Rename Include/internals/ to Include/pycore/
In-Reply-To: <1540759207.1168671.1557524968.5CFA99F3@webmail.messagingengine.com>
References: <CA+3bQGE7UriagGc_FYuM7ge5oGX+6+_w2c3HY1WDj8JY=6FuzQ@mail.gmail.com>
 <1540759207.1168671.1557524968.5CFA99F3@webmail.messagingengine.com>
Message-ID: <20181102172238.u7ysgkpj2b7aids5@python.ca>

On 2018-10-28, Benjamin Peterson wrote:
> I don't think more or less API should be magically included based
> on whether Py_BUILD_CORE is defined or not.

I agree.

> If we want to have private headers, we should include them where
> needed and not install them. Really, Py_BUILD_CORE should go away.
> We should be moving away from monolithic includes like Python.h to
> having each C file include exactly what it uses, private or not.

It seems that is best practice (e.g. look at Linux kernel include
file style).  I wonder however what are the real benefits to having
modular include files and directly using them as needed?

Pros for modular includes:

- speeds up build process if you have good dependency info in the
  build system.  Right now, change Python.h and everything gets
  rebuilt.  I'm not sure this is a huge advantage anymore.

- makes it clearer where an API is implemented?

Cons:

- more work to include the correct headers

- build system dependency definitions are more complicated.  Other
  systems generally have automatic dependancy generates (i.e. parse
  C files and find used includes).

A simple approach would be to introduce something like
Python-internal.h.  If you are a Python internal unit, you can
include both Python.h and Python-internal.h.  We could, over time,
split Python-iternal.h into smaller modular includes.

From vstinner at redhat.com  Fri Nov  2 15:01:30 2018
From: vstinner at redhat.com (Victor Stinner)
Date: Fri, 2 Nov 2018 20:01:30 +0100
Subject: [Python-Dev] Rename Include/internals/ to Include/pycore/
In-Reply-To: <20181102172238.u7ysgkpj2b7aids5@python.ca>
References: <CA+3bQGE7UriagGc_FYuM7ge5oGX+6+_w2c3HY1WDj8JY=6FuzQ@mail.gmail.com>
 <1540759207.1168671.1557524968.5CFA99F3@webmail.messagingengine.com>
 <20181102172238.u7ysgkpj2b7aids5@python.ca>
Message-ID: <CA+3bQGHoS+uToYCa=fLtPzDLdBmDu+f8EU0EFOhwCfu92rh3tA@mail.gmail.com>

Le ven. 2 nov. 2018 ? 18:32, Neil Schemenauer <nas-python at arctrix.com> a ?crit :
> A simple approach would be to introduce something like
> Python-internal.h.  If you are a Python internal unit, you can
> include both Python.h and Python-internal.h.  We could, over time,
> split Python-iternal.h into smaller modular includes.

Since this discussion, I already moved most Py_BUILD_CORE in
Include/internal/. I added a lot of #include "pycore_xxx.h" in C
files.

I started to reach the limit with this PR which adds the
pycore_object.h include to not less than 33 C files:
https://github.com/python/cpython/pull/10272

I rewrote this PR to avoid the need to modify 33 C files:
https://github.com/python/cpython/pull/10276/files

I added the following code to Python.h:

#ifdef Py_BUILD_CORE
/* bpo-35081: Automatically include pycore_object.h in Python.h, to avoid
to have to add an explicit #include "pycore_object.h" to each C file. */
# include "pycore_object.h"
#endif

I'm not sure of it's a temporary workaround or not :-) Maybe a
Python-internal.h would be a better solution? We can identify the most
common header files needed to access "Python internals" and put them
in this "common" header file.

For example, most C files using Python internals have to access
_PyRuntime global variable (55 C files), so "pycore_state.h" is a good
candidate.

By the way, I don't understand the rationale to have _PyRuntime in
pycore_state.h. IMHO pycore_state.h should only contain functions to
get the Python thread and Python interpreter states. IMHO _PyRuntime
is unrelated and should belong to a different header file, maybe
pycore_runtime.h? I didn't do this change yet *because* I would have
to modify the 55 files currently including it.

Victor

From brett at python.org  Fri Nov  2 18:24:20 2018
From: brett at python.org (Brett Cannon)
Date: Fri, 2 Nov 2018 15:24:20 -0700
Subject: [Python-Dev] PEP 543-conform TLS library
In-Reply-To: <3A7C8D1D-FA3F-46AF-8EC8-540D407EC825@gmail.com>
References: <3A7C8D1D-FA3F-46AF-8EC8-540D407EC825@gmail.com>
Message-ID: <CAP1=2W5FOVtnAk5_pj0_=xA9Gt9=qOCx-KixSD80Ree=rRu5UA@mail.gmail.com>

In case you never received a reply, you can try emailing Christian and Cory
directly for an answer.

On Fri, 26 Oct 2018 at 13:20, Mathias Laurin <mathias.laurin at gmail.com>
wrote:

> Hello Python Dev,
>
>
> I posted the following to python-ideas but here may be
> a more suitable place.  I apologize if cross posting
> bothers anyone.
>
>
> I have implemented an (I believe) PEP 543-conform TLS library
> and released TLS support in the latest version yesterday:
>
> https://github.com/Synss/python-mbedtls/tree/0.13.0
> https://pypi.org/project/python-mbedtls/0.13.0/
>
>
> As far as I know, I am the first one to follow PEP 543.  So one
> point is that the API works.  However, I have a couple of
> questions regarding the PEP:
>
> - I do not know what to do in `TLSWrappedBuffer.do_handshake()`.
>  The full TLS handshake requires writing to the server, reading
>  back, etc., (ClientHello, ServerHello, KeyExchange, etc.),
>  which cannot be accomplished in a single buffer.
>
>  For now, I am doing the handshake in
>  `TLSWrappedSocket.do_handshake()`: I set the BIO to using the
>  socket directly, then perform the handshake on the socket thus
>  entirely bypassing the TLSWrappedBuffer.  Once this is done, I
>  swap the BIO to using the buffer and go on encrypting and
>  decrypting from the buffer.  That is, the encrypted
>  communication is buffered.
>
> - The PEP sometimes mentions an "input buffer" and an "output
>  buffer", and some other times just "the buffer".  I believe
>  that both implementations are possible.  That is, with two
>  different buffers for input and output, or a single one.
>
>  I have implemented it with a single circular buffer (that is a
>  stream after all).  What the PEP is expecting is nonetheless
>  not clear to me.
>
>
> So, can anybody clarify these two points from the PEP?
>
>
> Or should I just address Cory Benfield (who does not seem very
> active anymore lately) and Christian Heimes directly?
>
>
> Cheers,
> Mathias
> _______________________________________________
> Python-Dev mailing list
> Python-Dev at python.org
> https://mail.python.org/mailman/listinfo/python-dev
> Unsubscribe:
> https://mail.python.org/mailman/options/python-dev/brett%40python.org
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://mail.python.org/pipermail/python-dev/attachments/20181102/315b7850/attachment.html>

From barry at barrys-emacs.org  Sat Nov  3 05:08:38 2018
From: barry at barrys-emacs.org (Barry Scott)
Date: Sat, 3 Nov 2018 09:08:38 +0000
Subject: [Python-Dev] windows compiler list missing 3.7 details on wiki
Message-ID: <16BCAA90-23DF-4B6A-8A78-DEB397109133@barrys-emacs.org>

On https://wiki.python.org/moin/WindowsCompilers details for 3.7 are missing.
I'm assuming its still VC V14

Barry


From steve.dower at python.org  Sat Nov  3 13:57:15 2018
From: steve.dower at python.org (Steve Dower)
Date: Sat, 3 Nov 2018 10:57:15 -0700
Subject: [Python-Dev] windows compiler list missing 3.7 details on wiki
In-Reply-To: <16BCAA90-23DF-4B6A-8A78-DEB397109133@barrys-emacs.org>
References: <16BCAA90-23DF-4B6A-8A78-DEB397109133@barrys-emacs.org>
Message-ID: <bfcde3d4-b290-6d3d-f315-7cd3076882ea@python.org>

Yes. Visual Studio 2015 or later can be used (and as this is the only 
way to get the compiler right now, I think it's fine to list that as the 
requirement - note that the "Visual Studio Build Tools" installer 
doesn't include the IDE itself).

Feel free to update the wiki.

Cheers,
Steve

On 03Nov2018 0208, Barry Scott wrote:
> On https://wiki.python.org/moin/WindowsCompilers details for 3.7 are missing.
> I'm assuming its still VC V14
> 
> Barry


From debatem1 at gmail.com  Sat Nov  3 20:59:18 2018
From: debatem1 at gmail.com (geremy condra)
Date: Sat, 3 Nov 2018 17:59:18 -0700
Subject: [Python-Dev] PEP 543-conform TLS library
In-Reply-To: <CAP1=2W5FOVtnAk5_pj0_=xA9Gt9=qOCx-KixSD80Ree=rRu5UA@mail.gmail.com>
References: <3A7C8D1D-FA3F-46AF-8EC8-540D407EC825@gmail.com>
 <CAP1=2W5FOVtnAk5_pj0_=xA9Gt9=qOCx-KixSD80Ree=rRu5UA@mail.gmail.com>
Message-ID: <CAJ=m_n67LUz1C6HYV6YonN5oRsF51xgOstU5AxD=qpzgmqyJFg@mail.gmail.com>

Not to derail this thread, but it may be worth looking into something like
Android's network security config (
https://developer.android.com/training/articles/security-config) in
relation to PEP 543.

One of the key takeaways from their analysis of a large number of
applications which touched TLS libraries was that their developers often
wanted to do simple and sane things but wound up doing complicated and
insane ones. To combat that, they created a fairly lightweight declarative
syntax for allowing narrow deviations from best practice. This syntax does
not have the full flexibility of their API, but is enough to satisfy the
needs of lots of developers and prevent lots of mistakes along the way.

In particular, I'd love to see some examples of how to achieve the same
effects as the canonical network security config examples using a PEP 543
interface. If they're useful enough it may even be beneficial to wrap those
up in a separate library, but at the very least it will help prove out that
PEP 543 can do the most important things that developers will want it to
do. If that already exists and I'm just ignorant of it, sorry for the noise.

Geremy Condra

On Fri, Nov 2, 2018 at 3:25 PM Brett Cannon <brett at python.org> wrote:

> In case you never received a reply, you can try emailing Christian and
> Cory directly for an answer.
>
> On Fri, 26 Oct 2018 at 13:20, Mathias Laurin <mathias.laurin at gmail.com>
> wrote:
>
>> Hello Python Dev,
>>
>>
>> I posted the following to python-ideas but here may be
>> a more suitable place.  I apologize if cross posting
>> bothers anyone.
>>
>>
>> I have implemented an (I believe) PEP 543-conform TLS library
>> and released TLS support in the latest version yesterday:
>>
>> https://github.com/Synss/python-mbedtls/tree/0.13.0
>> https://pypi.org/project/python-mbedtls/0.13.0/
>>
>>
>> As far as I know, I am the first one to follow PEP 543.  So one
>> point is that the API works.  However, I have a couple of
>> questions regarding the PEP:
>>
>> - I do not know what to do in `TLSWrappedBuffer.do_handshake()`.
>>  The full TLS handshake requires writing to the server, reading
>>  back, etc., (ClientHello, ServerHello, KeyExchange, etc.),
>>  which cannot be accomplished in a single buffer.
>>
>>  For now, I am doing the handshake in
>>  `TLSWrappedSocket.do_handshake()`: I set the BIO to using the
>>  socket directly, then perform the handshake on the socket thus
>>  entirely bypassing the TLSWrappedBuffer.  Once this is done, I
>>  swap the BIO to using the buffer and go on encrypting and
>>  decrypting from the buffer.  That is, the encrypted
>>  communication is buffered.
>>
>> - The PEP sometimes mentions an "input buffer" and an "output
>>  buffer", and some other times just "the buffer".  I believe
>>  that both implementations are possible.  That is, with two
>>  different buffers for input and output, or a single one.
>>
>>  I have implemented it with a single circular buffer (that is a
>>  stream after all).  What the PEP is expecting is nonetheless
>>  not clear to me.
>>
>>
>> So, can anybody clarify these two points from the PEP?
>>
>>
>> Or should I just address Cory Benfield (who does not seem very
>> active anymore lately) and Christian Heimes directly?
>>
>>
>> Cheers,
>> Mathias
>> _______________________________________________
>> Python-Dev mailing list
>> Python-Dev at python.org
>> https://mail.python.org/mailman/listinfo/python-dev
>> Unsubscribe:
>> https://mail.python.org/mailman/options/python-dev/brett%40python.org
>>
> _______________________________________________
> Python-Dev mailing list
> Python-Dev at python.org
> https://mail.python.org/mailman/listinfo/python-dev
> Unsubscribe:
> https://mail.python.org/mailman/options/python-dev/debatem1%40gmail.com
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://mail.python.org/pipermail/python-dev/attachments/20181103/2733b0c3/attachment.html>

From stephane at wirtel.be  Sun Nov  4 05:43:50 2018
From: stephane at wirtel.be (Stephane Wirtel)
Date: Sun, 4 Nov 2018 11:43:50 +0100
Subject: [Python-Dev] Need discussion for a PR about memory and objects
Message-ID: <20181104104350.GA12859@xps>

In this PR [https://github.com/python/cpython/pull/3382] "Remove reference to
address from the docs, as it only causes confusion", opened by Chris
Angelico, there is a discussion about the right term to use for the
address of an object in memory.

If you are interested by the topic, you could comment it.

If there is no comments then I think we could close the PR.

Thank you

St?phane

-- 
St?phane Wirtel - https://wirtel.be - @matrixise

From steve at pearwood.info  Sun Nov  4 08:03:15 2018
From: steve at pearwood.info (Steven D'Aprano)
Date: Mon, 5 Nov 2018 00:03:15 +1100
Subject: [Python-Dev] Need discussion for a PR about memory and objects
In-Reply-To: <20181104104350.GA12859@xps>
References: <20181104104350.GA12859@xps>
Message-ID: <20181104130314.GU3817@ando.pearwood.info>

On Sun, Nov 04, 2018 at 11:43:50AM +0100, Stephane Wirtel wrote:
> In this PR [https://github.com/python/cpython/pull/3382] "Remove reference 
> to
> address from the docs, as it only causes confusion", opened by Chris
> Angelico, there is a discussion about the right term to use for the
> address of an object in memory.

Why do we need to refer to the address of objects in memory?

Python's execution model is not based on addresses. We can't get the 
address of an object or do anything with it (except via ctypes). At the 
Python layer, objects just exist, they don't logically exist at any 
addressable location.

In fact, they might not exist in a single location -- compound objects 
are split across many locations or can share chunks of memory between 
multiple objects. Objects in Jython and IronPython can move about, those 
in PyPy can disappear from existence and reappear. The concept that 
every object has exactly one fixed location simply isn't correct.

I understand that people wishing to understand the implementation 
details of CPython objects will need to think about C-level concepts 
like memory address, but at the Python level, "address" is not a very 
meaningful or useful concept.


-- 
Steve

From stephane at wirtel.be  Sun Nov  4 08:38:27 2018
From: stephane at wirtel.be (Stephane Wirtel)
Date: Sun, 4 Nov 2018 14:38:27 +0100
Subject: [Python-Dev] Get a running instance of the doc for a PR.
Message-ID: <20181104133827.GA25586@xps>

Hi all,

When we receive a PR about the documentation, I think that could be
interesting if we could have a running instance of the doc on a sub
domain of python.org.

For example, pr-10000-doc.python.org or whatever, but by this way the
reviewers could see the result online.

The workflow would be like that:

New PR -> build the doc (done by Travis) -> publish it to a server ->
once published, the PR is notified by "doc is available at URL".

Once merged -> we remove the doc and the link (hello bedevere).

I am interested by this feature and if you also interested, tell me.
I would like discuss with Julien Palard and Ernest W.  Durbin III for a
solution as soon as possible.

Have a nice day,

St?phane

-- 
St?phane Wirtel - https://wirtel.be - @matrixise

From nad at python.org  Sun Nov  4 09:15:22 2018
From: nad at python.org (Ned Deily)
Date: Sun, 4 Nov 2018 09:15:22 -0500
Subject: [Python-Dev] Get a running instance of the doc for a PR.
In-Reply-To: <20181104133827.GA25586@xps>
References: <20181104133827.GA25586@xps>
Message-ID: <203B5254-326E-43EC-A80D-4A8147791A9D@python.org>

On Nov 4, 2018, at 08:38, Stephane Wirtel <stephane at wirtel.be> wrote:
> When we receive a PR about the documentation, I think that could be
> interesting if we could have a running instance of the doc on a sub
> domain of python.org.
> 
> For example, pr-10000-doc.python.org or whatever, but by this way the
> reviewers could see the result online.

It's an interesting idea but I don't like essentially opening python.org as a publishing platform (OK, another publishing platform - yes, I know about wiki.python.org).  Considering how easy it is to build and view the docs yourself, I don't think the benefits of such a service are worth the added complexity and potential abuse.

cd Doc
make venv # first time
git pr checkout ...
make html
open build/html/index.html  # depending on platform and code change


--
  Ned Deily
  nad at python.org -- []


From julien at palard.fr  Sun Nov  4 10:00:35 2018
From: julien at palard.fr (Julien Palard)
Date: Sun, 04 Nov 2018 15:00:35 +0000
Subject: [Python-Dev] Get a running instance of the doc for a PR.
In-Reply-To: <203B5254-326E-43EC-A80D-4A8147791A9D@python.org>
References: <20181104133827.GA25586@xps>
 <203B5254-326E-43EC-A80D-4A8147791A9D@python.org>
Message-ID: <dCNWpHselG_mmIFYqAYmu_MD8TGQMlu4rmE68Fc3aPJvMldn-P4FnrRDP7J3AxG9H3QNPO4y1P_WE-OGAkn0iQgiqEuijK0Ezbzl40LzV68=@palard.fr>

Considering feedback from Ned, what about building this as an independent service? We don't really need to interface with python.org at all, we just need some hardware, a domain, some code to interface with github API and... to start it's probably enough? It would be a usefull POC.

--?
Julien Palard
https://mdk.fr


From stephane at wirtel.be  Sun Nov  4 10:12:39 2018
From: stephane at wirtel.be (Stephane Wirtel)
Date: Sun, 4 Nov 2018 16:12:39 +0100
Subject: [Python-Dev] Get a running instance of the doc for a PR.
In-Reply-To: <203B5254-326E-43EC-A80D-4A8147791A9D@python.org>
References: <20181104133827.GA25586@xps>
 <203B5254-326E-43EC-A80D-4A8147791A9D@python.org>
Message-ID: <20181104151239.GA14162@xps>

On 11/04, Ned Deily wrote:
>On Nov 4, 2018, at 08:38, Stephane Wirtel <stephane at wirtel.be> wrote:
>> When we receive a PR about the documentation, I think that could be
>> interesting if we could have a running instance of the doc on a sub
>> domain of python.org.
>>
>> For example, pr-10000-doc.python.org or whatever, but by this way the
>> reviewers could see the result online.
>
>It's an interesting idea but I don't like essentially opening
>python.org as a publishing platform (OK, another publishing platform -
>yes, I know about wiki.python.org).  Considering how easy it is to
>build and view the docs yourself, I don't think the benefits of such a
>service are worth the added complexity and potential abuse.
>
>cd Doc
>make venv # first time
>git pr checkout ...
>make html
>open build/html/index.html  # depending on platform and code change

I am going to give your 3 counter-examples but I think you will find an
other counter-example ;-)

1. Two weeks ago, I have opened a PR
[https://github.com/python/cpython/pull/10009] about a rewording of a
sentence in the doc. Paul Ganssle was a reviewer and in a sentence he
said that would be nice to have a live preview of the docs on PR.
See https://github.com/python/cpython/pull/10009#issuecomment-433082605
Maybe he was on his smartphone/tablet and not in front of his computer.

2. On this morning, I was reviewing a PR
https://github.com/python/cpython/pull/10102, but the message from the
reviewer was "LGTM. Thanks for the PR ;-)". I don't doubt about the
reviewer but I want to check the result of sphinx and not just the
text, sometimes, we can find an other issue, you never know.

3. On this after-noon, I have reviewed a PR, and I was in the same case,
download the PR, build python, compile the doc and run the local server.

My workflow is the following steps:

git wpr XYZ
cd ../cpython-XYZ
./configure --prefix=$PWD-build --with-pydebug --silent
make -j 4 -s
make PYTHON=../python -C Doc/ venv
make -C Doc/ check suspicious html serve

and run the browser on http://localhost:8000/ and check the result.


1. Because I am a dev I can do it easily
2. If you are not a dev, you have to learn a new step (download sources,
compile sources, compile doc and check the result)

We could check easily the result without this big step.

git wpr -> wpr = !bash -c \"git fetch upstream pull/${1}/head:pr_${1} && git worktree add ../$(basename $(git rev-parse --show-toplevel))-pr-${1} pr_${1}\" -

I think this feature would be really useful for the contributors, the
reviewers and you, the core-dev.

St?phane

-- 
St?phane Wirtel - https://wirtel.be - @matrixise

From rosuav at gmail.com  Sun Nov  4 10:18:11 2018
From: rosuav at gmail.com (Chris Angelico)
Date: Mon, 5 Nov 2018 02:18:11 +1100
Subject: [Python-Dev] Get a running instance of the doc for a PR.
In-Reply-To: <dCNWpHselG_mmIFYqAYmu_MD8TGQMlu4rmE68Fc3aPJvMldn-P4FnrRDP7J3AxG9H3QNPO4y1P_WE-OGAkn0iQgiqEuijK0Ezbzl40LzV68=@palard.fr>
References: <20181104133827.GA25586@xps>
 <203B5254-326E-43EC-A80D-4A8147791A9D@python.org>
 <dCNWpHselG_mmIFYqAYmu_MD8TGQMlu4rmE68Fc3aPJvMldn-P4FnrRDP7J3AxG9H3QNPO4y1P_WE-OGAkn0iQgiqEuijK0Ezbzl40LzV68=@palard.fr>
Message-ID: <CAPTjJmoci5NhiEqGnZ9dZ4odfYHA+1=UDOMJogr4_oZeJCbzZA@mail.gmail.com>

On Mon, Nov 5, 2018 at 2:11 AM Julien Palard via Python-Dev
<python-dev at python.org> wrote:
>
> Considering feedback from Ned, what about building this as an independent service? We don't really need to interface with python.org at all, we just need some hardware, a domain, some code to interface with github API and... to start it's probably enough? It would be a usefull POC.
>

After running 'make html', the build directory is the entire site as a
set of static files, right? Maybe the easiest solution is to tie in
with GitHub Pages. I already have a script that will push a directory
up as the gh-pages branch of the current repo; it'd just need a tweak
so it can push to a specific repo, which you could create on GitHub
for the purpose. Not 100% automatic, but also not too difficult to
automate, if needed.

https://github.com/Rosuav/shed/blob/master/git-deploy

ChrisA

From stephane at wirtel.be  Sun Nov  4 10:25:25 2018
From: stephane at wirtel.be (Stephane Wirtel)
Date: Sun, 4 Nov 2018 16:25:25 +0100
Subject: [Python-Dev] Get a running instance of the doc for a PR.
In-Reply-To: <dCNWpHselG_mmIFYqAYmu_MD8TGQMlu4rmE68Fc3aPJvMldn-P4FnrRDP7J3AxG9H3QNPO4y1P_WE-OGAkn0iQgiqEuijK0Ezbzl40LzV68=@palard.fr>
References: <20181104133827.GA25586@xps>
 <203B5254-326E-43EC-A80D-4A8147791A9D@python.org>
 <dCNWpHselG_mmIFYqAYmu_MD8TGQMlu4rmE68Fc3aPJvMldn-P4FnrRDP7J3AxG9H3QNPO4y1P_WE-OGAkn0iQgiqEuijK0Ezbzl40LzV68=@palard.fr>
Message-ID: <20181104152525.GA12103@xps>

On 11/04, Julien Palard wrote:
>Considering feedback from Ned, what about building this as an
>independent service? We don't really need to interface with python.org
>at all, we just need some hardware, a domain, some code to interface
>with github API and... to start it's probably enough? It would be a
>usefull POC.
+1

We have 2 options

1. We keep a domain (python.org, or another one) and for each build we would have a subdomain for
each build by PR.
doc-pr-XYZ.domain.tld

2. We could store on domain but with a subdirectory by PR
domain.tld/doc-pr-XYZ

In travis, I think we have the PR info, we could use it and upload to
the server for the live preview.

Once merged, we drop the temporary doc on the server.


St?phane

>
>--?
>Julien Palard
>https://mdk.fr
>

-- 
St?phane Wirtel - https://wirtel.be - @matrixise

From stephane at wirtel.be  Sun Nov  4 10:32:11 2018
From: stephane at wirtel.be (Stephane Wirtel)
Date: Sun, 4 Nov 2018 16:32:11 +0100
Subject: [Python-Dev] Get a running instance of the doc for a PR.
In-Reply-To: <CAPTjJmoci5NhiEqGnZ9dZ4odfYHA+1=UDOMJogr4_oZeJCbzZA@mail.gmail.com>
References: <20181104133827.GA25586@xps>
 <203B5254-326E-43EC-A80D-4A8147791A9D@python.org>
 <dCNWpHselG_mmIFYqAYmu_MD8TGQMlu4rmE68Fc3aPJvMldn-P4FnrRDP7J3AxG9H3QNPO4y1P_WE-OGAkn0iQgiqEuijK0Ezbzl40LzV68=@palard.fr>
 <CAPTjJmoci5NhiEqGnZ9dZ4odfYHA+1=UDOMJogr4_oZeJCbzZA@mail.gmail.com>
Message-ID: <20181104153211.GB12103@xps>

On 11/05, Chris Angelico wrote:
>On Mon, Nov 5, 2018 at 2:11 AM Julien Palard via Python-Dev
><python-dev at python.org> wrote:
>>
>> Considering feedback from Ned, what about building this as an independent service? We don't really need to interface with python.org at all, we just need some hardware, a domain, some code to interface with github API and... to start it's probably enough? It would be a usefull POC.
>>
>
>After running 'make html', the build directory is the entire site as a
>set of static files, right? Maybe the easiest solution is to tie in
>with GitHub Pages. I already have a script that will push a directory
>up as the gh-pages branch of the current repo; it'd just need a tweak
>so it can push to a specific repo, which you could create on GitHub
>for the purpose. Not 100% automatic, but also not too difficult to
>automate, if needed.
>
>https://github.com/Rosuav/shed/blob/master/git-deploy

Nice idea, but I am not for that.

1. We will populate the git repository with a lot of gh-pages branches
and I am not for this solution
2. This static doc is just temporary, once merged, we have to remove the
link and the content on the server, with the gh-pages, that will be a
commit where we drop the content, but it's a commit and we will consume
the storage of github.
3. 1 repo has only one gh-pages, in our case, we need to have a lot of
gh-pages for a repo.

But thank you for your idea.

-- 
St?phane Wirtel - https://wirtel.be - @matrixise

From steve.dower at python.org  Sun Nov  4 10:34:23 2018
From: steve.dower at python.org (Steve Dower)
Date: Sun, 4 Nov 2018 07:34:23 -0800
Subject: [Python-Dev] Get a running instance of the doc for a PR.
In-Reply-To: <CAPTjJmoci5NhiEqGnZ9dZ4odfYHA+1=UDOMJogr4_oZeJCbzZA@mail.gmail.com>
References: <20181104133827.GA25586@xps>
 <203B5254-326E-43EC-A80D-4A8147791A9D@python.org>
 <dCNWpHselG_mmIFYqAYmu_MD8TGQMlu4rmE68Fc3aPJvMldn-P4FnrRDP7J3AxG9H3QNPO4y1P_WE-OGAkn0iQgiqEuijK0Ezbzl40LzV68=@palard.fr>
 <CAPTjJmoci5NhiEqGnZ9dZ4odfYHA+1=UDOMJogr4_oZeJCbzZA@mail.gmail.com>
Message-ID: <23b8f062-348b-9750-e31f-0b3dabf09b22@python.org>

On 04Nov2018 0718, Chris Angelico wrote:
> On Mon, Nov 5, 2018 at 2:11 AM Julien Palard via Python-Dev
> <python-dev at python.org> wrote:
>>
>> Considering feedback from Ned, what about building this as an independent service? We don't really need to interface with python.org at all, we just need some hardware, a domain, some code to interface with github API and... to start it's probably enough? It would be a usefull POC.
>>
> 
> After running 'make html', the build directory is the entire site as a
> set of static files, right? Maybe the easiest solution is to tie in
> with GitHub Pages. I already have a script that will push a directory
> up as the gh-pages branch of the current repo; it'd just need a tweak
> so it can push to a specific repo, which you could create on GitHub
> for the purpose. Not 100% automatic, but also not too difficult to
> automate, if needed.

I can trivially attach the built docs as a ZIP file to the Azure 
Pipelines build, though that doesn't help the "preview on my phone" 
scenario (unless your phone can extract and then open a directory of 
HTML files? Mine can't)

But that's also easy enough to tie into a second step to deploy the 
files practically anywhere. Pushing them to a git repo based on the PR 
name is easy, and presumably it can be a single repo with directories 
for different PRs? It might need a separate job to periodically clean it 
up, but this seems very doable.

Cheers,
Steve

From storchaka at gmail.com  Sun Nov  4 10:40:29 2018
From: storchaka at gmail.com (Serhiy Storchaka)
Date: Sun, 4 Nov 2018 17:40:29 +0200
Subject: [Python-Dev] Get a running instance of the doc for a PR.
In-Reply-To: <dCNWpHselG_mmIFYqAYmu_MD8TGQMlu4rmE68Fc3aPJvMldn-P4FnrRDP7J3AxG9H3QNPO4y1P_WE-OGAkn0iQgiqEuijK0Ezbzl40LzV68=@palard.fr>
References: <20181104133827.GA25586@xps>
 <203B5254-326E-43EC-A80D-4A8147791A9D@python.org>
 <dCNWpHselG_mmIFYqAYmu_MD8TGQMlu4rmE68Fc3aPJvMldn-P4FnrRDP7J3AxG9H3QNPO4y1P_WE-OGAkn0iQgiqEuijK0Ezbzl40LzV68=@palard.fr>
Message-ID: <prn3pb$h3l$1@blaine.gmane.org>

04.11.18 17:00, Julien Palard via Python-Dev ????:
> Considering feedback from Ned, what about building this as an independent service? We don't really need to interface with python.org at all, we just need some hardware, a domain, some code to interface with github API and... to start it's probably enough? It would be a usefull POC.

This will just move risks to this service.

Ned mentioned potential abuse. We will host unchecked content. Malicious 
user can create a PR which replaces Python documentation with malicious 
content.

The Doc/ directory includes Python scripts and Makefile which are used 
for building documentation. Malicious user can use this for executing 
arbitrary code on our server.


From stephane at wirtel.be  Sun Nov  4 10:46:42 2018
From: stephane at wirtel.be (Stephane Wirtel)
Date: Sun, 4 Nov 2018 16:46:42 +0100
Subject: [Python-Dev] Get a running instance of the doc for a PR.
In-Reply-To: <23b8f062-348b-9750-e31f-0b3dabf09b22@python.org>
References: <20181104133827.GA25586@xps>
 <203B5254-326E-43EC-A80D-4A8147791A9D@python.org>
 <dCNWpHselG_mmIFYqAYmu_MD8TGQMlu4rmE68Fc3aPJvMldn-P4FnrRDP7J3AxG9H3QNPO4y1P_WE-OGAkn0iQgiqEuijK0Ezbzl40LzV68=@palard.fr>
 <CAPTjJmoci5NhiEqGnZ9dZ4odfYHA+1=UDOMJogr4_oZeJCbzZA@mail.gmail.com>
 <23b8f062-348b-9750-e31f-0b3dabf09b22@python.org>
Message-ID: <20181104154642.GC12103@xps>

On 11/04, Steve Dower wrote:
>On 04Nov2018 0718, Chris Angelico wrote:
>>On Mon, Nov 5, 2018 at 2:11 AM Julien Palard via Python-Dev
>><python-dev at python.org> wrote:
>>>
>>>Considering feedback from Ned, what about building this as an independent service? We don't really need to interface with python.org at all, we just need some hardware, a domain, some code to interface with github API and... to start it's probably enough? It would be a usefull POC.
>>>
>>
>>After running 'make html', the build directory is the entire site as a
>>set of static files, right? Maybe the easiest solution is to tie in
>>with GitHub Pages. I already have a script that will push a directory
>>up as the gh-pages branch of the current repo; it'd just need a tweak
>>so it can push to a specific repo, which you could create on GitHub
>>for the purpose. Not 100% automatic, but also not too difficult to
>>automate, if needed.
>
>I can trivially attach the built docs as a ZIP file to the Azure 
>Pipelines build, though that doesn't help the "preview on my phone" 
>scenario (unless your phone can extract and then open a directory of 
>HTML files? Mine can't)
Or just upload the zip file to the server-live-preview-doc and unzip the
result.
>
>But that's also easy enough to tie into a second step to deploy the 
>files practically anywhere. Pushing them to a git repo based on the PR 
>name is easy, and presumably it can be a single repo with directories 
>for different PRs? It might need a separate job to periodically clean 
>it up, but this seems very doable.
for the subdirectory by PR I am not sure but we could have an issue with
the cache of the browser because we will use the same domain, but this
solution can be created in few hours. +1

For the subdomain, no problem with the cache, just update the DNS, but
we can have an issue with the propagation of the DNS if the TTL is high.

We could use Bedevere, not sure but I think it can receive an action
about the merge of a PR. Once merge, we execute the clean process ;-)
>
>Cheers,
>Steve
>_______________________________________________
>Python-Dev mailing list
>Python-Dev at python.org
>https://mail.python.org/mailman/listinfo/python-dev
>Unsubscribe: https://mail.python.org/mailman/options/python-dev/stephane%40wirtel.be

-- 
St?phane Wirtel - https://wirtel.be - @matrixise

From rosuav at gmail.com  Sun Nov  4 10:48:25 2018
From: rosuav at gmail.com (Chris Angelico)
Date: Mon, 5 Nov 2018 02:48:25 +1100
Subject: [Python-Dev] Get a running instance of the doc for a PR.
In-Reply-To: <20181104153211.GB12103@xps>
References: <20181104133827.GA25586@xps>
 <203B5254-326E-43EC-A80D-4A8147791A9D@python.org>
 <dCNWpHselG_mmIFYqAYmu_MD8TGQMlu4rmE68Fc3aPJvMldn-P4FnrRDP7J3AxG9H3QNPO4y1P_WE-OGAkn0iQgiqEuijK0Ezbzl40LzV68=@palard.fr>
 <CAPTjJmoci5NhiEqGnZ9dZ4odfYHA+1=UDOMJogr4_oZeJCbzZA@mail.gmail.com>
 <20181104153211.GB12103@xps>
Message-ID: <CAPTjJmoqq+prNQa5vvNZ5YnEQeX+Xr0ztFcqZDeNU1BpsbH-Aw@mail.gmail.com>

On Mon, Nov 5, 2018 at 2:33 AM Stephane Wirtel <stephane at wirtel.be> wrote:
>
> On 11/05, Chris Angelico wrote:
> >On Mon, Nov 5, 2018 at 2:11 AM Julien Palard via Python-Dev
> ><python-dev at python.org> wrote:
> >>
> >> Considering feedback from Ned, what about building this as an independent service? We don't really need to interface with python.org at all, we just need some hardware, a domain, some code to interface with github API and... to start it's probably enough? It would be a usefull POC.
> >>
> >
> >After running 'make html', the build directory is the entire site as a
> >set of static files, right? Maybe the easiest solution is to tie in
> >with GitHub Pages. I already have a script that will push a directory
> >up as the gh-pages branch of the current repo; it'd just need a tweak
> >so it can push to a specific repo, which you could create on GitHub
> >for the purpose. Not 100% automatic, but also not too difficult to
> >automate, if needed.
> >
> >https://github.com/Rosuav/shed/blob/master/git-deploy
>
> Nice idea, but I am not for that.
>
> 1. We will populate the git repository with a lot of gh-pages branches
> and I am not for this solution
> 2. This static doc is just temporary, once merged, we have to remove the
> link and the content on the server, with the gh-pages, that will be a
> commit where we drop the content, but it's a commit and we will consume
> the storage of github.
> 3. 1 repo has only one gh-pages, in our case, we need to have a lot of
> gh-pages for a repo.
>

Yeah, understood. I was thinking of having the individual patch
authors create temporary GitHub repositories to push to. It'd be an
optional step; if you want to show people a preview of your PR, just
create a repository and push to it (using a script something like
that). That way, you don't have to worry about malicious content
(since it'll be hosted under the author's name - I'm sure GitHub have
measures in place to deal with that, and it wouldn't be Python.org's
problem), nor having lots of gh-pages branches sitting around (they'd
be the responsibility of the author).

> But thank you for your idea.

No probs, and I don't mind if it's not adopted. Just wanted to put it out there.

ChrisA

From stephane at wirtel.be  Sun Nov  4 10:49:57 2018
From: stephane at wirtel.be (Stephane Wirtel)
Date: Sun, 4 Nov 2018 16:49:57 +0100
Subject: [Python-Dev] Get a running instance of the doc for a PR.
In-Reply-To: <prn3pb$h3l$1@blaine.gmane.org>
References: <20181104133827.GA25586@xps>
 <203B5254-326E-43EC-A80D-4A8147791A9D@python.org>
 <dCNWpHselG_mmIFYqAYmu_MD8TGQMlu4rmE68Fc3aPJvMldn-P4FnrRDP7J3AxG9H3QNPO4y1P_WE-OGAkn0iQgiqEuijK0Ezbzl40LzV68=@palard.fr>
 <prn3pb$h3l$1@blaine.gmane.org>
Message-ID: <20181104154957.GD12103@xps>

On 11/04, Serhiy Storchaka wrote:
>04.11.18 17:00, Julien Palard via Python-Dev ????:
>>Considering feedback from Ned, what about building this as an independent service? We don't really need to interface with python.org at all, we just need some hardware, a domain, some code to interface with github API and... to start it's probably enough? It would be a usefull POC.
>
>This will just move risks to this service.
>
>Ned mentioned potential abuse. We will host unchecked content. 
>Malicious user can create a PR which replaces Python documentation 
>with malicious content.
The content will be generated by the build/html directory from Travis.
If Travis is green we upload the doc, if Travis is red, we do not
publish it. If there is an abuse, we close/drop the PR, maybe Bedevere
can receive this notification via the webhooks and notify the server to
remove the doc.
>
>The Doc/ directory includes Python scripts and Makefile which are used 
>for building documentation. Malicious user can use this for executing 
>arbitrary code on our server.
Currently, we use Travis. The malicious code will be execute in the
container of Travis, not on the server. We only copy the static files
and if we use nginx/apache, we don't execute the .py files. Just serve
the .html,.css,.js files
>
>_______________________________________________
>Python-Dev mailing list
>Python-Dev at python.org
>https://mail.python.org/mailman/listinfo/python-dev
>Unsubscribe: https://mail.python.org/mailman/options/python-dev/stephane%40wirtel.be

-- 
St?phane Wirtel - https://wirtel.be - @matrixise

From steve at pearwood.info  Sun Nov  4 10:50:19 2018
From: steve at pearwood.info (Steven D'Aprano)
Date: Mon, 5 Nov 2018 02:50:19 +1100
Subject: [Python-Dev] Get a running instance of the doc for a PR.
In-Reply-To: <20181104151239.GA14162@xps>
References: <20181104133827.GA25586@xps>
 <203B5254-326E-43EC-A80D-4A8147791A9D@python.org>
 <20181104151239.GA14162@xps>
Message-ID: <20181104155017.GX3817@ando.pearwood.info>

On Sun, Nov 04, 2018 at 04:12:39PM +0100, Stephane Wirtel wrote:

> My workflow is the following steps:
> 
> git wpr XYZ
> cd ../cpython-XYZ
> ./configure --prefix=$PWD-build --with-pydebug --silent
> make -j 4 -s
> make PYTHON=../python -C Doc/ venv
> make -C Doc/ check suspicious html serve
> 
> and run the browser on http://localhost:8000/ and check the result.
> 
> 
> 1. Because I am a dev I can do it easily
> 2. If you are not a dev, you have to learn a new step (download sources,
> compile sources, compile doc and check the result)

If I am making doc patches, shouldn't I be doing that *before* I 
submit the PR? How else will I know that my changes haven't broken the 
docs?

So surely I need to learn those steps regardless?

(Not a rhetorical question.)


> I think this feature would be really useful for the contributors, the
> reviewers and you, the core-dev.

Sure. But the usefulness has to be weighed against the extra complexity, 
the extra "one more thing that can break and needs to be maintained", 
and the risk of abuse.

I have no opinion on whether the pluses outweigh the minuses.


-- 
Steve

From stephane at wirtel.be  Sun Nov  4 10:58:36 2018
From: stephane at wirtel.be (Stephane Wirtel)
Date: Sun, 4 Nov 2018 16:58:36 +0100
Subject: [Python-Dev] Get a running instance of the doc for a PR.
In-Reply-To: <CAPTjJmoqq+prNQa5vvNZ5YnEQeX+Xr0ztFcqZDeNU1BpsbH-Aw@mail.gmail.com>
References: <20181104133827.GA25586@xps>
 <203B5254-326E-43EC-A80D-4A8147791A9D@python.org>
 <dCNWpHselG_mmIFYqAYmu_MD8TGQMlu4rmE68Fc3aPJvMldn-P4FnrRDP7J3AxG9H3QNPO4y1P_WE-OGAkn0iQgiqEuijK0Ezbzl40LzV68=@palard.fr>
 <CAPTjJmoci5NhiEqGnZ9dZ4odfYHA+1=UDOMJogr4_oZeJCbzZA@mail.gmail.com>
 <20181104153211.GB12103@xps>
 <CAPTjJmoqq+prNQa5vvNZ5YnEQeX+Xr0ztFcqZDeNU1BpsbH-Aw@mail.gmail.com>
Message-ID: <20181104155836.GE12103@xps>

On 11/05, Chris Angelico wrote:
>On Mon, Nov 5, 2018 at 2:33 AM Stephane Wirtel <stephane at wirtel.be> wrote:
>>
>> On 11/05, Chris Angelico wrote:
>> >On Mon, Nov 5, 2018 at 2:11 AM Julien Palard via Python-Dev
>> ><python-dev at python.org> wrote:
>> >>
>> >> Considering feedback from Ned, what about building this as an independent service? We don't really need to interface with python.org at all, we just need some hardware, a domain, some code to interface with github API and... to start it's probably enough? It would be a usefull POC.
>> >>
>> >
>> >After running 'make html', the build directory is the entire site as a
>> >set of static files, right? Maybe the easiest solution is to tie in
>> >with GitHub Pages. I already have a script that will push a directory
>> >up as the gh-pages branch of the current repo; it'd just need a tweak
>> >so it can push to a specific repo, which you could create on GitHub
>> >for the purpose. Not 100% automatic, but also not too difficult to
>> >automate, if needed.
>> >
>> >https://github.com/Rosuav/shed/blob/master/git-deploy
>>
>> Nice idea, but I am not for that.
>>
>> 1. We will populate the git repository with a lot of gh-pages branches
>> and I am not for this solution
>> 2. This static doc is just temporary, once merged, we have to remove the
>> link and the content on the server, with the gh-pages, that will be a
>> commit where we drop the content, but it's a commit and we will consume
>> the storage of github.
>> 3. 1 repo has only one gh-pages, in our case, we need to have a lot of
>> gh-pages for a repo.
>>
>
>Yeah, understood. I was thinking of having the individual patch
>authors create temporary GitHub repositories to push to. It'd be an
>optional step; if you want to show people a preview of your PR, just
>create a repository and push to it (using a script something like
>that). That way, you don't have to worry about malicious content
>(since it'll be hosted under the author's name - I'm sure GitHub have
>measures in place to deal with that, and it wouldn't be Python.org's
>problem), nor having lots of gh-pages branches sitting around (they'd
>be the responsibility of the author).
>
>> But thank you for your idea.
>
>No probs, and I don't mind if it's not adopted. Just wanted to put it out there.
In fact, I was interested by your solution because we avoid the
maintenance of the server, but in our case, we would host many
Docs/build/html. 

Thanks again
>
>ChrisA
>_______________________________________________
>Python-Dev mailing list
>Python-Dev at python.org
>https://mail.python.org/mailman/listinfo/python-dev
>Unsubscribe: https://mail.python.org/mailman/options/python-dev/stephane%40wirtel.be

-- 
St?phane Wirtel - https://wirtel.be - @matrixise

From stephane at wirtel.be  Sun Nov  4 11:05:07 2018
From: stephane at wirtel.be (Stephane Wirtel)
Date: Sun, 4 Nov 2018 17:05:07 +0100
Subject: [Python-Dev] Get a running instance of the doc for a PR.
In-Reply-To: <20181104155017.GX3817@ando.pearwood.info>
References: <20181104133827.GA25586@xps>
 <203B5254-326E-43EC-A80D-4A8147791A9D@python.org>
 <20181104151239.GA14162@xps>
 <20181104155017.GX3817@ando.pearwood.info>
Message-ID: <20181104160507.GF12103@xps>

On 11/05, Steven D'Aprano wrote:
>On Sun, Nov 04, 2018 at 04:12:39PM +0100, Stephane Wirtel wrote:
>
>> My workflow is the following steps:
>>
>> git wpr XYZ
>> cd ../cpython-XYZ
>> ./configure --prefix=$PWD-build --with-pydebug --silent
>> make -j 4 -s
>> make PYTHON=../python -C Doc/ venv
>> make -C Doc/ check suspicious html serve
>>
>> and run the browser on http://localhost:8000/ and check the result.
>>
>>
>> 1. Because I am a dev I can do it easily
>> 2. If you are not a dev, you have to learn a new step (download sources,
>> compile sources, compile doc and check the result)
>
>If I am making doc patches, shouldn't I be doing that *before* I
>submit the PR? How else will I know that my changes haven't broken the
>docs?
You can use the web interface of Github and just add/remove/modify a
paragraph.

>
>So surely I need to learn those steps regardless?
>
>(Not a rhetorical question.)
>
>
>> I think this feature would be really useful for the contributors, the
>> reviewers and you, the core-dev.
>
>Sure. But the usefulness has to be weighed against the extra complexity,
>the extra "one more thing that can break and needs to be maintained",
>and the risk of abuse.
Which kind of abuse?

-- 
St?phane Wirtel - https://wirtel.be - @matrixise

From julien at palard.fr  Sun Nov  4 11:12:00 2018
From: julien at palard.fr (Julien Palard)
Date: Sun, 04 Nov 2018 16:12:00 +0000
Subject: [Python-Dev] Get a running instance of the doc for a PR.
In-Reply-To: <23b8f062-348b-9750-e31f-0b3dabf09b22@python.org>
References: <20181104133827.GA25586@xps>
 <203B5254-326E-43EC-A80D-4A8147791A9D@python.org>
 <dCNWpHselG_mmIFYqAYmu_MD8TGQMlu4rmE68Fc3aPJvMldn-P4FnrRDP7J3AxG9H3QNPO4y1P_WE-OGAkn0iQgiqEuijK0Ezbzl40LzV68=@palard.fr>
 <CAPTjJmoci5NhiEqGnZ9dZ4odfYHA+1=UDOMJogr4_oZeJCbzZA@mail.gmail.com>
 <23b8f062-348b-9750-e31f-0b3dabf09b22@python.org>
Message-ID: <A4mRE_KHREAET2dcImMmaeNEStivmZ6idpvChHarjkFmkPfTX5wXI0PfSY4teImK_VzpYVTJ79M6jy73fcQddt1S2OEjbOAm_Yy2QVhOW68=@palard.fr>

> I can trivially attach the built docs as a ZIP file to the Azure
> Pipelines build, though that doesn't help the "preview on my phone"

So one can build an HTTP server that gathers doc builds from Azure and expose them?

--?
Julien Palard
https://mdk.fr


From mariatta.wijaya at gmail.com  Sun Nov  4 10:53:44 2018
From: mariatta.wijaya at gmail.com (Mariatta Wijaya)
Date: Sun, 4 Nov 2018 07:53:44 -0800
Subject: [Python-Dev] Get a running instance of the doc for a PR.
In-Reply-To: <prn3pb$h3l$1@blaine.gmane.org>
References: <20181104133827.GA25586@xps>
 <203B5254-326E-43EC-A80D-4A8147791A9D@python.org>
 <dCNWpHselG_mmIFYqAYmu_MD8TGQMlu4rmE68Fc3aPJvMldn-P4FnrRDP7J3AxG9H3QNPO4y1P_WE-OGAkn0iQgiqEuijK0Ezbzl40LzV68=@palard.fr>
 <prn3pb$h3l$1@blaine.gmane.org>
Message-ID: <CAGbohnZm7kmt9V1QHB1cuZVv3CX5P2Sq=6R32A+ocDQPdYQ=8g@mail.gmail.com>

I think the intent is just uploading the output HTML and static assets.

I agree having the temporary output of PR docs build is useful, but I don't
think a python.org domain is necessary. If it can be uploaded to any cloud
storage service then that's good enough, just provide the link in the
status check. The output can be cleared after it receive the PR closed
webhook.

On Sun, Nov 4, 2018, 7:43 AM Serhiy Storchaka <storchaka at gmail.com wrote:

> 04.11.18 17:00, Julien Palard via Python-Dev ????:
> > Considering feedback from Ned, what about building this as an
> independent service? We don't really need to interface with python.org at
> all, we just need some hardware, a domain, some code to interface with
> github API and... to start it's probably enough? It would be a usefull POC.
>
> This will just move risks to this service.
>
> Ned mentioned potential abuse. We will host unchecked content. Malicious
> user can create a PR which replaces Python documentation with malicious
> content.
>
> The Doc/ directory includes Python scripts and Makefile which are used
> for building documentation. Malicious user can use this for executing
> arbitrary code on our server.
>
> _______________________________________________
> Python-Dev mailing list
> Python-Dev at python.org
> https://mail.python.org/mailman/listinfo/python-dev
> Unsubscribe:
> https://mail.python.org/mailman/options/python-dev/mariatta%40python.org
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://mail.python.org/pipermail/python-dev/attachments/20181104/6fa02b12/attachment-0001.html>

From mariatta.wijaya at gmail.com  Sun Nov  4 11:02:49 2018
From: mariatta.wijaya at gmail.com (Mariatta Wijaya)
Date: Sun, 4 Nov 2018 08:02:49 -0800
Subject: [Python-Dev] Get a running instance of the doc for a PR.
In-Reply-To: <20181104155017.GX3817@ando.pearwood.info>
References: <20181104133827.GA25586@xps>
 <203B5254-326E-43EC-A80D-4A8147791A9D@python.org>
 <20181104151239.GA14162@xps> <20181104155017.GX3817@ando.pearwood.info>
Message-ID: <CAGbohnYjfMtVBbSSZA=pNW_NNYMwc-WOy_L0V=pXij+tTUwfJw@mail.gmail.com>

This will make review turnout quicker, since I can potentially review and
view the output from anywhere (phone while on a beach) instead of waiting
until I'm back home, open a computer, and then verify the output myself.

On Sun, Nov 4, 2018, 7:56 AM Steven D'Aprano <steve at pearwood.info wrote:

> On Sun, Nov 04, 2018 at 04:12:39PM +0100, Stephane Wirtel wrote:
>
> > My workflow is the following steps:
> >
> > git wpr XYZ
> > cd ../cpython-XYZ
> > ./configure --prefix=$PWD-build --with-pydebug --silent
> > make -j 4 -s
> > make PYTHON=../python -C Doc/ venv
> > make -C Doc/ check suspicious html serve
> >
> > and run the browser on http://localhost:8000/ and check the result.
> >
> >
> > 1. Because I am a dev I can do it easily
> > 2. If you are not a dev, you have to learn a new step (download sources,
> > compile sources, compile doc and check the result)
>
> If I am making doc patches, shouldn't I be doing that *before* I
> submit the PR? How else will I know that my changes haven't broken the
> docs?
>
> So surely I need to learn those steps regardless?
>
> (Not a rhetorical question.)
>
>
> > I think this feature would be really useful for the contributors, the
> > reviewers and you, the core-dev.
>
> Sure. But the usefulness has to be weighed against the extra complexity,
> the extra "one more thing that can break and needs to be maintained",
> and the risk of abuse.
>
> I have no opinion on whether the pluses outweigh the minuses.
>
>
> --
> Steve
> _______________________________________________
> Python-Dev mailing list
> Python-Dev at python.org
> https://mail.python.org/mailman/listinfo/python-dev
> Unsubscribe:
> https://mail.python.org/mailman/options/python-dev/mariatta%40python.org
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://mail.python.org/pipermail/python-dev/attachments/20181104/6147cd26/attachment.html>

From steve.dower at python.org  Sun Nov  4 11:20:04 2018
From: steve.dower at python.org (Steve Dower)
Date: Sun, 4 Nov 2018 08:20:04 -0800
Subject: [Python-Dev] Get a running instance of the doc for a PR.
In-Reply-To: <A4mRE_KHREAET2dcImMmaeNEStivmZ6idpvChHarjkFmkPfTX5wXI0PfSY4teImK_VzpYVTJ79M6jy73fcQddt1S2OEjbOAm_Yy2QVhOW68=@palard.fr>
References: <20181104133827.GA25586@xps>
 <203B5254-326E-43EC-A80D-4A8147791A9D@python.org>
 <dCNWpHselG_mmIFYqAYmu_MD8TGQMlu4rmE68Fc3aPJvMldn-P4FnrRDP7J3AxG9H3QNPO4y1P_WE-OGAkn0iQgiqEuijK0Ezbzl40LzV68=@palard.fr>
 <CAPTjJmoci5NhiEqGnZ9dZ4odfYHA+1=UDOMJogr4_oZeJCbzZA@mail.gmail.com>
 <23b8f062-348b-9750-e31f-0b3dabf09b22@python.org>
 <A4mRE_KHREAET2dcImMmaeNEStivmZ6idpvChHarjkFmkPfTX5wXI0PfSY4teImK_VzpYVTJ79M6jy73fcQddt1S2OEjbOAm_Yy2QVhOW68=@palard.fr>
Message-ID: <7d0df116-abc5-74c2-e9fd-d778da062ec9@python.org>

On 04Nov2018 0812, Julien Palard wrote:
>> I can trivially attach the built docs as a ZIP file to the Azure
>> Pipelines build, though that doesn't help the "preview on my phone"
> 
> So one can build an HTTP server that gathers doc builds from Azure and expose them?

Either that, or Azure can push it directly to the server. (This way is 
simpler, since the processing power is already there and the trigger is 
trivial, compared to triggering yet another service from the build 
completion. Though it does mean putting credentials somewhere, which is 
why a github repo is the easiest option, as those are already there.)

Cheers,
Steve

From stephane at wirtel.be  Sun Nov  4 11:25:44 2018
From: stephane at wirtel.be (Stephane Wirtel)
Date: Sun, 4 Nov 2018 17:25:44 +0100
Subject: [Python-Dev] Get a running instance of the doc for a PR.
In-Reply-To: <CAGbohnZm7kmt9V1QHB1cuZVv3CX5P2Sq=6R32A+ocDQPdYQ=8g@mail.gmail.com>
References: <20181104133827.GA25586@xps>
 <203B5254-326E-43EC-A80D-4A8147791A9D@python.org>
 <dCNWpHselG_mmIFYqAYmu_MD8TGQMlu4rmE68Fc3aPJvMldn-P4FnrRDP7J3AxG9H3QNPO4y1P_WE-OGAkn0iQgiqEuijK0Ezbzl40LzV68=@palard.fr>
 <prn3pb$h3l$1@blaine.gmane.org>
 <CAGbohnZm7kmt9V1QHB1cuZVv3CX5P2Sq=6R32A+ocDQPdYQ=8g@mail.gmail.com>
Message-ID: <20181104162544.GA23921@xps>

On 11/04, Mariatta Wijaya wrote:
>I think the intent is just uploading the output HTML and static assets.
Yep, it's my idea, just upload the output html and static assets,
nothing else.
>
>I agree having the temporary output of PR docs build is useful, but I don't
>think a python.org domain is necessary. If it can be uploaded to any cloud
>storage service then that's good enough, just provide the link in the
>status check. The output can be cleared after it receive the PR closed
>webhook.
+1

And I think Bedevere is the best candidate for this feature (once
closed, remove from the server)



-- 
St?phane Wirtel - https://wirtel.be - @matrixise

From tritium-list at sdamon.com  Sun Nov  4 11:28:35 2018
From: tritium-list at sdamon.com (Alex Walters)
Date: Sun, 4 Nov 2018 11:28:35 -0500
Subject: [Python-Dev] Get a running instance of the doc for a PR.
In-Reply-To: <20181104133827.GA25586@xps>
References: <20181104133827.GA25586@xps>
Message-ID: <010401d4745b$6fec9a90$4fc5cfb0$@sdamon.com>

Doesn't read the docs already do this for pull requests?  Even if it doesn't, don't the core maintainers of read the docs go to pycon?  I wouldn't suggest read the docs for primary docs hosting for python, but they are perfectly fine for live testing pull request documentation without having to roll our own.

> -----Original Message-----
> From: Python-Dev <python-dev-bounces+tritium-
> list=sdamon.com at python.org> On Behalf Of Stephane Wirtel
> Sent: Sunday, November 4, 2018 8:38 AM
> To: python-dev at python.org
> Subject: [Python-Dev] Get a running instance of the doc for a PR.
> 
> Hi all,
> 
> When we receive a PR about the documentation, I think that could be
> interesting if we could have a running instance of the doc on a sub
> domain of python.org.
> 
> For example, pr-10000-doc.python.org or whatever, but by this way the
> reviewers could see the result online.
> 
> The workflow would be like that:
> 
> New PR -> build the doc (done by Travis) -> publish it to a server ->
> once published, the PR is notified by "doc is available at URL".
> 
> Once merged -> we remove the doc and the link (hello bedevere).
> 
> I am interested by this feature and if you also interested, tell me.
> I would like discuss with Julien Palard and Ernest W.  Durbin III for a
> solution as soon as possible.
> 
> Have a nice day,
> 
> St?phane
> 
> --
> St?phane Wirtel - https://wirtel.be - @matrixise
> _______________________________________________
> Python-Dev mailing list
> Python-Dev at python.org
> https://mail.python.org/mailman/listinfo/python-dev
> Unsubscribe: https://mail.python.org/mailman/options/python-dev/tritium-
> list%40sdamon.com


From stephane at wirtel.be  Sun Nov  4 11:32:38 2018
From: stephane at wirtel.be (Stephane Wirtel)
Date: Sun, 4 Nov 2018 17:32:38 +0100
Subject: [Python-Dev] Get a running instance of the doc for a PR.
In-Reply-To: <CAGbohnYjfMtVBbSSZA=pNW_NNYMwc-WOy_L0V=pXij+tTUwfJw@mail.gmail.com>
References: <20181104133827.GA25586@xps>
 <203B5254-326E-43EC-A80D-4A8147791A9D@python.org>
 <20181104151239.GA14162@xps>
 <20181104155017.GX3817@ando.pearwood.info>
 <CAGbohnYjfMtVBbSSZA=pNW_NNYMwc-WOy_L0V=pXij+tTUwfJw@mail.gmail.com>
Message-ID: <20181104163238.GB23921@xps>

On 11/04, Mariatta Wijaya wrote:
>This will make review turnout quicker, since I can potentially review and
>view the output from anywhere (phone while on a beach) instead of waiting
>until I'm back home, open a computer, and then verify the output myself.
Yep, last week I was at a dinner at PyCon.DE, I have seen a PR, I wanted
to check the result and approve it or not. With this feature, I can
check it asap and just approve via github. Once approved, miss-islington
could merge the PR, once merged, Bedevere can notify the service and
remove the documentation of this PR.


-- 
St?phane Wirtel - https://wirtel.be - @matrixise

From nad at python.org  Sun Nov  4 11:40:25 2018
From: nad at python.org (Ned Deily)
Date: Sun, 4 Nov 2018 11:40:25 -0500
Subject: [Python-Dev] Get a running instance of the doc for a PR.
In-Reply-To: <20181104151239.GA14162@xps>
References: <20181104133827.GA25586@xps>
 <203B5254-326E-43EC-A80D-4A8147791A9D@python.org>
 <20181104151239.GA14162@xps>
Message-ID: <DE17F969-2084-457D-B516-600CCF43BB16@python.org>

On Nov 4, 2018, at 10:12, Stephane Wirtel <stephane at wirtel.be> wrote:
> 3. On this after-noon, I have reviewed a PR, and I was in the same case,
> download the PR, build python, compile the doc and run the local server.
> 
> My workflow is the following steps:
> 
> git wpr XYZ
> cd ../cpython-XYZ
> ./configure --prefix=$PWD-build --with-pydebug --silent
> make -j 4 -s
> make PYTHON=../python -C Doc/ venv
> make -C Doc/ check suspicious html serve
> 
> and run the browser on http://localhost:8000/ and check the result.

To address one point, there's no need to run a web server to review the docs.  The generated docs can be viewed directly by any modern web browser by opening one of the files in the web browser's file menu.  Or perhaps easier, you can click on any of the generated html files; or on macOS you can use the open(1) command from the shell to open and view in the default web browser.

$ open build/html/index.html


--
  Ned Deily
  nad at python.org -- []


From paul at ganssle.io  Sun Nov  4 12:04:31 2018
From: paul at ganssle.io (Paul Ganssle)
Date: Sun, 4 Nov 2018 12:04:31 -0500
Subject: [Python-Dev] Get a running instance of the doc for a PR.
In-Reply-To: <010401d4745b$6fec9a90$4fc5cfb0$@sdamon.com>
References: <20181104133827.GA25586@xps>
 <010401d4745b$6fec9a90$4fc5cfb0$@sdamon.com>
Message-ID: <26398c8f-170d-c468-b603-ea79ca8fdcc2@ganssle.io>

There is an open request for this on GH, but it's not currently done:
https://github.com/rtfd/readthedocs.org/issues/1340

At the PyCon US sprints this year, we added documentation previews via
netlify, and they have been super useful:
https://github.com/pypa/setuptools/pull/1367 My understanding is that
other projects do something similar with CircleCI.

It's not amazingly /difficult/ for reviewers to fetch the submitter's
branch, build the documentation and review it locally, but it's a decent
number of extra steps for what /should/ be a very simple review. I think
we all know that reviewer time and effort is one of the biggest
bottlenecks in the CPython development workflow, and this could make it
/much/ easier to do reviews.

Some of the concerns about increasing the surface area I think are a bit
overblown. I haven't seen any problems yet in the projects that do this,
and I don't think it lends itself to abuse particularly
well.//Considering that the rest of the CI suite lets you run arbitrary
code on many platforms, I don't think it's particularly more dangerous
to allow people to generate ephemeral static hosted web sites as well.


Best.

Paul

On 11/4/18 11:28 AM, Alex Walters wrote:
> Doesn't read the docs already do this for pull requests?  Even if it doesn't, don't the core maintainers of read the docs go to pycon?  I wouldn't suggest read the docs for primary docs hosting for python, but they are perfectly fine for live testing pull request documentation without having to roll our own.
>
>> -----Original Message-----
>> From: Python-Dev <python-dev-bounces+tritium-
>> list=sdamon.com at python.org> On Behalf Of Stephane Wirtel
>> Sent: Sunday, November 4, 2018 8:38 AM
>> To: python-dev at python.org
>> Subject: [Python-Dev] Get a running instance of the doc for a PR.
>>
>> Hi all,
>>
>> When we receive a PR about the documentation, I think that could be
>> interesting if we could have a running instance of the doc on a sub
>> domain of python.org.
>>
>> For example, pr-10000-doc.python.org or whatever, but by this way the
>> reviewers could see the result online.
>>
>> The workflow would be like that:
>>
>> New PR -> build the doc (done by Travis) -> publish it to a server ->
>> once published, the PR is notified by "doc is available at URL".
>>
>> Once merged -> we remove the doc and the link (hello bedevere).
>>
>> I am interested by this feature and if you also interested, tell me.
>> I would like discuss with Julien Palard and Ernest W.  Durbin III for a
>> solution as soon as possible.
>>
>> Have a nice day,
>>
>> St?phane
>>
>> --
>> St?phane Wirtel - https://wirtel.be - @matrixise
>> _______________________________________________
>> Python-Dev mailing list
>> Python-Dev at python.org
>> https://mail.python.org/mailman/listinfo/python-dev
>> Unsubscribe: https://mail.python.org/mailman/options/python-dev/tritium-
>> list%40sdamon.com
> _______________________________________________
> Python-Dev mailing list
> Python-Dev at python.org
> https://mail.python.org/mailman/listinfo/python-dev
> Unsubscribe: https://mail.python.org/mailman/options/python-dev/paul%40ganssle.io
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://mail.python.org/pipermail/python-dev/attachments/20181104/9b4b74c1/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: OpenPGP digital signature
URL: <http://mail.python.org/pipermail/python-dev/attachments/20181104/9b4b74c1/attachment.sig>

From nad at python.org  Sun Nov  4 12:16:14 2018
From: nad at python.org (Ned Deily)
Date: Sun, 4 Nov 2018 12:16:14 -0500
Subject: [Python-Dev] Get a running instance of the doc for a PR.
In-Reply-To: <26398c8f-170d-c468-b603-ea79ca8fdcc2@ganssle.io>
References: <20181104133827.GA25586@xps>
 <010401d4745b$6fec9a90$4fc5cfb0$@sdamon.com>
 <26398c8f-170d-c468-b603-ea79ca8fdcc2@ganssle.io>
Message-ID: <261F41E1-7678-47CC-B40B-829F3ADB57BD@python.org>

On Nov 4, 2018, at 12:04, Paul Ganssle <paul at ganssle.io> wrote:
> Some of the concerns about increasing the surface area I think are a bit overblown. I haven't seen any problems yet in the projects that do this, and I don't think it lends itself to abuse particularly well. Considering that the rest of the CI suite lets you run arbitrary code on many platforms, I don't think it's particularly more dangerous to allow people to generate ephemeral static hosted web sites as well.

The rest of the CI suite does not let you publish things on the python.org domain, unless I'm forgetting something; they're clearly under a CI environment like Travis or AppVeyor or Azure.  That's really my main concern.


--
  Ned Deily
  nad at python.org -- []


From paul at ganssle.io  Sun Nov  4 12:21:15 2018
From: paul at ganssle.io (Paul Ganssle)
Date: Sun, 4 Nov 2018 12:21:15 -0500
Subject: [Python-Dev] Get a running instance of the doc for a PR.
In-Reply-To: <261F41E1-7678-47CC-B40B-829F3ADB57BD@python.org>
References: <20181104133827.GA25586@xps>
 <010401d4745b$6fec9a90$4fc5cfb0$@sdamon.com>
 <26398c8f-170d-c468-b603-ea79ca8fdcc2@ganssle.io>
 <261F41E1-7678-47CC-B40B-829F3ADB57BD@python.org>
Message-ID: <99a88026-60c4-68df-c022-f7d5186afeae@ganssle.io>

Oh, sorry if I misunderstood the concern. Yes, I agree that putting this
under python.org would not be a good idea.

Either hosting it on a hosting provider like netlify (or azure if that's
possible) or a dedicated domain that could be created for the purpose
(e.g. python-doc-ci.org) would be best. Alternatively, the domain could
be skipped entirely and the github hooks could link directly to
documentation by machine IP (though I suspect buying a domain for this
purpose would be a lot easier than coordinating what's necessary to make
direct links to a machine IP reasonable).


Best,
Paul

On 11/4/18 12:16 PM, Ned Deily wrote:
> On Nov 4, 2018, at 12:04, Paul Ganssle <paul at ganssle.io> wrote:
>> Some of the concerns about increasing the surface area I think are a bit overblown. I haven't seen any problems yet in the projects that do this, and I don't think it lends itself to abuse particularly well. Considering that the rest of the CI suite lets you run arbitrary code on many platforms, I don't think it's particularly more dangerous to allow people to generate ephemeral static hosted web sites as well.
> The rest of the CI suite does not let you publish things on the python.org domain, unless I'm forgetting something; they're clearly under a CI environment like Travis or AppVeyor or Azure.  That's really my main concern.
>
>
> --
>   Ned Deily
>   nad at python.org -- []
>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: OpenPGP digital signature
URL: <http://mail.python.org/pipermail/python-dev/attachments/20181104/087542f9/attachment.sig>

From stephane at wirtel.be  Sun Nov  4 14:02:33 2018
From: stephane at wirtel.be (Stephane Wirtel)
Date: Sun, 4 Nov 2018 20:02:33 +0100
Subject: [Python-Dev] Get a running instance of the doc for a PR.
In-Reply-To: <99a88026-60c4-68df-c022-f7d5186afeae@ganssle.io>
References: <20181104133827.GA25586@xps>
 <010401d4745b$6fec9a90$4fc5cfb0$@sdamon.com>
 <26398c8f-170d-c468-b603-ea79ca8fdcc2@ganssle.io>
 <261F41E1-7678-47CC-B40B-829F3ADB57BD@python.org>
 <99a88026-60c4-68df-c022-f7d5186afeae@ganssle.io>
Message-ID: <20181104190233.GA29252@xps>

On 11/04, Paul Ganssle wrote:
>Oh, sorry if I misunderstood the concern. Yes, I agree that putting this
>under python.org would not be a good idea.
>
>Either hosting it on a hosting provider like netlify (or azure if that's
>possible) or a dedicated domain that could be created for the purpose
>(e.g. python-doc-ci.org) would be best. Alternatively, the domain could
>be skipped entirely and the github hooks could link directly to
>documentation by machine IP (though I suspect buying a domain for this
>purpose would be a lot easier than coordinating what's necessary to make
>direct links to a machine IP reasonable).
Yep, I am fine with that.

Thanks Paul
>
>
>Best,
>Paul
>
>On 11/4/18 12:16 PM, Ned Deily wrote:
>> On Nov 4, 2018, at 12:04, Paul Ganssle <paul at ganssle.io> wrote:
>>> Some of the concerns about increasing the surface area I think are a bit overblown. I haven't seen any problems yet in the projects that do this, and I don't think it lends itself to abuse particularly well. Considering that the rest of the CI suite lets you run arbitrary code on many platforms, I don't think it's particularly more dangerous to allow people to generate ephemeral static hosted web sites as well.
>> The rest of the CI suite does not let you publish things on the python.org domain, unless I'm forgetting something; they're clearly under a CI environment like Travis or AppVeyor or Azure.  That's really my main concern.
>>
>>
>> --
>>   Ned Deily
>>   nad at python.org -- []
>>
>




>_______________________________________________
>Python-Dev mailing list
>Python-Dev at python.org
>https://mail.python.org/mailman/listinfo/python-dev
>Unsubscribe: https://mail.python.org/mailman/options/python-dev/stephane%40wirtel.be


-- 
St?phane Wirtel - https://wirtel.be - @matrixise

From stephane at wirtel.be  Sun Nov  4 14:05:31 2018
From: stephane at wirtel.be (Stephane Wirtel)
Date: Sun, 4 Nov 2018 20:05:31 +0100
Subject: [Python-Dev] Get a running instance of the doc for a PR.
In-Reply-To: <DE17F969-2084-457D-B516-600CCF43BB16@python.org>
References: <20181104133827.GA25586@xps>
 <203B5254-326E-43EC-A80D-4A8147791A9D@python.org>
 <20181104151239.GA14162@xps>
 <DE17F969-2084-457D-B516-600CCF43BB16@python.org>
Message-ID: <20181104190531.GB29252@xps>

On 11/04, Ned Deily wrote:
>On Nov 4, 2018, at 10:12, Stephane Wirtel <stephane at wirtel.be> wrote:
>> 3. On this after-noon, I have reviewed a PR, and I was in the same case,
>> download the PR, build python, compile the doc and run the local server.
>>
>> My workflow is the following steps:
>>
>> git wpr XYZ
>> cd ../cpython-XYZ
>> ./configure --prefix=$PWD-build --with-pydebug --silent
>> make -j 4 -s
>> make PYTHON=../python -C Doc/ venv
>> make -C Doc/ check suspicious html serve
>>
>> and run the browser on http://localhost:8000/ and check the result.
>
>To address one point, there's no need to run a web server to review the
>docs.  The generated docs can be viewed directly by any modern web
>browser by opening one of the files in the web browser's file menu.  Or
>perhaps easier, you can click on any of the generated html files; or on
>macOS you can use the open(1) command from the shell to open and view
>in the default web browser.
>
>$ open build/html/index.html
Ned, I agree with you about this point, but there is an advantage when
you use localhost:8000, you only have one entrypoint. And when you
switch between many PR, you just have to execute the make -C Doc/ serve
command (because in my workflow and with the full URI, the path can
change in function of the PR, I use git worktree for each PR).

But yep, I am +1 for firefox build/html/index.html
>
>
>--
>  Ned Deily
>  nad at python.org -- []
>

-- 
St?phane Wirtel - https://wirtel.be - @matrixise

From mhroncok at redhat.com  Sun Nov  4 16:58:49 2018
From: mhroncok at redhat.com (=?UTF-8?Q?Miro_Hron=c4=8dok?=)
Date: Sun, 4 Nov 2018 22:58:49 +0100
Subject: [Python-Dev] Get a running instance of the doc for a PR.
In-Reply-To: <20181104154957.GD12103@xps>
References: <20181104133827.GA25586@xps>
 <203B5254-326E-43EC-A80D-4A8147791A9D@python.org>
 <dCNWpHselG_mmIFYqAYmu_MD8TGQMlu4rmE68Fc3aPJvMldn-P4FnrRDP7J3AxG9H3QNPO4y1P_WE-OGAkn0iQgiqEuijK0Ezbzl40LzV68=@palard.fr>
 <prn3pb$h3l$1@blaine.gmane.org> <20181104154957.GD12103@xps>
Message-ID: <22297099-29ed-dbb2-ee69-e8c23af1a844@redhat.com>

On 04. 11. 18 16:49, Stephane Wirtel wrote:
> On 11/04, Serhiy Storchaka wrote:
>> 04.11.18 17:00, Julien Palard via Python-Dev ????:
>>> Considering feedback from Ned, what about building this as an 
>>> independent service? We don't really need to interface with 
>>> python.org at all, we just need some hardware, a domain, some code to 
>>> interface with github API and... to start it's probably enough? It 
>>> would be a usefull POC.
>>
>> This will just move risks to this service.
>>
>> Ned mentioned potential abuse. We will host unchecked content. 
>> Malicious user can create a PR which replaces Python documentation 
>> with malicious content.
> The content will be generated by the build/html directory from Travis.
> If Travis is green we upload the doc, if Travis is red, we do not
> publish it. If there is an abuse, we close/drop the PR, maybe Bedevere
> can receive this notification via the webhooks and notify the server to
> remove the doc.
>>
>> The Doc/ directory includes Python scripts and Makefile which are used 
>> for building documentation. Malicious user can use this for executing 
>> arbitrary code on our server.
> Currently, we use Travis. The malicious code will be execute in the
> container of Travis, not on the server. We only copy the static files
> and if we use nginx/apache, we don't execute the .py files. Just serve
> the .html,.css,.js files

Yet you need to let Travis CI know how to upload the results (HTML 
files) somewhere. That usually involves some kind of credentials.
You can secretly tell Travis the credentials, however somebody would be 
able to modify the Makefile (or anything else) to send the credentials 
to their webservice/e-mail/whatever.
That is in fact not possible, for exactly this reason: Travis CI builds 
from PRs don't see the "secret" stuff.

https://docs.travis-ci.com/user/environment-variables#defining-encrypted-variables-in-travisyml

-- 
Miro Hron?ok
--
Phone: +420777974800
IRC: mhroncok

From steve at pearwood.info  Sun Nov  4 17:38:36 2018
From: steve at pearwood.info (Steven D'Aprano)
Date: Mon, 5 Nov 2018 09:38:36 +1100
Subject: [Python-Dev] Get a running instance of the doc for a PR.
In-Reply-To: <261F41E1-7678-47CC-B40B-829F3ADB57BD@python.org>
References: <20181104133827.GA25586@xps>
 <010401d4745b$6fec9a90$4fc5cfb0$@sdamon.com>
 <26398c8f-170d-c468-b603-ea79ca8fdcc2@ganssle.io>
 <261F41E1-7678-47CC-B40B-829F3ADB57BD@python.org>
Message-ID: <20181104223836.GY3817@ando.pearwood.info>

On Sun, Nov 04, 2018 at 12:16:14PM -0500, Ned Deily wrote:

> On Nov 4, 2018, at 12:04, Paul Ganssle <paul at ganssle.io> wrote:
>
> > Some of the concerns about increasing the surface area I think are a 
> > bit overblown. I haven't seen any problems yet in the projects that 
> > do this,

You may or may not be right, but have you looked for problems or just 
assumed that because nobody has brought any to your attention, they 
don't exist?

"I have seen nothing" != "there is nothing to see".


> > and I don't think it lends itself to abuse particularly 
> > well. Considering that the rest of the CI suite lets you run 
> > arbitrary code on many platforms, I don't think it's particularly 
> > more dangerous to allow people to generate ephemeral static hosted 
> > web sites as well.
> 
> The rest of the CI suite does not let you publish things on the 
> python.org domain, unless I'm forgetting something; they're clearly 
> under a CI environment like Travis or AppVeyor or Azure.  That's 
> really my main concern.

Sorry Ned, I don't follow you here. It sounds like you're saying that 
you're fine with spam or abusive content being hosted in our name, so 
long as its hosted by somebody else, rather than by us (python.org) 
ourselves.

I trust I'm missing something, but I don't know what it is.


-- 
Steve

From steve at pearwood.info  Sun Nov  4 17:48:42 2018
From: steve at pearwood.info (Steven D'Aprano)
Date: Mon, 5 Nov 2018 09:48:42 +1100
Subject: [Python-Dev] Get a running instance of the doc for a PR.
In-Reply-To: <20181104160507.GF12103@xps>
References: <20181104133827.GA25586@xps>
 <203B5254-326E-43EC-A80D-4A8147791A9D@python.org>
 <20181104151239.GA14162@xps> <20181104155017.GX3817@ando.pearwood.info>
 <20181104160507.GF12103@xps>
Message-ID: <20181104224842.GZ3817@ando.pearwood.info>

On Sun, Nov 04, 2018 at 05:05:07PM +0100, Stephane Wirtel wrote:

> >If I am making doc patches, shouldn't I be doing that *before* I
> >submit the PR? How else will I know that my changes haven't broken the
> >docs?
>
> You can use the web interface of Github and just add/remove/modify a
> paragraph.

Does Github show a preview? If not, then my question still stands: how 
do I know my changes aren't broken?

If Github does show a preview, then couldn't the reviewer look at that 
too?


-- 
Steve

From paul at ganssle.io  Sun Nov  4 18:01:30 2018
From: paul at ganssle.io (Paul Ganssle)
Date: Sun, 4 Nov 2018 18:01:30 -0500
Subject: [Python-Dev] Get a running instance of the doc for a PR.
In-Reply-To: <20181104223836.GY3817@ando.pearwood.info>
References: <20181104133827.GA25586@xps>
 <010401d4745b$6fec9a90$4fc5cfb0$@sdamon.com>
 <26398c8f-170d-c468-b603-ea79ca8fdcc2@ganssle.io>
 <261F41E1-7678-47CC-B40B-829F3ADB57BD@python.org>
 <20181104223836.GY3817@ando.pearwood.info>
Message-ID: <156b2748-5a38-9cee-7700-b4891351a851@ganssle.io>


On 11/4/18 5:38 PM, Steven D'Aprano wrote:
> On Sun, Nov 04, 2018 at 12:16:14PM -0500, Ned Deily wrote:
>
>> On Nov 4, 2018, at 12:04, Paul Ganssle <paul at ganssle.io> wrote:
>>
>>> Some of the concerns about increasing the surface area I think are a 
>>> bit overblown. I haven't seen any problems yet in the projects that 
>>> do this,
> You may or may not be right, but have you looked for problems or just 
> assumed that because nobody has brought any to your attention, they 
> don't exist?
>
> "I have seen nothing" != "there is nothing to see".
>
I can only speak from my experience with setuptools, but I do look at
every setuptools PR and I've never seen anything even close to this.
That said, I have also never seen anyone using my Travis or Appveyor
instances to mine cryptocurrency, but I've been told that that happens.

In any case, I think the standard should not be "this never happens"
(otherwise you also can't run CI), but that it happens rarely enough
that it's not a major problem and that you can deal with it when it does
come up. Frankly, I think the much more likely target for these sorts of
attacks is small, mostly abandoned projects with very few followers. If
you post a spam site on some ephemeral domain via the CPython CI, it's
likely that hundreds of people will notice it just because it's a very
active project. You will be banned from the project for life and
probably reported to github nearly instantly. Likely you have much more
value for your time if you target some 1-star repo that set this up 2
years ago and is maintained by someone who hasn't committed to github in
over a year.

That said, big projects like CPython are probably more likely to attract
the troll version of this, where the point isn't to get away with
hosting some content or using the CI, but to annoy and disrupt the
project itself by wasting our resources chasing down spam or whatever. I
think if that isn't already happening with comment floods on the issue
tracker, GH threads and mailing lists, it's not especially /more/ likely
to happen because people can spin up a website with a PR.

>>> and I don't think it lends itself to abuse particularly 
>>> well. Considering that the rest of the CI suite lets you run 
>>> arbitrary code on many platforms, I don't think it's particularly 
>>> more dangerous to allow people to generate ephemeral static hosted 
>>> web sites as well.
>> The rest of the CI suite does not let you publish things on the 
>> python.org domain, unless I'm forgetting something; they're clearly 
>> under a CI environment like Travis or AppVeyor or Azure.  That's 
>> really my main concern.
> Sorry Ned, I don't follow you here. It sounds like you're saying that 
> you're fine with spam or abusive content being hosted in our name, so 
> long as its hosted by somebody else, rather than by us (python.org) 
> ourselves.
>
> I trust I'm missing something, but I don't know what it is.

I think there are two concerns - one is that the python.org domain is
generally (currently) used for official content. If people can put
arbitrary websites on there, presumably they can exploit whatever trust
people have put into this fact.

Another is that - and I am not a web expert here - I think that the
domain where content is hosted is used as a marker of trust between
different pages, and many applications will consider anything on
*.python.org to be first-party content from other *.python.org domains.?
I believe this is the reason why readthedocs moved all hosted
documentation from *.readthedocs.org to *.readthedocs.io. Similarly
user-submitted content on PyPI is usually hosted under the
pythonhosted.org domain, not pypi.org or pypi.python.org. You'll notice
that GH also hosts user content under a githubusercontent.org domain.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://mail.python.org/pipermail/python-dev/attachments/20181104/2db51fa2/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: OpenPGP digital signature
URL: <http://mail.python.org/pipermail/python-dev/attachments/20181104/2db51fa2/attachment.sig>

From vstinner at redhat.com  Sun Nov  4 18:48:42 2018
From: vstinner at redhat.com (Victor Stinner)
Date: Mon, 5 Nov 2018 00:48:42 +0100
Subject: [Python-Dev] Get a running instance of the doc for a PR.
In-Reply-To: <20181104133827.GA25586@xps>
References: <20181104133827.GA25586@xps>
Message-ID: <CA+3bQGGYbCQir1XcAqVTYuX0bURi3hcP+Nyy=-Jr0wr-Xz9pDQ@mail.gmail.com>

OpenStack does that on review.openstack.org PRs. If I recall correctly, the
CI produces files which are online on a static web server. Nothing crazy.
And it works. Old files are removed, I don't know when exactly.

I don't think that it matters where the static files are hosted.

Victor

Le dimanche 4 novembre 2018, Stephane Wirtel <stephane at wirtel.be> a ?crit :
> Hi all,
>
> When we receive a PR about the documentation, I think that could be
> interesting if we could have a running instance of the doc on a sub
> domain of python.org.
>
> For example, pr-10000-doc.python.org or whatever, but by this way the
> reviewers could see the result online.
>
> The workflow would be like that:
>
> New PR -> build the doc (done by Travis) -> publish it to a server ->
> once published, the PR is notified by "doc is available at URL".
>
> Once merged -> we remove the doc and the link (hello bedevere).
>
> I am interested by this feature and if you also interested, tell me.
> I would like discuss with Julien Palard and Ernest W.  Durbin III for a
> solution as soon as possible.
>
> Have a nice day,
>
> St?phane
>
> --
> St?phane Wirtel - https://wirtel.be - @matrixise
> _______________________________________________
> Python-Dev mailing list
> Python-Dev at python.org
> https://mail.python.org/mailman/listinfo/python-dev
> Unsubscribe:
https://mail.python.org/mailman/options/python-dev/vstinner%40redhat.com
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://mail.python.org/pipermail/python-dev/attachments/20181105/1fc1d192/attachment.html>

From sorin.sbarnea at gmail.com  Sun Nov  4 19:39:32 2018
From: sorin.sbarnea at gmail.com (Sorin Sbarnea)
Date: Mon, 5 Nov 2018 00:39:32 +0000
Subject: [Python-Dev] Get a running instance of the doc for a PR.
In-Reply-To: <CA+3bQGGYbCQir1XcAqVTYuX0bURi3hcP+Nyy=-Jr0wr-Xz9pDQ@mail.gmail.com>
References: <20181104133827.GA25586@xps>
 <CA+3bQGGYbCQir1XcAqVTYuX0bURi3hcP+Nyy=-Jr0wr-Xz9pDQ@mail.gmail.com>
Message-ID: <95112A17-AC0F-47F9-BC00-A431F02E2FA8@gmail.com>

I can confirm that this is what OpenStack does. Sometimes the build artifacts (logs, docs ...) are rotated in two weeks but this is more than enough to perform a review. If I remember well retention is based on disk space and not hardcoded to a number of days, which is great.

TBH, I don't really know how a human can check the docs if they cannot access them on a webserver.

I hope to see the same on python too, very useful.

> On 4 Nov 2018, at 23:48, Victor Stinner <vstinner at redhat.com> wrote:
> 
> OpenStack does that on review.openstack.org <http://review.openstack.org/> PRs. If I recall correctly, the CI produces files which are online on a static web server. Nothing crazy. And it works. Old files are removed, I don't know when exactly.
> 
> I don't think that it matters where the static files are hosted.
> 
> Victor
> 
> Le dimanche 4 novembre 2018, Stephane Wirtel <stephane at wirtel.be <mailto:stephane at wirtel.be>> a ?crit :
> > Hi all,
> >
> > When we receive a PR about the documentation, I think that could be
> > interesting if we could have a running instance of the doc on a sub
> > domain of python.org <http://python.org/>.
> >
> > For example, pr-10000-doc.python.org <http://pr-10000-doc.python.org/> or whatever, but by this way the
> > reviewers could see the result online.
> >
> > The workflow would be like that:
> >
> > New PR -> build the doc (done by Travis) -> publish it to a server ->
> > once published, the PR is notified by "doc is available at URL".
> >
> > Once merged -> we remove the doc and the link (hello bedevere).
> >
> > I am interested by this feature and if you also interested, tell me.
> > I would like discuss with Julien Palard and Ernest W.  Durbin III for a
> > solution as soon as possible.
> >
> > Have a nice day,
> >
> > St?phane
> >
> > --
> > St?phane Wirtel - https://wirtel.be <https://wirtel.be/> - @matrixise
> > _______________________________________________
> > Python-Dev mailing list
> > Python-Dev at python.org <mailto:Python-Dev at python.org>
> > https://mail.python.org/mailman/listinfo/python-dev <https://mail.python.org/mailman/listinfo/python-dev>
> > Unsubscribe: https://mail.python.org/mailman/options/python-dev/vstinner%40redhat.com <https://mail.python.org/mailman/options/python-dev/vstinner%40redhat.com>
> > _______________________________________________
> Python-Dev mailing list
> Python-Dev at python.org
> https://mail.python.org/mailman/listinfo/python-dev
> Unsubscribe: https://mail.python.org/mailman/options/python-dev/sorin.sbarnea%40gmail.com

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://mail.python.org/pipermail/python-dev/attachments/20181105/b61f6192/attachment.html>

From nad at python.org  Sun Nov  4 21:11:49 2018
From: nad at python.org (Ned Deily)
Date: Sun, 4 Nov 2018 21:11:49 -0500
Subject: [Python-Dev] Get a running instance of the doc for a PR.
In-Reply-To: <95112A17-AC0F-47F9-BC00-A431F02E2FA8@gmail.com>
References: <20181104133827.GA25586@xps>
 <CA+3bQGGYbCQir1XcAqVTYuX0bURi3hcP+Nyy=-Jr0wr-Xz9pDQ@mail.gmail.com>
 <95112A17-AC0F-47F9-BC00-A431F02E2FA8@gmail.com>
Message-ID: <8064CA01-718F-4229-9772-96017B299476@python.org>

Not to belabor the point but:

On Nov 4, 2018, at 19:39, Sorin Sbarnea <sorin.sbarnea at gmail.com> wrote:
> TBH, I don't really know how a human can check the docs if they cannot access them on a webserver.

It's actually trivially easy with the Python doc set because the docs were designed to also be downloadable and usable off-line.  That is, the same files html, js, css, and other resources that get built and loaded onto the website can also be just browsed directly from a file system, like:

firefox Doc/build/html/index.html

or, say, using the Open File command in Safari or whatever.  No web server is needed.

The docsets for the heads of each of the active branches are built and packaged nightly and downloadable from python.org:

https://docs.python.org/3/download.html

Also, archive copies of the docset at the time of each release is downloadable from here:

https://www.python.org/doc/versions/

There are built using the same Doc/Makefile found in the cpython repo branches and the resulting Doc/build/html directory contains the docset for that snapshot of the repo with every file in the proper location for the webbrowser to load directly.

--
  Ned Deily
  nad at python.org -- []


From pierre.glaser at inria.fr  Mon Nov  5 06:30:39 2018
From: pierre.glaser at inria.fr (Pierre Glaser)
Date: Mon, 5 Nov 2018 12:30:39 +0100
Subject: [Python-Dev] PEP 574 -- Pickle protocol 5 with out-of-band data
In-Reply-To: <34eaf991-fb6c-c540-ea6d-e7b6267df34f@gmail.com>
References: <34eaf991-fb6c-c540-ea6d-e7b6267df34f@gmail.com>
Message-ID: <f25cec8d-6d63-caf5-d9b6-aab3af86ac32@inria.fr>

Hi All,
As part of our scikit-learn development and our effort to provide better 
parallelism for python, we rely heavily on dynamic classes and functions 
pickling. For this
usage we use cloudpickle, but it suffers from performance issues due to 
its pure python implementation. After long discussions with Olivier 
Grisel and Thomas
Moreau, we ended up agreeing on the fact that the best solution for this 
problem would be to add those functionalities to the _pickle.c module.
I am already quite familiar with the C/Python API, and can dedicate a 
lot of my time in the next couple months to make this happen.

Serhiy, from this thread 
(https://mail.python.org/pipermail/python-dev/2018-March/152509.html), 
it seems that you already started implementing local classes pickling.
I would be happy to use this work as a starting point and build from it. 
What do you think?

Regards,

Pierre


From pierre.glaser at inria.fr  Mon Nov  5 06:36:50 2018
From: pierre.glaser at inria.fr (Pierre Glaser)
Date: Mon, 5 Nov 2018 12:36:50 +0100
Subject: [Python-Dev] PEP 574 -- Pickle protocol 5 with out-of-band data
In-Reply-To: <34eaf991-fb6c-c540-ea6d-e7b6267df34f@gmail.com>
References: <34eaf991-fb6c-c540-ea6d-e7b6267df34f@gmail.com>
Message-ID: <80f765f2-850f-76c7-3ba1-3a5ca2c87701@inria.fr>

Hi All,
As part of our scikit-learn development and our effort to provide better 
parallelism for python, we rely heavily on dynamic classes and functions 
pickling. For this
usage we use cloudpickle, but it suffers from performance issues due to 
its pure python implementation. After long discussions with Olivier 
Grisel and Thomas
Moreau, we ended up agreeing on the fact that the best solution for this 
problem would be to add those functionalities to the _pickle.c module.
I am already quite familiar with the C/Python API, and can dedicate a 
lot of my time in the next couple months to make this happen.

Serhiy, from this thread 
(https://mail.python.org/pipermail/python-dev/2018-March/152509.html), 
it seems that you already started implementing local classes pickling.
I would be happy to use this work as a starting point and build from it. 
What do you think?

Regards,

Pierre


From vstinner at redhat.com  Tue Nov  6 10:09:09 2018
From: vstinner at redhat.com (Victor Stinner)
Date: Tue, 6 Nov 2018 16:09:09 +0100
Subject: [Python-Dev] What is the difference between Py_BUILD_CORE and
 Py_BUILD_CORE_BUILTIN?
Message-ID: <CA+3bQGFskgwBf-m5kL6EkP22+Z_51s4sPCcoH4=T2Wmfge=ZrQ@mail.gmail.com>

Hi,

I'm trying to cleanup the Python C API, especially strictly separate
the public C API, the stable C API (Py_LIMITED_API), and the internal
C API (Py_BUILD_CORE).

Move internal headers to Include/internal/ :
https://bugs.python.org/issue35081

Move !Py_LIMITED_API to Include/pycapi/:
https://bugs.python.org/issue35134

I tried to ensure that Py_BUILD_CORE is defined when including
pycore_xxx.h headers from Include/internal/, but the compilation of
the _json module fails. Modules/_json.c contains:

/* Core extension modules are built-in on some platforms (e.g. Windows). */
#ifdef Py_BUILD_CORE
#define Py_BUILD_CORE_BUILTIN
#undef Py_BUILD_CORE
#endif

I don't understand the difference between Py_BUILD_CORE and
Py_BUILD_CORE_BUILTIN defines. Do we need to have two different
defines? Can't we compile _json with Py_BUILD_CORE?

_json.c uses pycore_accu.h:

/*
 * A two-level accumulator of unicode objects that avoids both the overhead
 * of keeping a huge number of small separate objects, and the quadratic
 * behaviour of using a naive repeated concatenation scheme.
 */

Is it a problem of the visibility/scope of symbols in the python DLL on Windows?

Victor

From srinivasan.rns at gmail.com  Tue Nov  6 13:07:40 2018
From: srinivasan.rns at gmail.com (srinivasan)
Date: Tue, 6 Nov 2018 23:37:40 +0530
Subject: [Python-Dev] SyntaxError: can't assign to literal while using
 ""blkid -o export %s | grep 'TYPE' | cut -d"=" -f3" % (fs)" using
 subprocess module in Python
Message-ID: <CAFsTbWd8saSbGSBtfDc3=TssZwgsB=j6b==ct195gVkJH84EpA@mail.gmail.com>

Dear Python Experts Team,

As am newbie to python development, I am trying to use the below function
to get verify the filesystem type of the SD card parition using bash
command in python using subprocess module, I ma seeing the below Error
"SyntaxError: can't assign to literal"

*CODE:*
*====*

import helper
from os import path
import subprocess
import os
import otg_ni


class emmc(object):
    """
        emmc getters and setters
        info:
https://www.kernel.org/doc/Documentation/cpu-freq/user-guide.txt
    """

    def __init__(self):
        self._helper = helper.helper()
        self._otg_ni = otg_ni.otg_ni()


*def get_fstype_of_mounted_partition(self, fs):*
        """
            Get the filesystem type of the mounted partition.

            :partition_name : Partition path as string (e.g. /dev/mmcblk0p1)
            :return: filesystem type as string or None if not found
        """

*        cmd = "blkid -o export %s | grep 'TYPE' | cut -d"=" -f3" % (fs)*
        *return self._helper.execute_cmd_output_string(cmd)*



*def execute_cmd_output_string(self, cmd, enable_shell=False):*
        """
            Execute a command and return its output as a string.

            :param cmd: abs path of the command with arguments
            :param enable_shell : force the cmd to be run as shell script
            :return: a string.
        """

        try:
            result = subprocess.check_output(split(cmd),
                                             stderr=subprocess.STDOUT,
                                             shell=enable_shell)

        except subprocess.CalledProcessError as e:
            s = """While executing '{}' something went wrong.
                Return code == '{}'
                Return output:\n'{}'
                """.format(cmd, e.returncode, e.output, shell=enable_shell)
            raise AssertionError(s)

        return result.strip().decode("utf-8")
*if __name__ == "__main__":*
    m = emmc()
*    m.get_fstype_of_mounted_partition("/dev/mmcblk0p1")*
*Error:*
*======*

root:~/qa/test_library# python3 sd.py
  File "sd.py", line 99
*    cmd = "blkid -o export %s | grep 'TYPE' | cut -d"=" -f3" % (fs)*
*         ^*
*SyntaxError: can't assign to literal*
root:~/qa/test_library#

Kindly do the needful as early as possible, as am stuck with this issue
from past 2 days no clues yet, please redirect me to the correct forum if
this is not the right place for pasting python related queries

Many Thanks in advance,
Srini
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://mail.python.org/pipermail/python-dev/attachments/20181106/5c4b2d58/attachment.html>

From ericsnowcurrently at gmail.com  Tue Nov  6 13:13:19 2018
From: ericsnowcurrently at gmail.com (Eric Snow)
Date: Tue, 6 Nov 2018 11:13:19 -0700
Subject: [Python-Dev] Rename Include/internals/ to Include/pycore/
In-Reply-To: <CA+3bQGHoS+uToYCa=fLtPzDLdBmDu+f8EU0EFOhwCfu92rh3tA@mail.gmail.com>
References: <CA+3bQGE7UriagGc_FYuM7ge5oGX+6+_w2c3HY1WDj8JY=6FuzQ@mail.gmail.com>
 <1540759207.1168671.1557524968.5CFA99F3@webmail.messagingengine.com>
 <20181102172238.u7ysgkpj2b7aids5@python.ca>
 <CA+3bQGHoS+uToYCa=fLtPzDLdBmDu+f8EU0EFOhwCfu92rh3tA@mail.gmail.com>
Message-ID: <CALFfu7Aea_oeXuTgdsT7thjLoiD+0PjJUSUeztzyJ9=ofwh2cQ@mail.gmail.com>

On Fri, Nov 2, 2018 at 1:02 PM Victor Stinner <vstinner at redhat.com> wrote:
>
> Le ven. 2 nov. 2018 ? 18:32, Neil Schemenauer <nas-python at arctrix.com> a ?crit :
> > A simple approach would be to introduce something like
> > Python-internal.h.  If you are a Python internal unit, you can
> > include both Python.h and Python-internal.h.  We could, over time,
> > split Python-iternal.h into smaller modular includes.
>
> Since this discussion, I already moved most Py_BUILD_CORE in
> Include/internal/. I added a lot of #include "pycore_xxx.h" in C
> files.
>
> I started to reach the limit with this PR which adds the
> pycore_object.h include to not less than 33 C files:
> https://github.com/python/cpython/pull/10272
>
> I rewrote this PR to avoid the need to modify 33 C files:
> https://github.com/python/cpython/pull/10276/files
>
> I added the following code to Python.h:
>
> #ifdef Py_BUILD_CORE
> /* bpo-35081: Automatically include pycore_object.h in Python.h, to avoid
> to have to add an explicit #include "pycore_object.h" to each C file. */
> # include "pycore_object.h"
> #endif
>
> I'm not sure of it's a temporary workaround or not :-) Maybe a
> Python-internal.h would be a better solution? We can identify the most
> common header files needed to access "Python internals" and put them
> in this "common" header file.
>
> For example, most C files using Python internals have to access
> _PyRuntime global variable (55 C files), so "pycore_state.h" is a good
> candidate.

FWIW, I'm still in favor of keeping the includes specific.  For me
personally it helps to narrow down dependencies, making the source
easier to follow.

> By the way, I don't understand the rationale to have _PyRuntime in
> pycore_state.h. IMHO pycore_state.h should only contain functions to
> get the Python thread and Python interpreter states. IMHO _PyRuntime
> is unrelated and should belong to a different header file, maybe
> pycore_runtime.h? I didn't do this change yet *because* I would have
> to modify the 55 files currently including it.

The runtime state isn't all that different from the thread state or
the interpreter state.  It's simply broader in scope, much like the
interpreter state is broader in scope than the thread state.  That's
why I put it where I did.

-eric

From rosuav at gmail.com  Tue Nov  6 13:15:21 2018
From: rosuav at gmail.com (Chris Angelico)
Date: Wed, 7 Nov 2018 05:15:21 +1100
Subject: [Python-Dev] SyntaxError: can't assign to literal while using
 ""blkid -o export %s | grep 'TYPE' | cut -d"=" -f3" % (fs)" using
 subprocess module in Python
In-Reply-To: <CAFsTbWd8saSbGSBtfDc3=TssZwgsB=j6b==ct195gVkJH84EpA@mail.gmail.com>
References: <CAFsTbWd8saSbGSBtfDc3=TssZwgsB=j6b==ct195gVkJH84EpA@mail.gmail.com>
Message-ID: <CAPTjJmr6TSX-jX03EC-O9cDPYiY-tF_p6pKBan3bnpoCQGQxoA@mail.gmail.com>

On Wed, Nov 7, 2018 at 5:11 AM srinivasan <srinivasan.rns at gmail.com> wrote:
> As am newbie to python development, I am trying to use the below function to get verify the filesystem type of the SD card parition using bash command in python using subprocess module, I ma seeing the below Error "SyntaxError: can't assign to literal"
>

This is more appropriate for python-list than for python-dev, which is
about the development OF Python. But your problem here is quite
simple:

>         cmd = "blkid -o export %s | grep 'TYPE' | cut -d"=" -f3" % (fs)

You're trying to use the same quotation mark inside the string and
outside it. That's not going to work. Try removing your inner quotes.

You may also want to consider using Python to do your searching and
cutting, rather than a shell pipeline. For more information on that,
ask on python-list; people will be very happy to help out.

ChrisA

From ericsnowcurrently at gmail.com  Tue Nov  6 13:19:17 2018
From: ericsnowcurrently at gmail.com (Eric Snow)
Date: Tue, 6 Nov 2018 11:19:17 -0700
Subject: [Python-Dev] What is the difference between Py_BUILD_CORE and
 Py_BUILD_CORE_BUILTIN?
In-Reply-To: <CA+3bQGFskgwBf-m5kL6EkP22+Z_51s4sPCcoH4=T2Wmfge=ZrQ@mail.gmail.com>
References: <CA+3bQGFskgwBf-m5kL6EkP22+Z_51s4sPCcoH4=T2Wmfge=ZrQ@mail.gmail.com>
Message-ID: <CALFfu7Ad63CzVeoSN2favRHJaZs20YUsmBbfRHp1Xbz9ANh9Mg@mail.gmail.com>

On Tue, Nov 6, 2018 at 8:09 AM Victor Stinner <vstinner at redhat.com> wrote:
> I don't understand the difference between Py_BUILD_CORE and
> Py_BUILD_CORE_BUILTIN defines. Do we need to have two different
> defines? Can't we compile _json with Py_BUILD_CORE?
>
> [snip]
>
> Is it a problem of the visibility/scope of symbols in the python DLL on Windows?

Yep.  I added Py_BUILD_CORE_BUILTIN as a workaround for building on
Windows.  For extension modules on Windows there's a conflict between
Py_BUILD_CORE and some of the Windows symbols that get defined.  My
Windows build knowledge is pretty limited so that's about as far as I
can go. :)  Steve might be able to give you more info.

-eric

From david at graniteweb.com  Tue Nov  6 13:33:59 2018
From: david at graniteweb.com (David Rock)
Date: Tue, 6 Nov 2018 12:33:59 -0600
Subject: [Python-Dev] [Tutor] SyntaxError: can't assign to literal while
 using ""blkid -o export %s | grep 'TYPE' | cut -d"=" -f3" % (fs)" using
 subprocess module in Python
In-Reply-To: <CAFsTbWd8saSbGSBtfDc3=TssZwgsB=j6b==ct195gVkJH84EpA@mail.gmail.com>
References: <CAFsTbWd8saSbGSBtfDc3=TssZwgsB=j6b==ct195gVkJH84EpA@mail.gmail.com>
Message-ID: <C5B8E015-27C4-44B1-94D1-4E9BE8B393BF@graniteweb.com>

> 
> *def get_fstype_of_mounted_partition(self, fs):*
>        """
>            Get the filesystem type of the mounted partition.
> 
>            :partition_name : Partition path as string (e.g. /dev/mmcblk0p1)
>            :return: filesystem type as string or None if not found
>        """
> 
> *        cmd = "blkid -o export %s | grep 'TYPE' | cut -d"=" -f3" % (fs)*
>        *return self._helper.execute_cmd_output_string(cmd)*
> 
> 
> 
> root:~/qa/test_library# python3 sd.py
>  File "sd.py", line 99
> *    cmd = "blkid -o export %s | grep 'TYPE' | cut -d"=" -f3" % (fs)*
> *         ^*
> *SyntaxError: can't assign to literal*
> root:~/qa/test_library#
> 

looking at
 cmd = "blkid -o export %s | grep 'TYPE' | cut -d"=" -f3" % (fs)*

It?s probably because you have ? characters that are inside ? characters and it can?t tell where the string ends. It looks like you are trying to do

cmd = "blkid -o export %s | grep 'TYPE' | cut -d?      =      " -f3" % (fs)*

which doesn?t make sense.  Try using triple quotes instead so it?s clear what string you are trying to use.

cmd = ?""blkid -o export %s | grep 'TYPE' | cut -d"=" -f3?"" % (fs)


? 
David Rock
david at graniteweb.com





From steve at pearwood.info  Tue Nov  6 17:25:51 2018
From: steve at pearwood.info (Steven D'Aprano)
Date: Wed, 7 Nov 2018 09:25:51 +1100
Subject: [Python-Dev] SyntaxError: can't assign to literal while using
 ""blkid -o export %s | grep 'TYPE' | cut -d"=" -f3" % (fs)" using
 subprocess module in Python
In-Reply-To: <CAFsTbWd8saSbGSBtfDc3=TssZwgsB=j6b==ct195gVkJH84EpA@mail.gmail.com>
References: <CAFsTbWd8saSbGSBtfDc3=TssZwgsB=j6b==ct195gVkJH84EpA@mail.gmail.com>
Message-ID: <20181106222551.GA4071@ando.pearwood.info>

This list is for the development *of* the Python interpreter, not 
support for *using* Python. If you signed up to this mailing list via 
the web, it clearly says:

    Do not post general Python questions to this list.

highlighted in a great big box in red. Was that not clear enough? What 
can we do to make that more clear?

You can try many other places for support, such as Stackoverflow, 
Reddit's /r/LearnPython, or the Python tutor mailing list:

https://mail.python.org/mailman/listinfo/tutor

but I expect most of them will tell you the same thing. You should try 
to give a *minimum* example of your problem, not your entire script. 
Start by reading here:

http://sscce.org/

As for your SyntaxError, the problem is line 99:

>   File "sd.py", line 99
> *    cmd = "blkid -o export %s | grep 'TYPE' | cut -d"=" -f3" % (fs)*
> *         ^*
> *SyntaxError: can't assign to literal*

The arrow ^ is pointing to the wrong equals sign, but simplifying the 
code and adding spaces makes it clear:

cmd = "spam" = "eggs"

gives the same error. Perhaps you mean == (equals) or perhaps the second 
assignment shouldn't be there at all?



-- 
Steve

From justinarthur at gmail.com  Wed Nov  7 23:24:55 2018
From: justinarthur at gmail.com (Justin Turner Arthur)
Date: Wed, 7 Nov 2018 22:24:55 -0600
Subject: [Python-Dev] Implementing an awaitable
Message-ID: <CAN5awxg0N=gaCmQxwujd-fdqWxkVT5eGm7MzQS+UcdGLrTKqug@mail.gmail.com>

I'm trying to figure out if our documentation on the new awaitable concept
in Python 3.6+ is correct. It seems to imply that if an object's __await__
method returns an iterator, the object is awaitable. However, just
returning an iterator doesn't seem to work with await in a coroutine or
with the asyncio selector loop's run_until_complete method.

If the awaitable is not a coroutine or future, it looks like we wrap it in
a coroutine using sub-generator delegation, and therefore have to have an
iterator that fits a very specific shape for the coroutine step process
that isn't documented anywhere I could find. Am I missing something?

If the definition of an awaitable is more than just an __await__ iterator,
we may need to expand the documentation as well as the abstract base class.

Here's what I tried in making a synchronous awaitable that resolves to the
int 42:
class MyAwaitable(Awaitable):
    def __await__(self):
        return iter((42,))
# RuntimeError: Task got bad yield: 42

class MyAwaitable(Awaitable):
    def __await__(self):
        yield 42
# RuntimeError: Task got bad yield: 42

class MyAwaitable(Awaitable):
    def __await__(self):
        return (i for i in (42,))
# RuntimeError: Task got bad yield: 42

class MyAwaitable(Awaitable):
    def __await__(self):
        return self
    def __next__(self):
        return 42
# RuntimeError: Task got bad yield: 42'''

class MyAwaitable(Awaitable):
    def __await__(self):
        return iter(asyncio.coroutine(lambda: 42)())
# TypeError: __await__() returned a coroutine

class MyAwaitable(Awaitable):
    def __await__(self):
        yield from asyncio.coroutine(lambda: 42)()
# None

class MyAwaitable(Awaitable):
    def __await__(self):
        return (yield from asyncio.coroutine(lambda: 42)())
# 42

async def await_things():
    print(await MyAwaitable())

asyncio.get_event_loop().run_until_complete(await_things())
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://mail.python.org/pipermail/python-dev/attachments/20181107/e2f7ee2d/attachment.html>

From njs at pobox.com  Thu Nov  8 00:26:59 2018
From: njs at pobox.com (Nathaniel Smith)
Date: Wed, 7 Nov 2018 21:26:59 -0800
Subject: [Python-Dev] Implementing an awaitable
In-Reply-To: <CAN5awxg0N=gaCmQxwujd-fdqWxkVT5eGm7MzQS+UcdGLrTKqug@mail.gmail.com>
References: <CAN5awxg0N=gaCmQxwujd-fdqWxkVT5eGm7MzQS+UcdGLrTKqug@mail.gmail.com>
Message-ID: <CAPJVwBmGKaPhE7QQ5_QM9o23H1T26LwnrgLt2Wbd0=LoqcdsUg@mail.gmail.com>

"Awaitable" is a language-level concept. To actually use awaitables,
you also need a coroutine runner library, and each library defines
additional restrictions on the awaitables it works with. So e.g. when
using asyncio as your coroutine runner, asyncio expects your
awaitables to follow particular rules about what values they yield,
what kinds of values they can handle being sent/thrown back in, etc.
Different async libraries use different rules here.

Asyncio's rules aren't documented, I guess because it's such a
low-level thing that anyone who really needs to know is expected to
read the source :-). (In particular asyncio/futures.py and
asyncio/tasks.py.) But it's basically: the object returned by
__await__ has to implement the generator interface (which is a
superset of the iterator interface), the objects yielded by your
iterator have to implement the Future interface, and then you're
resumed either by sending back None when the Future completes, or else
by having an exception thrown in.

-n

On Wed, Nov 7, 2018 at 8:24 PM, Justin Turner Arthur
<justinarthur at gmail.com> wrote:
> I'm trying to figure out if our documentation on the new awaitable concept
> in Python 3.6+ is correct. It seems to imply that if an object's __await__
> method returns an iterator, the object is awaitable. However, just returning
> an iterator doesn't seem to work with await in a coroutine or with the
> asyncio selector loop's run_until_complete method.
>
> If the awaitable is not a coroutine or future, it looks like we wrap it in a
> coroutine using sub-generator delegation, and therefore have to have an
> iterator that fits a very specific shape for the coroutine step process that
> isn't documented anywhere I could find. Am I missing something?
>
> If the definition of an awaitable is more than just an __await__ iterator,
> we may need to expand the documentation as well as the abstract base class.
>
> Here's what I tried in making a synchronous awaitable that resolves to the
> int 42:
> class MyAwaitable(Awaitable):
>     def __await__(self):
>         return iter((42,))
> # RuntimeError: Task got bad yield: 42
>
> class MyAwaitable(Awaitable):
>     def __await__(self):
>         yield 42
> # RuntimeError: Task got bad yield: 42
>
> class MyAwaitable(Awaitable):
>     def __await__(self):
>         return (i for i in (42,))
> # RuntimeError: Task got bad yield: 42
>
> class MyAwaitable(Awaitable):
>     def __await__(self):
>         return self
>     def __next__(self):
>         return 42
> # RuntimeError: Task got bad yield: 42'''
>
> class MyAwaitable(Awaitable):
>     def __await__(self):
>         return iter(asyncio.coroutine(lambda: 42)())
> # TypeError: __await__() returned a coroutine
>
> class MyAwaitable(Awaitable):
>     def __await__(self):
>         yield from asyncio.coroutine(lambda: 42)()
> # None
>
> class MyAwaitable(Awaitable):
>     def __await__(self):
>         return (yield from asyncio.coroutine(lambda: 42)())
> # 42
>
> async def await_things():
>     print(await MyAwaitable())
>
> asyncio.get_event_loop().run_until_complete(await_things())
>
>
> _______________________________________________
> Python-Dev mailing list
> Python-Dev at python.org
> https://mail.python.org/mailman/listinfo/python-dev
> Unsubscribe:
> https://mail.python.org/mailman/options/python-dev/njs%40pobox.com
>



-- 
Nathaniel J. Smith -- https://vorpus.org

From justinarthur at gmail.com  Thu Nov  8 01:05:26 2018
From: justinarthur at gmail.com (Justin Turner Arthur)
Date: Thu, 8 Nov 2018 00:05:26 -0600
Subject: [Python-Dev] Implementing an awaitable
In-Reply-To: <CAPJVwBmGKaPhE7QQ5_QM9o23H1T26LwnrgLt2Wbd0=LoqcdsUg@mail.gmail.com>
References: <CAN5awxg0N=gaCmQxwujd-fdqWxkVT5eGm7MzQS+UcdGLrTKqug@mail.gmail.com>
 <CAPJVwBmGKaPhE7QQ5_QM9o23H1T26LwnrgLt2Wbd0=LoqcdsUg@mail.gmail.com>
Message-ID: <CAN5awxg0TjMW60CU4BSV8cEiwqg1Du-nFkYJY=L91PdOZAmufA@mail.gmail.com>

Thanks for the thorough rundown, Nathaniel. I started to get an idea of the
required shape only by looking at CPython code like you suggest. I wanted
to create an awaitable compatible with asyncio and trio that could be
awaited more than once unlike a coroutine, and not runner-specific like a
Future or Deferred. Are coroutines the only common awaitable the various
async libraries are going to have for now?

I'll take Python documentation suggestions up with other channels.
- Justin

On Wed, Nov 7, 2018 at 11:27 PM Nathaniel Smith <njs at pobox.com> wrote:

> "Awaitable" is a language-level concept. To actually use awaitables,
> you also need a coroutine runner library, and each library defines
> additional restrictions on the awaitables it works with. So e.g. when
> using asyncio as your coroutine runner, asyncio expects your
> awaitables to follow particular rules about what values they yield,
> what kinds of values they can handle being sent/thrown back in, etc.
> Different async libraries use different rules here.
>
> Asyncio's rules aren't documented, I guess because it's such a
> low-level thing that anyone who really needs to know is expected to
> read the source :-). (In particular asyncio/futures.py and
> asyncio/tasks.py.) But it's basically: the object returned by
> __await__ has to implement the generator interface (which is a
> superset of the iterator interface), the objects yielded by your
> iterator have to implement the Future interface, and then you're
> resumed either by sending back None when the Future completes, or else
> by having an exception thrown in.
>
> -n
>
> On Wed, Nov 7, 2018 at 8:24 PM, Justin Turner Arthur
> <justinarthur at gmail.com> wrote:
> > I'm trying to figure out if our documentation on the new awaitable
> concept
> > in Python 3.6+ is correct. It seems to imply that if an object's
> __await__
> > method returns an iterator, the object is awaitable. However, just
> returning
> > an iterator doesn't seem to work with await in a coroutine or with the
> > asyncio selector loop's run_until_complete method.
> >
> > If the awaitable is not a coroutine or future, it looks like we wrap it
> in a
> > coroutine using sub-generator delegation, and therefore have to have an
> > iterator that fits a very specific shape for the coroutine step process
> that
> > isn't documented anywhere I could find. Am I missing something?
> >
> > If the definition of an awaitable is more than just an __await__
> iterator,
> > we may need to expand the documentation as well as the abstract base
> class.
> >
> > Here's what I tried in making a synchronous awaitable that resolves to
> the
> > int 42:
> > class MyAwaitable(Awaitable):
> >     def __await__(self):
> >         return iter((42,))
> > # RuntimeError: Task got bad yield: 42
> >
> > class MyAwaitable(Awaitable):
> >     def __await__(self):
> >         yield 42
> > # RuntimeError: Task got bad yield: 42
> >
> > class MyAwaitable(Awaitable):
> >     def __await__(self):
> >         return (i for i in (42,))
> > # RuntimeError: Task got bad yield: 42
> >
> > class MyAwaitable(Awaitable):
> >     def __await__(self):
> >         return self
> >     def __next__(self):
> >         return 42
> > # RuntimeError: Task got bad yield: 42'''
> >
> > class MyAwaitable(Awaitable):
> >     def __await__(self):
> >         return iter(asyncio.coroutine(lambda: 42)())
> > # TypeError: __await__() returned a coroutine
> >
> > class MyAwaitable(Awaitable):
> >     def __await__(self):
> >         yield from asyncio.coroutine(lambda: 42)()
> > # None
> >
> > class MyAwaitable(Awaitable):
> >     def __await__(self):
> >         return (yield from asyncio.coroutine(lambda: 42)())
> > # 42
> >
> > async def await_things():
> >     print(await MyAwaitable())
> >
> > asyncio.get_event_loop().run_until_complete(await_things())
> >
> >
> > _______________________________________________
> > Python-Dev mailing list
> > Python-Dev at python.org
> > https://mail.python.org/mailman/listinfo/python-dev
> > Unsubscribe:
> > https://mail.python.org/mailman/options/python-dev/njs%40pobox.com
> >
>
>
>
> --
> Nathaniel J. Smith -- https://vorpus.org
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://mail.python.org/pipermail/python-dev/attachments/20181108/6e8bcb58/attachment.html>

From steve at pearwood.info  Fri Nov  9 06:05:07 2018
From: steve at pearwood.info (Steven D'Aprano)
Date: Fri, 9 Nov 2018 22:05:07 +1100
Subject: [Python-Dev] Signalling NANs
Message-ID: <20181109110507.GK4071@ando.pearwood.info>

I'm trying to understand some unexpected behaviour with float NANs in 
Python 3.5.

Background: in IEEE-754 maths, NANs (Not A Number) come in two flavours, 
so called "quiet NANs" and "signalling NANs". By default, arithmetic 
operations on qnans return a qnan; operations on snans "signal", which 
in Python terms means raising an exception.

The original IEEE-754 standard didn't specify how to distinguish a qnan 
from a snan, but a de facto standard arose that bit 51 of the float was 
the "quiet bit", if it were set, the NAN was quiet.

For the purposes of this email, I'm going to assume that standard is in 
place, even though technically speaking it is platform-dependent.

According to my tests, it seems that we cannot create snans in Python. 
The float constructor doesn't recognise "snan", raising ValueError. Nor 
can we convert a Decimal snan into a float:

py> from decimal import Decimal
py> snan = Decimal('snan')
py> float(dsnan)
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
ValueError: cannot convert signaling NaN to float


But unexpectedly (to me at least), we apparently cannot even create a 
signalling NAN by casting 64 bits to a float. Here are the functions I 
use to do the cast:

from struct import pack, unpack

def cast_float2int(x):
    return unpack('<Q', pack('<d', x))[0]

def cast_int2float(i):
    return unpack('<d', pack('<Q', i))[0]



Here's a regular quiet NAN round-tripping, as expected:

py> x = cast_int2float(0x7ff8000000000001)
py> x
nan
py> hex(cast_float2int(x))
'0x7ff8000000000001'


So far so good. But now let me try with a signalling NAN:


py> x = cast_int2float(0x7ff0000000000001)
py> x
nan
py> hex(cast_float2int(x))
'0x7ff8000000000001'


So it seems that the "quiet" bit is automatically set, even when using 
the struct module, making it impossible to create snan floats.

Is this intended? If so, why?

Is this meant as a language feature?



Thanks in advance,


Steve

From storchaka at gmail.com  Fri Nov  9 06:46:12 2018
From: storchaka at gmail.com (Serhiy Storchaka)
Date: Fri, 9 Nov 2018 13:46:12 +0200
Subject: [Python-Dev] Signalling NANs
In-Reply-To: <20181109110507.GK4071@ando.pearwood.info>
References: <20181109110507.GK4071@ando.pearwood.info>
Message-ID: <ps3ru2$h6s$1@blaine.gmane.org>

09.11.18 13:05, Steven D'Aprano ????:
> py> x = cast_int2float(0x7ff0000000000001)
> py> x
> nan
> py> hex(cast_float2int(x))
> '0x7ff8000000000001'

I got '0x7ff0000000000001'.


From status at bugs.python.org  Fri Nov  9 12:09:53 2018
From: status at bugs.python.org (Python tracker)
Date: Fri,  9 Nov 2018 18:09:53 +0100 (CET)
Subject: [Python-Dev] Summary of Python tracker Issues
Message-ID: <20181109170953.393015789C@psf.upfronthosting.co.za>


ACTIVITY SUMMARY (2018-11-02 - 2018-11-09)
Python tracker at https://bugs.python.org/

To view or respond to any of the issues listed below, click on the issue.
Do NOT respond to this message.

Issues counts and deltas:
  open    6834 ( +6)
  closed 40118 (+47)
  total  46952 (+53)

Open issues with patches: 2726 


Issues opened (42)
==================

#10536: Enhancements to gettext docs
https://bugs.python.org/issue10536  reopened by serhiy.storchaka

#32409: venv activate.bat is UTF-8 encoded but uses current console co
https://bugs.python.org/issue32409  reopened by pablogsal

#33486: regen autotools related files
https://bugs.python.org/issue33486  reopened by ned.deily

#34011: Default preference not given to venv DLL's
https://bugs.python.org/issue34011  reopened by pablogsal

#35145: sqlite3: "select *" should optionally sniff and autoconvert TE
https://bugs.python.org/issue35145  reopened by matrixise

#35149: pip3 show causing Error for  ConfigParaser
https://bugs.python.org/issue35149  opened by mdileep

#35151: Python 2 xml.etree.ElementTree documentation tutorial uses und
https://bugs.python.org/issue35151  opened by epakai

#35153: Allow to set headers in xmlrpc.client.ServerProxy
https://bugs.python.org/issue35153  opened by ced

#35155: Clarify Protocol Handlers in urllib.request Docs
https://bugs.python.org/issue35155  opened by Denton-L

#35156: Consider revising documentation on Python Builds from source
https://bugs.python.org/issue35156  opened by neyuru

#35157: Missing pyconfig.h when building from source and pgo flag is e
https://bugs.python.org/issue35157  opened by neyuru

#35158: Fix PEP 3115 to NOT imply that the class dictionary is used in
https://bugs.python.org/issue35158  opened by joydiamond

#35163: locale: setlocale(..., 'eo') sets non-existing locale
https://bugs.python.org/issue35163  opened by carmenbianca

#35164: socket.getfqdn and socket.gethostbyname fail on MacOS
https://bugs.python.org/issue35164  opened by ssbarnea

#35165: Possible wrong method name in attribute references doc
https://bugs.python.org/issue35165  opened by denis-osipov

#35166: BUILD_MAP_UNPACK doesn't function as expected for dict subclas
https://bugs.python.org/issue35166  opened by bup

#35168: shlex punctuation_chars inconsistency
https://bugs.python.org/issue35168  opened by tphh

#35169: Improve error messages for assignment
https://bugs.python.org/issue35169  opened by serhiy.storchaka

#35172: Add support for other MSVC compiler versions to distutils. dis
https://bugs.python.org/issue35172  opened by Ali Rizvi-Santiago

#35173: Re-use already existing functionality to allow Python 2.7.x (b
https://bugs.python.org/issue35173  opened by Ali Rizvi-Santiago

#35174: Calling for super().__str__ seems to call self.__repr__ in lis
https://bugs.python.org/issue35174  opened by Camion

#35177: Add missing dependencies between AST/parser header files
https://bugs.python.org/issue35177  opened by vstinner

#35178: Typo/trivial mistake in warnings.py (may be related to 2.x to 
https://bugs.python.org/issue35178  opened by tashrifbillah

#35181: Doc: Namespace Packages: Inconsistent documentation of __loade
https://bugs.python.org/issue35181  opened by mdk

#35182: Popen.communicate() breaks when child closes its side of pipe 
https://bugs.python.org/issue35182  opened by and800

#35183: os.path.splitext documentation needs typical example
https://bugs.python.org/issue35183  opened by shaungriffith

#35184: Makefile is not correctly generated when compiling pyextat wit
https://bugs.python.org/issue35184  opened by mgmacias95

#35185: Logger race condition - loses lines if removeHandler called fr
https://bugs.python.org/issue35185  opened by benspiller

#35186: distutils.command.upload uses deprecated platform.dist with bd
https://bugs.python.org/issue35186  opened by p-ganssle

#35189: PEP 475: fnctl functions are not retried if interrupted by a s
https://bugs.python.org/issue35189  opened by akeskimo

#35190: collections.abc.Sequence cannot be used to test whether a clas
https://bugs.python.org/issue35190  opened by hroncok

#35191: socket.setblocking(x) treats multiples of 2**32 as False
https://bugs.python.org/issue35191  opened by izbyshev

#35192: pathlib mkdir throws FileExistsError when not supposed to
https://bugs.python.org/issue35192  opened by Adam Dunlap

#35193: Off by one error in peephole call to find_op on case RETURN_VA
https://bugs.python.org/issue35193  opened by gregory.p.smith

#35194: A typo in a constant in cp932 codec
https://bugs.python.org/issue35194  opened by izbyshev

#35195: Pandas read_csv() is 3.5X Slower on Python 3.7.1 vs Python 3.6
https://bugs.python.org/issue35195  opened by Dragoljub

#35196: IDLE text squeezer is too aggressive and is slow
https://bugs.python.org/issue35196  opened by rhettinger

#35197: graminit.h defines very generic names like 'stmt' or 'test'
https://bugs.python.org/issue35197  opened by vstinner

#35198: Build issue while compiling cpp files in AIX
https://bugs.python.org/issue35198  opened by Ayappan

#35199: Convert PyTuple_GET_ITEM() macro to a function call with addit
https://bugs.python.org/issue35199  opened by vstinner

#35200: Range repr could be better
https://bugs.python.org/issue35200  opened by mdk

#35201: Recursive '**' matches non-existent directories.
https://bugs.python.org/issue35201  opened by daniel



Most recent 15 issues with no replies (15)
==========================================

#35201: Recursive '**' matches non-existent directories.
https://bugs.python.org/issue35201

#35198: Build issue while compiling cpp files in AIX
https://bugs.python.org/issue35198

#35195: Pandas read_csv() is 3.5X Slower on Python 3.7.1 vs Python 3.6
https://bugs.python.org/issue35195

#35191: socket.setblocking(x) treats multiples of 2**32 as False
https://bugs.python.org/issue35191

#35186: distutils.command.upload uses deprecated platform.dist with bd
https://bugs.python.org/issue35186

#35185: Logger race condition - loses lines if removeHandler called fr
https://bugs.python.org/issue35185

#35184: Makefile is not correctly generated when compiling pyextat wit
https://bugs.python.org/issue35184

#35183: os.path.splitext documentation needs typical example
https://bugs.python.org/issue35183

#35177: Add missing dependencies between AST/parser header files
https://bugs.python.org/issue35177

#35173: Re-use already existing functionality to allow Python 2.7.x (b
https://bugs.python.org/issue35173

#35172: Add support for other MSVC compiler versions to distutils. dis
https://bugs.python.org/issue35172

#35169: Improve error messages for assignment
https://bugs.python.org/issue35169

#35163: locale: setlocale(..., 'eo') sets non-existing locale
https://bugs.python.org/issue35163

#35158: Fix PEP 3115 to NOT imply that the class dictionary is used in
https://bugs.python.org/issue35158

#35155: Clarify Protocol Handlers in urllib.request Docs
https://bugs.python.org/issue35155



Most recent 15 issues waiting for review (15)
=============================================

#35200: Range repr could be better
https://bugs.python.org/issue35200

#35199: Convert PyTuple_GET_ITEM() macro to a function call with addit
https://bugs.python.org/issue35199

#35197: graminit.h defines very generic names like 'stmt' or 'test'
https://bugs.python.org/issue35197

#35194: A typo in a constant in cp932 codec
https://bugs.python.org/issue35194

#35193: Off by one error in peephole call to find_op on case RETURN_VA
https://bugs.python.org/issue35193

#35191: socket.setblocking(x) treats multiples of 2**32 as False
https://bugs.python.org/issue35191

#35189: PEP 475: fnctl functions are not retried if interrupted by a s
https://bugs.python.org/issue35189

#35186: distutils.command.upload uses deprecated platform.dist with bd
https://bugs.python.org/issue35186

#35181: Doc: Namespace Packages: Inconsistent documentation of __loade
https://bugs.python.org/issue35181

#35177: Add missing dependencies between AST/parser header files
https://bugs.python.org/issue35177

#35173: Re-use already existing functionality to allow Python 2.7.x (b
https://bugs.python.org/issue35173

#35172: Add support for other MSVC compiler versions to distutils. dis
https://bugs.python.org/issue35172

#35169: Improve error messages for assignment
https://bugs.python.org/issue35169

#35155: Clarify Protocol Handlers in urllib.request Docs
https://bugs.python.org/issue35155

#35153: Allow to set headers in xmlrpc.client.ServerProxy
https://bugs.python.org/issue35153



Top 10 most discussed issues (10)
=================================

#34805: Explicitly specify `MyClass.__subclasses__()` returns classes 
https://bugs.python.org/issue34805  11 msgs

#35194: A typo in a constant in cp932 codec
https://bugs.python.org/issue35194  10 msgs

#35113: inspect.getsource returns incorrect source for classes when cl
https://bugs.python.org/issue35113   9 msgs

#35145: sqlite3: "select *" should optionally sniff and autoconvert TE
https://bugs.python.org/issue35145   9 msgs

#32409: venv activate.bat is UTF-8 encoded but uses current console co
https://bugs.python.org/issue32409   8 msgs

#34155: email.utils.parseaddr mistakenly parse an email
https://bugs.python.org/issue34155   7 msgs

#35105: Document that CPython accepts "invalid" identifiers
https://bugs.python.org/issue35105   7 msgs

#35131: Cannot access to customized paths within .pth file
https://bugs.python.org/issue35131   7 msgs

#35157: Missing pyconfig.h when building from source and pgo flag is e
https://bugs.python.org/issue35157   7 msgs

#35104: IDLE: On macOS, Command-M minimizes & opens "Open Module..."
https://bugs.python.org/issue35104   6 msgs



Issues closed (48)
==================

#2504: Add gettext.pgettext() and variants support
https://bugs.python.org/issue2504  closed by serhiy.storchaka

#17560: problem using multiprocessing with really big objects?
https://bugs.python.org/issue17560  closed by pitrou

#19675: Pool dies with excessive workers, but does not cleanup
https://bugs.python.org/issue19675  closed by mdk

#21263: test_gdb failures on os x 10.9.2
https://bugs.python.org/issue21263  closed by ned.deily

#25711: Rewrite zipimport from scratch
https://bugs.python.org/issue25711  closed by serhiy.storchaka

#29341: Missing accepting path-like object in docstrings of os module 
https://bugs.python.org/issue29341  closed by pablogsal

#31553: Extend json.tool to handle jsonlines (with a flag)
https://bugs.python.org/issue31553  closed by serhiy.storchaka

#31583: 2to3 call for file in current directory yields error
https://bugs.python.org/issue31583  closed by denis-osipov

#32285: In `unicodedata`, it should be possible to check a unistr's no
https://bugs.python.org/issue32285  closed by benjamin.peterson

#32512: Add an option to profile to run library module as a script
https://bugs.python.org/issue32512  closed by mariocj89

#33000: IDLE Doc: Text consumes unlimited RAM, consoles likely not
https://bugs.python.org/issue33000  closed by terry.reedy

#33275: glob.glob should explicitly note that results aren't sorted
https://bugs.python.org/issue33275  closed by mdk

#33462: reversible dict
https://bugs.python.org/issue33462  closed by inada.naoki

#33578: cjkcodecs missing getstate and setstate implementations
https://bugs.python.org/issue33578  closed by inada.naoki

#34205: Ansible: _PyImport_LoadDynamicModuleWithSpec() crash on an inv
https://bugs.python.org/issue34205  closed by mdk

#34547: Wsgiref server does not handle closed connections gracefully
https://bugs.python.org/issue34547  closed by chris.jerdonek

#34699: allow path-like objects in program arguments in Windows
https://bugs.python.org/issue34699  closed by serhiy.storchaka

#34726: Add support of checked hash-based pycs in zipimport
https://bugs.python.org/issue34726  closed by serhiy.storchaka

#34885: asyncio documention has lost its paragraph about cancellation
https://bugs.python.org/issue34885  closed by asvetlov

#34898: add mtime argument to gzip.compress
https://bugs.python.org/issue34898  closed by serhiy.storchaka

#34966: Pydoc: better support of method aliases
https://bugs.python.org/issue34966  closed by serhiy.storchaka

#34969: Add --fast, --best to the gzip CLI
https://bugs.python.org/issue34969  closed by mdk

#35015: availability directive breaks po files
https://bugs.python.org/issue35015  closed by mdk

#35032: Remove the videos from faq/Windows
https://bugs.python.org/issue35032  closed by matrixise

#35065: Reading received data from a closed TCP stream using `StreamRe
https://bugs.python.org/issue35065  closed by asvetlov

#35099: Improve the IDLE - console differences doc
https://bugs.python.org/issue35099  closed by terry.reedy

#35109: Doctest in CI uses python binary built from master causing Dep
https://bugs.python.org/issue35109  closed by mdk

#35118: Add peek() or first() method in queue
https://bugs.python.org/issue35118  closed by rhettinger

#35123: Add style guide for sentinel usage
https://bugs.python.org/issue35123  closed by serhiy.storchaka

#35133: Bugs in concatenating string literals on different lines
https://bugs.python.org/issue35133  closed by serhiy.storchaka

#35147: _Py_NO_RETURN is always empty on GCC
https://bugs.python.org/issue35147  closed by vstinner

#35148: cannot activate a venv environment on a Swiss German windows
https://bugs.python.org/issue35148  closed by vinay.sajip

#35150: Misc/README.valgrind out-of-date
https://bugs.python.org/issue35150  closed by cheryl.sabella

#35152: too small type for struct.pack/unpack in mutliprocessing.Conne
https://bugs.python.org/issue35152  closed by serhiy.storchaka

#35154: subprocess.list2cmdline() does not allow running some commands
https://bugs.python.org/issue35154  closed by Roffild

#35159: Add a link to the devguide in the sidebar of the documentation
https://bugs.python.org/issue35159  closed by mdk

#35160: PyObjects initialized with PyObject_New have uninitialized poi
https://bugs.python.org/issue35160  closed by benjamin.peterson

#35161: ASAN: stack-use-after-scope in grp.getgr{nam,gid} and pwd.getp
https://bugs.python.org/issue35161  closed by serhiy.storchaka

#35162: Inconsistent behaviour around __new__
https://bugs.python.org/issue35162  closed by serhiy.storchaka

#35167: Specify program for gzip and json.tool command line options
https://bugs.python.org/issue35167  closed by serhiy.storchaka

#35170: 3.7.1 compile failure on CentOS 6.10; _ctypes did not build
https://bugs.python.org/issue35170  closed by lana.deere

#35171: test_TimeRE_recreation_timezone failure on systems with non-de
https://bugs.python.org/issue35171  closed by benjamin.peterson

#35175: Builtin function all() is handling dict() types in a weird way
https://bugs.python.org/issue35175  closed by josh.r

#35176: for loop range bug
https://bugs.python.org/issue35176  closed by steven.daprano

#35179: Limit max sendfile chunk to 0x7ffff000
https://bugs.python.org/issue35179  closed by asvetlov

#35180: Ctypes segfault or TypeError tested for python2.7 and 3
https://bugs.python.org/issue35180  closed by josh.r

#35187: a bug about np.arrange
https://bugs.python.org/issue35187  closed by mark.dickinson

#35188: something confused about numpy.arange
https://bugs.python.org/issue35188  closed by xyl123

From chris.barker at noaa.gov  Fri Nov  9 16:17:09 2018
From: chris.barker at noaa.gov (Chris Barker)
Date: Fri, 9 Nov 2018 13:17:09 -0800
Subject: [Python-Dev] Signalling NANs
In-Reply-To: <ps3ru2$h6s$1@blaine.gmane.org>
References: <20181109110507.GK4071@ando.pearwood.info>
 <ps3ru2$h6s$1@blaine.gmane.org>
Message-ID: <CALGmxEKNMPbZa7vqMFZmbMdvXxb6py7qPu7zY_vGQ1OHfj302g@mail.gmail.com>

works for me, too:

In [9]: x = cast_int2float(0x7ff8000000000001)
In [10]: hex(cast_float2int(x))
Out[10]: '0x7ff8000000000001'

In [11]: x = cast_int2float(0x7ff0000000000001)
In [12]: hex(cast_float2int(x))
Out[12]: '0x7ff0000000000001'

OS-X, conda build:

Python 3.7.0 | packaged by conda-forge | (default, Aug 27 2018, 17:24:52)
[Clang 6.1.0 (clang-602.0.53)] on darwin

I suspect it depends on the compiler's math library

But neither is raising an exception:

In [3]: x = cast_int2float(0x7ff0000000000001)

In [4]: y = cast_int2float(0x7ff8000000000001)

In [5]: 2.0 / x
Out[5]: nan

In [6]: 2.0 / y
Out[6]: nan

When should it?

-CHB



On Fri, Nov 9, 2018 at 3:46 AM, Serhiy Storchaka <storchaka at gmail.com>
wrote:

> 09.11.18 13:05, Steven D'Aprano ????:
>
>> py> x = cast_int2float(0x7ff0000000000001)
>> py> x
>> nan
>> py> hex(cast_float2int(x))
>> '0x7ff8000000000001'
>>
>
> I got '0x7ff0000000000001'.
>
>
> _______________________________________________
> Python-Dev mailing list
> Python-Dev at python.org
> https://mail.python.org/mailman/listinfo/python-dev
> Unsubscribe: https://mail.python.org/mailman/options/python-dev/chris.
> barker%40noaa.gov
>



-- 

Christopher Barker, Ph.D.
Oceanographer

Emergency Response Division
NOAA/NOS/OR&R            (206) 526-6959   voice
7600 Sand Point Way NE   (206) 526-6329   fax
Seattle, WA  98115       (206) 526-6317   main reception

Chris.Barker at noaa.gov
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://mail.python.org/pipermail/python-dev/attachments/20181109/c96c97a6/attachment.html>

From vstinner at redhat.com  Fri Nov  9 19:30:37 2018
From: vstinner at redhat.com (Victor Stinner)
Date: Sat, 10 Nov 2018 01:30:37 +0100
Subject: [Python-Dev] Experiment an opt-in new C API for Python? (leave
 current API unchanged)
Message-ID: <CA+3bQGGcuo_-fdJwrisGP6+h6CuNzcErSoacaQySEb5h4nOQEQ@mail.gmail.com>

Hi,

The current C API of Python is both a strength and a weakness of the
Python ecosystem as a whole. It's a strength because it allows to
quickly reuse a huge number of existing libraries by writing a glue
for them. It made numpy possible and this project is a big sucess!
It's a weakness because of its cost on the maintenance, it prevents
optimizations, and more generally it prevents to experiment modifying
Python internals.

For example, CPython cannot use tagged pointers, because the existing
C API is heavily based on the ability to dereference a PyObject*
object and access directly members of objects (like PyTupleObject).
For example, Py_INCREF() modifies *directly* PyObject.ob_refcnt. It's
not possible neither to use a Python compiled in debug mode on C
extensions (compiled in release mode), because the ABI is different in
debug mode. As a consequence, nobody uses the debug mode, whereas it
is very helpful to develop C extensions and investigate bugs.

I also consider that the C API gives too much work to PyPy (for their
"cpyext" module). A better C API (not leaking implementation) details
would make PyPy more efficient (and simplify its implementation in the
long term, when the support for the old C API can be removed). For
example, PyList_GetItem(list, 0) currently converts all items of the
list to PyObject* in PyPy, it can waste memory if only the first item
of the list is needed. PyPy has much more efficient storage than an
array of PyObject* for lists.

I wrote a website to explain all these issues with much more details:

   https://pythoncapi.readthedocs.io/

I identified "bad APIs" like using borrowed references or giving
access to PyObject** (ex: PySequence_Fast_ITEMS).

I already wrote an (incomplete) implementation of a new C API which
doesn't leak implementation details:

   https://github.com/pythoncapi/pythoncapi

It uses an opt-in option (Py_NEWCAPI define -- I'm not sure about the
name) to get the new API. The current C API is unchanged.

Ah, important points. I don't want to touch the current C API nor make
it less efficient. And compatibility in both directions (current C API
<=> new C API) is very important for me. There is no such plan as
"Python 4" which would break the world and *force* everybody to
upgrade to the new C API, or stay to Python 3 forever. No. The new C
API must be an opt-in option, and current C API remains the default
and not be changed.

I have different ideas for the compatibility part, but I'm not sure of
what are the best options yet.

My short term for the new C API would be to ease the experimentation
of projects like tagged pointers. Currently, I have to maintain the
implementation of a new C API which is not really convenient.

--

Today I tried to abuse the Py_DEBUG define for the new C API, but it
seems to be a bad idea:

   https://github.com/python/cpython/pull/10435

A *new* define is needed to opt-in for the new C API.

Victor

From mike at selik.org  Fri Nov  9 19:49:13 2018
From: mike at selik.org (Michael Selik)
Date: Fri, 9 Nov 2018 16:49:13 -0800
Subject: [Python-Dev] Experiment an opt-in new C API for Python? (leave
 current API unchanged)
In-Reply-To: <CA+3bQGGcuo_-fdJwrisGP6+h6CuNzcErSoacaQySEb5h4nOQEQ@mail.gmail.com>
References: <CA+3bQGGcuo_-fdJwrisGP6+h6CuNzcErSoacaQySEb5h4nOQEQ@mail.gmail.com>
Message-ID: <CAGgTfkN7=k2zxuJt7OubAeZ0ns8NH_PpuMvSuA+Sf_s2FvRPXw@mail.gmail.com>

On Fri, Nov 9, 2018 at 4:33 PM Victor Stinner <vstinner at redhat.com> wrote:

> It uses an opt-in option (Py_NEWCAPI define -- I'm not sure about the
> name) to get the new API. The current C API is unchanged.
>

While one can hope that this will be the only time the C API will be
revised, it may be better to number it instead of calling it "NEW". 20
years from now, it won't feel new anymore.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://mail.python.org/pipermail/python-dev/attachments/20181109/bbfb1cf2/attachment.html>

From vstinner at redhat.com  Fri Nov  9 19:53:26 2018
From: vstinner at redhat.com (Victor Stinner)
Date: Sat, 10 Nov 2018 01:53:26 +0100
Subject: [Python-Dev] Experiment an opt-in new C API for Python? (leave
 current API unchanged)
In-Reply-To: <CA+3bQGGcuo_-fdJwrisGP6+h6CuNzcErSoacaQySEb5h4nOQEQ@mail.gmail.com>
References: <CA+3bQGGcuo_-fdJwrisGP6+h6CuNzcErSoacaQySEb5h4nOQEQ@mail.gmail.com>
Message-ID: <CA+3bQGGmvXbH+Tm6e0ii1L0eRc8xwX+o_O4+0OY3R6EiSFjhPg@mail.gmail.com>

To hide all implementation details, I propose to stop using macros and
use function calls instead. For example, replace:

#define PyTuple_GET_ITEM(op, i) \
   (((PyTupleObject *)(op))->ob_item[i])

with:

# define PyTuple_GET_ITEM(op, i) PyTuple_GetItem(op, i)

With this change, C extensions using PyTuple_GET_ITEM() does no longer
dereference PyObject* nor access PyTupleObject.ob_item. For example,
PyPy doesn't have to convert all tuple items to PyObject, but only
create one PyObject for the requested item. Another example is that it
becomes possible to use a "CPython debug runtime" which checks at
runtime that the first argument is a tuple and that the index is
valid. For a longer explanation, see the idea of different "Python
runtimes":

   https://pythoncapi.readthedocs.io/runtimes.html

Replacing macros with function calls is only a first step. It doesn't
solve the problem of borrowed references for example.

Obviously, such change has a cost on performances. Sadly, I didn't run
a benchmark yet. At this point, I mostly care about correctness and
the feasibility of the whole project. I also hope that the new C API
will allow to implement new optimizations which cannot even be
imagined today, because of the backward compatibility. The question is
if the performance balance is positive or not at the all :-)
Hopefully, there is no urgency to take any decision at this point. The
whole project is experimental and can be cancelled anytime.

Victor

From vstinner at redhat.com  Fri Nov  9 19:56:02 2018
From: vstinner at redhat.com (Victor Stinner)
Date: Sat, 10 Nov 2018 01:56:02 +0100
Subject: [Python-Dev] Experiment an opt-in new C API for Python? (leave
 current API unchanged)
In-Reply-To: <CAGgTfkN7=k2zxuJt7OubAeZ0ns8NH_PpuMvSuA+Sf_s2FvRPXw@mail.gmail.com>
References: <CA+3bQGGcuo_-fdJwrisGP6+h6CuNzcErSoacaQySEb5h4nOQEQ@mail.gmail.com>
 <CAGgTfkN7=k2zxuJt7OubAeZ0ns8NH_PpuMvSuA+Sf_s2FvRPXw@mail.gmail.com>
Message-ID: <CA+3bQGEG9dmCfRP5_kxqJ-==1ad+jYhdtDFv6ZaeW5mc102fWw@mail.gmail.com>

Le sam. 10 nov. 2018 ? 01:49, Michael Selik <mike at selik.org> a ?crit :
>> It uses an opt-in option (Py_NEWCAPI define -- I'm not sure about the
>> name) to get the new API. The current C API is unchanged.
>
> While one can hope that this will be the only time the C API will be revised, it may be better to number it instead of calling it "NEW". 20 years from now, it won't feel new anymore.

That's exactly why I dislike "New", it's like adding "Ex" or "2" to a
function name :-)

Well, before bikeshedding on the C define name, I would prefer to see
if the overall idea of trying to push code for the new C API in the
master branch is a good idea, or if it's too early and the experiment
must continue in a fork.

Victor

From njs at pobox.com  Fri Nov  9 20:50:04 2018
From: njs at pobox.com (Nathaniel Smith)
Date: Fri, 9 Nov 2018 17:50:04 -0800
Subject: [Python-Dev] Experiment an opt-in new C API for Python? (leave
 current API unchanged)
In-Reply-To: <CA+3bQGGcuo_-fdJwrisGP6+h6CuNzcErSoacaQySEb5h4nOQEQ@mail.gmail.com>
References: <CA+3bQGGcuo_-fdJwrisGP6+h6CuNzcErSoacaQySEb5h4nOQEQ@mail.gmail.com>
Message-ID: <CAPJVwBmKHMMKypLDhjhkWHSE7HnHSh_irqaRfCug_+YL4jOtqw@mail.gmail.com>

On Fri, Nov 9, 2018 at 4:30 PM, Victor Stinner <vstinner at redhat.com> wrote:
> Ah, important points. I don't want to touch the current C API nor make
> it less efficient. And compatibility in both directions (current C API
> <=> new C API) is very important for me. There is no such plan as
> "Python 4" which would break the world and *force* everybody to
> upgrade to the new C API, or stay to Python 3 forever. No. The new C
> API must be an opt-in option, and current C API remains the default
> and not be changed.

Doesn't this mean that you're just making the C API larger and more
complicated, rather than simplifying it? You cite some benefits
(tagged pointers, changing the layout of PyObject, making PyPy's life
easier), but I don't see how you can do any of those things so long as
the current C API remains supported.

-n

-- 
Nathaniel J. Smith -- https://vorpus.org

From vstinner at redhat.com  Fri Nov  9 21:03:03 2018
From: vstinner at redhat.com (Victor Stinner)
Date: Sat, 10 Nov 2018 03:03:03 +0100
Subject: [Python-Dev] Experiment an opt-in new C API for Python? (leave
 current API unchanged)
In-Reply-To: <CAPJVwBmKHMMKypLDhjhkWHSE7HnHSh_irqaRfCug_+YL4jOtqw@mail.gmail.com>
References: <CA+3bQGGcuo_-fdJwrisGP6+h6CuNzcErSoacaQySEb5h4nOQEQ@mail.gmail.com>
 <CAPJVwBmKHMMKypLDhjhkWHSE7HnHSh_irqaRfCug_+YL4jOtqw@mail.gmail.com>
Message-ID: <CA+3bQGFg23bYrSmxtzkXsHAGbrA5EkjxOExOfwZiBmDPu3-jZQ@mail.gmail.com>

Le sam. 10 nov. 2018 ? 02:50, Nathaniel Smith <njs at pobox.com> a ?crit :
> Doesn't this mean that you're just making the C API larger and more
> complicated, rather than simplifying it? You cite some benefits
> (tagged pointers, changing the layout of PyObject, making PyPy's life
> easier), but I don't see how you can do any of those things so long as
> the current C API remains supported.

Tagged pointers and changing the layout of PyObject can only be
experimented in a new different Python runtime which only supports C
extensions compiled with the new C API. Technically, it can be CPython
compiled with a different flag, as there is already python3-dbg (debug
mode, ./configure --with-pydebug) and python3 (release mode). Or it
can be CPython fork.

I don't propose to experiment tagged pointer or changing the layout of
PyObject in CPython. It may require too many changes and it's unclear
if it's worth it or not. I only propose to implement the least
controversial part of the new C API in the master branch, since
maintaining this new C API in a fork is painful.

I cannot promise that it will make PyPy's life easier. PyPy developers
already told me that they already implemented the support of the
current C API. The promise is that if you use the new C API, PyPy
should be more efficient, because it would have less things to
emulate. To be honest, I'm not sure at this point, I don't know PyPy
internals. I also know that PyPy developers always complain when we
*add new functions* to the C API, and there is a non-zero risk that I
would like to add new functions, since current ones have issues :-) I
am working with PyPy to involve them in the new C API.

Victor

From vstinner at redhat.com  Fri Nov  9 21:14:33 2018
From: vstinner at redhat.com (Victor Stinner)
Date: Sat, 10 Nov 2018 03:14:33 +0100
Subject: [Python-Dev] Experiment an opt-in new C API for Python? (leave
 current API unchanged)
In-Reply-To: <CA+3bQGGmvXbH+Tm6e0ii1L0eRc8xwX+o_O4+0OY3R6EiSFjhPg@mail.gmail.com>
References: <CA+3bQGGcuo_-fdJwrisGP6+h6CuNzcErSoacaQySEb5h4nOQEQ@mail.gmail.com>
 <CA+3bQGGmvXbH+Tm6e0ii1L0eRc8xwX+o_O4+0OY3R6EiSFjhPg@mail.gmail.com>
Message-ID: <CA+3bQGEeTgDdKekTfFb-rbi5o3G7pzCs4xUWaDwL097wBYd-mQ@mail.gmail.com>

Sometimes, code is easier to understand than a long explanation, so
here is a very simple example of modified function for the new C API:

https://bugs.python.org/issue35206
https://github.com/python/cpython/pull/10443/files

PyTuple_GET_ITEM() becomes a function call and the function
implementation checks arguments at runtime if compiled in debug mode.

Technically, the header file still uses a macro, to implicitly cast to
PyObject*, since currently the macro accepts any type, and the new C
API should not change that.

Victor
Le sam. 10 nov. 2018 ? 01:53, Victor Stinner <vstinner at redhat.com> a ?crit :
>
> To hide all implementation details, I propose to stop using macros and
> use function calls instead. For example, replace:
>
> #define PyTuple_GET_ITEM(op, i) \
>    (((PyTupleObject *)(op))->ob_item[i])
>
> with:
>
> # define PyTuple_GET_ITEM(op, i) PyTuple_GetItem(op, i)
>
> With this change, C extensions using PyTuple_GET_ITEM() does no longer
> dereference PyObject* nor access PyTupleObject.ob_item. For example,
> PyPy doesn't have to convert all tuple items to PyObject, but only
> create one PyObject for the requested item. Another example is that it
> becomes possible to use a "CPython debug runtime" which checks at
> runtime that the first argument is a tuple and that the index is
> valid. For a longer explanation, see the idea of different "Python
> runtimes":
>
>    https://pythoncapi.readthedocs.io/runtimes.html
>
> Replacing macros with function calls is only a first step. It doesn't
> solve the problem of borrowed references for example.
>
> Obviously, such change has a cost on performances. Sadly, I didn't run
> a benchmark yet. At this point, I mostly care about correctness and
> the feasibility of the whole project. I also hope that the new C API
> will allow to implement new optimizations which cannot even be
> imagined today, because of the backward compatibility. The question is
> if the performance balance is positive or not at the all :-)
> Hopefully, there is no urgency to take any decision at this point. The
> whole project is experimental and can be cancelled anytime.
>
> Victor

From njs at pobox.com  Fri Nov  9 22:02:37 2018
From: njs at pobox.com (Nathaniel Smith)
Date: Fri, 9 Nov 2018 19:02:37 -0800
Subject: [Python-Dev] Experiment an opt-in new C API for Python? (leave
 current API unchanged)
In-Reply-To: <CA+3bQGFg23bYrSmxtzkXsHAGbrA5EkjxOExOfwZiBmDPu3-jZQ@mail.gmail.com>
References: <CA+3bQGGcuo_-fdJwrisGP6+h6CuNzcErSoacaQySEb5h4nOQEQ@mail.gmail.com>
 <CAPJVwBmKHMMKypLDhjhkWHSE7HnHSh_irqaRfCug_+YL4jOtqw@mail.gmail.com>
 <CA+3bQGFg23bYrSmxtzkXsHAGbrA5EkjxOExOfwZiBmDPu3-jZQ@mail.gmail.com>
Message-ID: <CAPJVwBm73w6UZdvkddTnhavd+WmFU-L2pBKFG=u+mC=nY2Y6Qg@mail.gmail.com>

On Fri, Nov 9, 2018 at 6:03 PM, Victor Stinner <vstinner at redhat.com> wrote:
> Le sam. 10 nov. 2018 ? 02:50, Nathaniel Smith <njs at pobox.com> a ?crit :
>> Doesn't this mean that you're just making the C API larger and more
>> complicated, rather than simplifying it? You cite some benefits
>> (tagged pointers, changing the layout of PyObject, making PyPy's life
>> easier), but I don't see how you can do any of those things so long as
>> the current C API remains supported.
>
> Tagged pointers and changing the layout of PyObject can only be
> experimented in a new different Python runtime which only supports C
> extensions compiled with the new C API. Technically, it can be CPython
> compiled with a different flag, as there is already python3-dbg (debug
> mode, ./configure --with-pydebug) and python3 (release mode). Or it
> can be CPython fork.
>
> I don't propose to experiment tagged pointer or changing the layout of
> PyObject in CPython. It may require too many changes and it's unclear
> if it's worth it or not. I only propose to implement the least
> controversial part of the new C API in the master branch, since
> maintaining this new C API in a fork is painful.
>
> I cannot promise that it will make PyPy's life easier. PyPy developers
> already told me that they already implemented the support of the
> current C API. The promise is that if you use the new C API, PyPy
> should be more efficient, because it would have less things to
> emulate. To be honest, I'm not sure at this point, I don't know PyPy
> internals. I also know that PyPy developers always complain when we
> *add new functions* to the C API, and there is a non-zero risk that I
> would like to add new functions, since current ones have issues :-) I
> am working with PyPy to involve them in the new C API.

So is it fair to say that your plan is that CPython will always use
the current ("old") API internally, and the "new" API will be
essentially an abstraction layer, that's designed to let people write
C extensions that target the old API, while also being flexible enough
to target PyPy and other "new different Python runtimes"?

If so, then would it make more sense to develop this as an actual
separate abstraction layer? That would have the huge advantage that it
could be distributed and versioned separately from CPython, different
packages could use different versions of the abstraction layer, PyPy
isn't forced to immediately add a bunch of new APIs...

-n

-- 
Nathaniel J. Smith -- https://vorpus.org

From dinoviehland at gmail.com  Fri Nov  9 23:58:27 2018
From: dinoviehland at gmail.com (Dino Viehland)
Date: Fri, 9 Nov 2018 20:58:27 -0800
Subject: [Python-Dev] Experiment an opt-in new C API for Python? (leave
 current API unchanged)
In-Reply-To: <CA+3bQGEG9dmCfRP5_kxqJ-==1ad+jYhdtDFv6ZaeW5mc102fWw@mail.gmail.com>
References: <CA+3bQGGcuo_-fdJwrisGP6+h6CuNzcErSoacaQySEb5h4nOQEQ@mail.gmail.com>
 <CAGgTfkN7=k2zxuJt7OubAeZ0ns8NH_PpuMvSuA+Sf_s2FvRPXw@mail.gmail.com>
 <CA+3bQGEG9dmCfRP5_kxqJ-==1ad+jYhdtDFv6ZaeW5mc102fWw@mail.gmail.com>
Message-ID: <CA+fnyjhGqaUZnzQ4sfqqpoC0TaM_R9k2AkvGjX6h2y0KgWRwQw@mail.gmail.com>

>
> That's exactly why I dislike "New", it's like adding "Ex" or "2" to a
> function name :-)
>
> Well, before bikeshedding on the C define name, I would prefer to see
> if the overall idea of trying to push code for the new C API in the
> master branch is a good idea, or if it's too early and the experiment
> must continue in a fork.


Rather than adding yet another pre-processor directive for this I would
suggest just adding a new header file that only has the new stable API.
For example it could just be "py.h" or "pyapi.h".  It would have all of the
definitions for the stable API.

While that would involve some duplication from the existing headers, I
don't think it would be such a big deal - the idea is the API won't change,
methods won't be removed, and occasionally new methods will get
added in a very thoughtful manner.  Having it be separate will force
thought and conversation about it.

It would also make it very easy to look and see what exactly is in the
stable API as well.  There's be a pretty flat list which can be consulted,
and hopefully it ends up not being super huge either.

BTW, thanks for continuing to push on this Victor, it seems like great
progress!

On Fri, Nov 9, 2018 at 4:57 PM Victor Stinner <vstinner at redhat.com> wrote:

> Le sam. 10 nov. 2018 ? 01:49, Michael Selik <mike at selik.org> a ?crit :
> >> It uses an opt-in option (Py_NEWCAPI define -- I'm not sure about the
> >> name) to get the new API. The current C API is unchanged.
> >
> > While one can hope that this will be the only time the C API will be
> revised, it may be better to number it instead of calling it "NEW". 20
> years from now, it won't feel new anymore.
>
> That's exactly why I dislike "New", it's like adding "Ex" or "2" to a
> function name :-)
>
> Well, before bikeshedding on the C define name, I would prefer to see
> if the overall idea of trying to push code for the new C API in the
> master branch is a good idea, or if it's too early and the experiment
> must continue in a fork.
>
> Victor
> _______________________________________________
> Python-Dev mailing list
> Python-Dev at python.org
> https://mail.python.org/mailman/listinfo/python-dev
> Unsubscribe:
> https://mail.python.org/mailman/options/python-dev/dinoviehland%40gmail.com
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://mail.python.org/pipermail/python-dev/attachments/20181109/a442e92b/attachment.html>

From neil at python.ca  Sat Nov 10 14:22:48 2018
From: neil at python.ca (Neil Schemenauer)
Date: Sat, 10 Nov 2018 13:22:48 -0600
Subject: [Python-Dev] Experiment an opt-in new C API for Python? (leave
 current API unchanged)
In-Reply-To: <CA+fnyjhGqaUZnzQ4sfqqpoC0TaM_R9k2AkvGjX6h2y0KgWRwQw@mail.gmail.com>
References: <CA+3bQGGcuo_-fdJwrisGP6+h6CuNzcErSoacaQySEb5h4nOQEQ@mail.gmail.com>
 <CAGgTfkN7=k2zxuJt7OubAeZ0ns8NH_PpuMvSuA+Sf_s2FvRPXw@mail.gmail.com>
 <CA+3bQGEG9dmCfRP5_kxqJ-==1ad+jYhdtDFv6ZaeW5mc102fWw@mail.gmail.com>
 <CA+fnyjhGqaUZnzQ4sfqqpoC0TaM_R9k2AkvGjX6h2y0KgWRwQw@mail.gmail.com>
Message-ID: <20181110192248.lk5ureidahc3yfzi@python.ca>

On 2018-11-09, Dino Viehland wrote:
> Rather than adding yet another pre-processor directive for this I would
> suggest just adding a new header file that only has the new stable API.
> For example it could just be "py.h" or "pyapi.h".  It would have all of the
> definitions for the stable API.

I like this idea.  It will be easier to define a minimal and clean
API with this approach.  I believe it can mostly be a subset of the
current API.

I think we could Dino's idea with Nathaniel's suggestion of
developing it separate from CPython.  Victor's C-API project is
already attempting to provide backwards compatibility.  I.e. you can
have an extension module that uses the new API but compiles and runs
with older versions of Python (e.g. 3.6).  So, whatever is inside
this new API, it must be possible to build it on top of the existing
Python API.

Regards,

  Neil

From steve at pearwood.info  Sat Nov 10 18:26:42 2018
From: steve at pearwood.info (Steven D'Aprano)
Date: Sun, 11 Nov 2018 10:26:42 +1100
Subject: [Python-Dev] Signalling NANs
In-Reply-To: <CALGmxEKNMPbZa7vqMFZmbMdvXxb6py7qPu7zY_vGQ1OHfj302g@mail.gmail.com>
References: <20181109110507.GK4071@ando.pearwood.info>
 <ps3ru2$h6s$1@blaine.gmane.org>
 <CALGmxEKNMPbZa7vqMFZmbMdvXxb6py7qPu7zY_vGQ1OHfj302g@mail.gmail.com>
Message-ID: <20181110232642.GS4071@ando.pearwood.info>

On Fri, Nov 09, 2018 at 01:17:09PM -0800, Chris Barker via Python-Dev wrote:
> works for me, too:
> 
> In [9]: x = cast_int2float(0x7ff8000000000001)
> In [10]: hex(cast_float2int(x))
> Out[10]: '0x7ff8000000000001'
> 
> In [11]: x = cast_int2float(0x7ff0000000000001)
> In [12]: hex(cast_float2int(x))
> Out[12]: '0x7ff0000000000001'


Fascinating. I borrowed a Debian system and tried it on there, and got 
the same results as you. So I wonder whether it is something unusual 
about my Red Hat system that it prevents the formation of signalling 
NANs?

However, I don't think that explains why the float constructor doesn't 
allow Decimal('snan') to be converted to a float.


> I suspect it depends on the compiler's math library

Unfortunately that's probably true.


> But neither is raising an exception:
[...]
> When should it?

I think that, by default, any arithmetic operation, comparison or math 
library function call ought to raise if given a snan, if the underlying 
math library supports IEEE-754 signals. Which I imagine these days 
nearly all should do.

So any of these should raise:

snan + 1
math.sin(snan)
snan == 0



-- 
Steve

From njs at pobox.com  Sat Nov 10 19:27:29 2018
From: njs at pobox.com (Nathaniel Smith)
Date: Sat, 10 Nov 2018 16:27:29 -0800
Subject: [Python-Dev] Signalling NANs
In-Reply-To: <20181110232642.GS4071@ando.pearwood.info>
References: <20181109110507.GK4071@ando.pearwood.info>
 <ps3ru2$h6s$1@blaine.gmane.org>
 <CALGmxEKNMPbZa7vqMFZmbMdvXxb6py7qPu7zY_vGQ1OHfj302g@mail.gmail.com>
 <20181110232642.GS4071@ando.pearwood.info>
Message-ID: <CAPJVwB=RwskV4tktgfnV-rdexqnKKyfZwkhEErNV5KhganXO1w@mail.gmail.com>

On Sat, Nov 10, 2018 at 3:26 PM, Steven D'Aprano <steve at pearwood.info> wrote:
> On Fri, Nov 09, 2018 at 01:17:09PM -0800, Chris Barker via Python-Dev wrote:
>> works for me, too:
>>
>> In [9]: x = cast_int2float(0x7ff8000000000001)
>> In [10]: hex(cast_float2int(x))
>> Out[10]: '0x7ff8000000000001'
>>
>> In [11]: x = cast_int2float(0x7ff0000000000001)
>> In [12]: hex(cast_float2int(x))
>> Out[12]: '0x7ff0000000000001'
>
>
> Fascinating. I borrowed a Debian system and tried it on there, and got
> the same results as you. So I wonder whether it is something unusual
> about my Red Hat system that it prevents the formation of signalling
> NANs?

Apparently loading a sNaN into an x87 register silently converts it to
a qNaN, and on Linux C compilers are allowed to do that at any point:

   https://stackoverflow.com/questions/22816095/signalling-nan-was-corrupted-when-returning-from-x86-function-flds-fstps-of-x87

So the Debian/RH difference may just be different register allocation
in two slightly different compiler versions.

Also, gcc doesn't even try to support sNaN correctly unless you pass
-fsignaling-nans, and the docs warn that this isn't very well tested:

   https://www.cleancss.com/explain-command/gcc/5197

IEEE754 is a wonderful thing, and even imperfect implementations are
still way better than what came before, but real systems are almost
universally sloppy about details. I don't think any real libm even
tries to set all the status flags correctly. And I'm not sure sNaN
support is actually useful anyway...

Of course if all you want is a value that raises an exception whenever
it's used in an arithmetic expression, then Python does support that
:-)

   sNaN = object()

-n

-- 
Nathaniel J. Smith -- https://vorpus.org

From stephane at wirtel.be  Sun Nov 11 09:34:45 2018
From: stephane at wirtel.be (Stephane Wirtel)
Date: Sun, 11 Nov 2018 14:34:45 +0000
Subject: [Python-Dev] Get a running instance of the doc for a PR.
In-Reply-To: <CAGbohnYjfMtVBbSSZA=pNW_NNYMwc-WOy_L0V=pXij+tTUwfJw@mail.gmail.com>
References: <20181104133827.GA25586@xps>
 <203B5254-326E-43EC-A80D-4A8147791A9D@python.org>
 <20181104151239.GA14162@xps>
 <20181104155017.GX3817@ando.pearwood.info>
 <CAGbohnYjfMtVBbSSZA=pNW_NNYMwc-WOy_L0V=pXij+tTUwfJw@mail.gmail.com>
Message-ID: <20181111143445.GA23982@xps>

Mariatta,

Do you think we could add a webhook for the build of the documentation
for each PR where the build of the doc works?

St?phane


-- 
St?phane Wirtel - https://wirtel.be - @matrixise

From steve at pearwood.info  Sun Nov 11 16:50:23 2018
From: steve at pearwood.info (Steven D'Aprano)
Date: Mon, 12 Nov 2018 08:50:23 +1100
Subject: [Python-Dev] Signalling NANs
In-Reply-To: <CAPJVwB=RwskV4tktgfnV-rdexqnKKyfZwkhEErNV5KhganXO1w@mail.gmail.com>
References: <20181109110507.GK4071@ando.pearwood.info>
 <ps3ru2$h6s$1@blaine.gmane.org>
 <CALGmxEKNMPbZa7vqMFZmbMdvXxb6py7qPu7zY_vGQ1OHfj302g@mail.gmail.com>
 <20181110232642.GS4071@ando.pearwood.info>
 <CAPJVwB=RwskV4tktgfnV-rdexqnKKyfZwkhEErNV5KhganXO1w@mail.gmail.com>
Message-ID: <20181111215023.GZ4071@ando.pearwood.info>

On Sat, Nov 10, 2018 at 04:27:29PM -0800, Nathaniel Smith wrote:

> Apparently loading a sNaN into an x87 register silently converts it to
> a qNaN, and on Linux C compilers are allowed to do that at any point:
> 
>    https://stackoverflow.com/questions/22816095/signalling-nan-was-corrupted-when-returning-from-x86-function-flds-fstps-of-x87

Thanks for finding that.

> So the Debian/RH difference may just be different register allocation
> in two slightly different compiler versions.

The Debian box uses an ARM processor, so there's that difference too.


-- 
Steve

From greg.ewing at canterbury.ac.nz  Sun Nov 11 17:05:19 2018
From: greg.ewing at canterbury.ac.nz (Greg Ewing)
Date: Mon, 12 Nov 2018 11:05:19 +1300
Subject: [Python-Dev] Signalling NANs
In-Reply-To: <20181111215023.GZ4071@ando.pearwood.info>
References: <20181109110507.GK4071@ando.pearwood.info>
 <ps3ru2$h6s$1@blaine.gmane.org>
 <CALGmxEKNMPbZa7vqMFZmbMdvXxb6py7qPu7zY_vGQ1OHfj302g@mail.gmail.com>
 <20181110232642.GS4071@ando.pearwood.info>
 <CAPJVwB=RwskV4tktgfnV-rdexqnKKyfZwkhEErNV5KhganXO1w@mail.gmail.com>
 <20181111215023.GZ4071@ando.pearwood.info>
Message-ID: <5BE8A79F.70907@canterbury.ac.nz>

Steven D'Aprano wrote:

> The Debian box uses an ARM processor, so there's that difference too.

FWIW, I tried this on MacOSX 10.6 with an Intel Xeon and it also
seems to suppress sNaNs.

-- 
Greg

From vstinner at redhat.com  Sun Nov 11 18:19:24 2018
From: vstinner at redhat.com (Victor Stinner)
Date: Mon, 12 Nov 2018 00:19:24 +0100
Subject: [Python-Dev] Experiment an opt-in new C API for Python? (leave
 current API unchanged)
In-Reply-To: <CAPJVwBm73w6UZdvkddTnhavd+WmFU-L2pBKFG=u+mC=nY2Y6Qg@mail.gmail.com>
References: <CA+3bQGGcuo_-fdJwrisGP6+h6CuNzcErSoacaQySEb5h4nOQEQ@mail.gmail.com>
 <CAPJVwBmKHMMKypLDhjhkWHSE7HnHSh_irqaRfCug_+YL4jOtqw@mail.gmail.com>
 <CA+3bQGFg23bYrSmxtzkXsHAGbrA5EkjxOExOfwZiBmDPu3-jZQ@mail.gmail.com>
 <CAPJVwBm73w6UZdvkddTnhavd+WmFU-L2pBKFG=u+mC=nY2Y6Qg@mail.gmail.com>
Message-ID: <CA+3bQGH2bk6Fv_EPnrndRTPVmnX_w4Q4RTkKv6Kx8cXSOJxJiA@mail.gmail.com>

Le sam. 10 nov. 2018 ? 04:02, Nathaniel Smith <njs at pobox.com> a ?crit :
> So is it fair to say that your plan is that CPython will always use
> the current ("old") API internally, and the "new" API will be
> essentially an abstraction layer, that's designed to let people write
> C extensions that target the old API, while also being flexible enough
> to target PyPy and other "new different Python runtimes"?

What we call is "Python C API" is not really an API. I mean, nobody
tried to sit down and think about a proper API to access Python from
C. We happened is that we had an implementation of Python written in C
and it was cool to just "expose everything". By everything, I mean
"everything". It's hard to find a secret CPython feature not exposed
or leaked in the C API.

The problem that I'm trying to solve to "fix the C API" to hide
implementation details, with one constraint: don't create a new
"Python 4". I don't want to break the backward compatibility without
having a slow and smooth transition plan. The "old" and new C API must
be supported in parallel, at least in the standard CPython,
/usr/bin/python3.

Writing a new API from scratch is nice, but it's harder to moving all
existing C extensions from the "old" C API to a new one.

Replacing macros with functions has little impact on backward
compatibility. Most C extensions should still work if macros become
functions.

I'm not sure yet how far we should go towards a perfect API which
doesn't leak everything. We have to move slowly, and make sure that we
don't break major C extensions. We need to write tools to fully
automate the conversion. If it's not possible, maybe the whole project
will fail.

I'm looking for a practical solutions based on the existing C API and
the existing CPython code base.

> If so, then would it make more sense to develop this as an actual
> separate abstraction layer? That would have the huge advantage that it
> could be distributed and versioned separately from CPython, different
> packages could use different versions of the abstraction layer, PyPy
> isn't forced to immediately add a bunch of new APIs...

I didn't investigate this option. But I expect that you will have to
write a full new API using a different prefix than "Py_". Otherwise,
I'm not sure how you want to handle PyTuple_GET_ITEM() as a macro on
one side (Include/tupleobject.h) and PyTuple_GET_ITEM() on the other
side (hypotetical_new_api.h).

Would it mean to duplicate all functions to get a different prefix?

If you keep the "Py_" prefix, what I would like to ensure is that some
functions are no longer accessible. How you remove
PySequence_Fast_GET_ITEM() for example?

For me, it seems simpler to modify CPython headers than starting on
something new. It seems simpler to choose the proper level of
compatibility. I start from an API 100% compatible (the current C
API), and decide what is changed and how.

Victor

From greg at krypto.org  Tue Nov 13 01:46:30 2018
From: greg at krypto.org (Gregory P. Smith)
Date: Mon, 12 Nov 2018 22:46:30 -0800
Subject: [Python-Dev] Experiment an opt-in new C API for Python? (leave
 current API unchanged)
In-Reply-To: <CAPJVwBmKHMMKypLDhjhkWHSE7HnHSh_irqaRfCug_+YL4jOtqw@mail.gmail.com>
References: <CA+3bQGGcuo_-fdJwrisGP6+h6CuNzcErSoacaQySEb5h4nOQEQ@mail.gmail.com>
 <CAPJVwBmKHMMKypLDhjhkWHSE7HnHSh_irqaRfCug_+YL4jOtqw@mail.gmail.com>
Message-ID: <CAGE7PNJeKGiVA5i8=Xrh6bRS7M=AURUPr8TjadQXEhCQuNwbWw@mail.gmail.com>

On Fri, Nov 9, 2018 at 5:50 PM Nathaniel Smith <njs at pobox.com> wrote:

> On Fri, Nov 9, 2018 at 4:30 PM, Victor Stinner <vstinner at redhat.com>
> wrote:
> > Ah, important points. I don't want to touch the current C API nor make
> > it less efficient. And compatibility in both directions (current C API
> > <=> new C API) is very important for me. There is no such plan as
> > "Python 4" which would break the world and *force* everybody to
> > upgrade to the new C API, or stay to Python 3 forever. No. The new C
> > API must be an opt-in option, and current C API remains the default
> > and not be changed.
>
> Doesn't this mean that you're just making the C API larger and more
> complicated, rather than simplifying it? You cite some benefits
> (tagged pointers, changing the layout of PyObject, making PyPy's life
> easier), but I don't see how you can do any of those things so long as
> the current C API remains supported.
>
> -n
>

I believe the implied missing thing from Victor's description is this:

Experimentation with new internal implementations can begin once we have a
new C API by explicitly breaking the old C API with-in such experiments (as
is required for most anything interesting).  All code that is written to
the new C API still works during this process, thus making the job of
practical testing of such new VM internals easier.

>From there, you can make decisions on how heavily to push the world towards
adoption of the new C API and by when so that a runtime not supporting the
old API can be realized with a list of enticing carrot tasting benefits.
(devising any necessary pypy cpyext-like compatibility solutions for super
long lived code or things that sadly want to use the 3.7 ABI for 10 years
in the process - and similarly an extension to provide some or all of this
API/ABI on top of older existing stable Python releases!)

I'd *love* to get to a situation where the only valid ABI we support knows
nothing about internal structs at all. Today, PyObject memory layout is
exposed to the world and unchangable. :(

This is a long process release wise (assume multiple stable releases go by
before we could declare that). But *we've got to start* by defining what we
want to provide as a seriously limited but functional API and ABI even if
it doesn't perform as well as things compiled against our existing
exposed-internals C API.  For *most* extension modules, performance of this
sort is not important. For the numpys of the world life is more
complicated, we should work with them to figure out their C API needs.

If it wasn't already obvious, you've got my support on this. :)
-gps

PS If the conversation devolves to arguing about "new" being a bad name,
that's a good sign.  I suggest calling it the Vorpal API after the bunny.
Or be boring and just use a year number for the name.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://mail.python.org/pipermail/python-dev/attachments/20181112/e2f2605e/attachment.html>

From greg at krypto.org  Tue Nov 13 02:13:19 2018
From: greg at krypto.org (Gregory P. Smith)
Date: Mon, 12 Nov 2018 23:13:19 -0800
Subject: [Python-Dev] Experiment an opt-in new C API for Python? (leave
 current API unchanged)
In-Reply-To: <CA+3bQGH2bk6Fv_EPnrndRTPVmnX_w4Q4RTkKv6Kx8cXSOJxJiA@mail.gmail.com>
References: <CA+3bQGGcuo_-fdJwrisGP6+h6CuNzcErSoacaQySEb5h4nOQEQ@mail.gmail.com>
 <CAPJVwBmKHMMKypLDhjhkWHSE7HnHSh_irqaRfCug_+YL4jOtqw@mail.gmail.com>
 <CA+3bQGFg23bYrSmxtzkXsHAGbrA5EkjxOExOfwZiBmDPu3-jZQ@mail.gmail.com>
 <CAPJVwBm73w6UZdvkddTnhavd+WmFU-L2pBKFG=u+mC=nY2Y6Qg@mail.gmail.com>
 <CA+3bQGH2bk6Fv_EPnrndRTPVmnX_w4Q4RTkKv6Kx8cXSOJxJiA@mail.gmail.com>
Message-ID: <CAGE7PN+ci_Pf_zsVDRssvdcnqmZrx=Q1n84XkwWUSNSTbnKuuw@mail.gmail.com>

On Sun, Nov 11, 2018 at 3:19 PM Victor Stinner <vstinner at redhat.com> wrote:

> Le sam. 10 nov. 2018 ? 04:02, Nathaniel Smith <njs at pobox.com> a ?crit :
> > So is it fair to say that your plan is that CPython will always use
> > the current ("old") API internally, and the "new" API will be
> > essentially an abstraction layer, that's designed to let people write
> > C extensions that target the old API, while also being flexible enough
> > to target PyPy and other "new different Python runtimes"?
>
> What we call is "Python C API" is not really an API. I mean, nobody
> tried to sit down and think about a proper API to access Python from
> C. We happened is that we had an implementation of Python written in C
> and it was cool to just "expose everything". By everything, I mean
> "everything". It's hard to find a secret CPython feature not exposed
> or leaked in the C API.
>
> The problem that I'm trying to solve to "fix the C API" to hide
> implementation details, with one constraint: don't create a new
> "Python 4". I don't want to break the backward compatibility without
> having a slow and smooth transition plan. The "old" and new C API must
> be supported in parallel, at least in the standard CPython,
> /usr/bin/python3.
>
> Writing a new API from scratch is nice, but it's harder to moving all
> existing C extensions from the "old" C API to a new one.
>
> Replacing macros with functions has little impact on backward
> compatibility. Most C extensions should still work if macros become
> functions.
>
> I'm not sure yet how far we should go towards a perfect API which
> doesn't leak everything. We have to move slowly, and make sure that we
> don't break major C extensions. We need to write tools to fully
> automate the conversion. If it's not possible, maybe the whole project
> will fail.
>
> I'm looking for a practical solutions based on the existing C API and
> the existing CPython code base.
>
> > If so, then would it make more sense to develop this as an actual
> > separate abstraction layer? That would have the huge advantage that it
> > could be distributed and versioned separately from CPython, different
> > packages could use different versions of the abstraction layer, PyPy
> > isn't forced to immediately add a bunch of new APIs...
>

I like where this thought is headed!

I didn't investigate this option. But I expect that you will have to
> write a full new API using a different prefix than "Py_". Otherwise,
> I'm not sure how you want to handle PyTuple_GET_ITEM() as a macro on
> one side (Include/tupleobject.h) and PyTuple_GET_ITEM() on the other
> side (hypotetical_new_api.h).
>
> Would it mean to duplicate all functions to get a different prefix?
>

For strict C, yes, namespacing has always been manual collision
avoidance/mangling.  You'd need a new unique name for anything defined as a
function that conflicts with the old C API function names.  You could hide
these from code if you are just reusing the name by using #define in the
new API header of the old name to the new unique name... but that makes
code a real challenge to read and understand at a glance.  Without
examining the header file imports the reader wouldn't know for example if
the code is calling the API that borrows a reference (old api, evil) or one
that gets its own reference (presumed new api).

When things have only ever been macros (Py_INCREF, etc) the name can be
reused if there has never been a function of that name in an old C API.
But beware of reuse for anything where the semantics change to avoid
misunderstandings about behavior from people familiar with the old API or
googling API names to look up behavior.

I suspect optimizing for ease of transition from code written to the
existing C API to the new API by keeping names the same is the wrong thing
to optimize for.

Using entirely new names may actually be a good thing as it makes it
immediately clear which way a given piece of code is written. It'd also be
good for PyObject* the old C API thing be a different type from
PythonHandle* (a new API thing who's name I just made up) such that they
could not be passed around and exchanged for one another without a compiler
complaint.  Code written using both APIs should not be allowed to transit
objects directly between different APIs.

-gps


>
> If you keep the "Py_" prefix, what I would like to ensure is that some
> functions are no longer accessible. How you remove
> PySequence_Fast_GET_ITEM() for example?
>
> For me, it seems simpler to modify CPython headers than starting on
> something new. It seems simpler to choose the proper level of
> compatibility. I start from an API 100% compatible (the current C
> API), and decide what is changed and how.
>
> Victor
> _______________________________________________
> Python-Dev mailing list
> Python-Dev at python.org
> https://mail.python.org/mailman/listinfo/python-dev
> Unsubscribe:
> https://mail.python.org/mailman/options/python-dev/greg%40krypto.org
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://mail.python.org/pipermail/python-dev/attachments/20181112/3db8ccdd/attachment.html>

From vstinner at redhat.com  Tue Nov 13 04:31:35 2018
From: vstinner at redhat.com (Victor Stinner)
Date: Tue, 13 Nov 2018 10:31:35 +0100
Subject: [Python-Dev] Experiment an opt-in new C API for Python? (leave
 current API unchanged)
In-Reply-To: <CAGE7PN+ci_Pf_zsVDRssvdcnqmZrx=Q1n84XkwWUSNSTbnKuuw@mail.gmail.com>
References: <CA+3bQGGcuo_-fdJwrisGP6+h6CuNzcErSoacaQySEb5h4nOQEQ@mail.gmail.com>
 <CAPJVwBmKHMMKypLDhjhkWHSE7HnHSh_irqaRfCug_+YL4jOtqw@mail.gmail.com>
 <CA+3bQGFg23bYrSmxtzkXsHAGbrA5EkjxOExOfwZiBmDPu3-jZQ@mail.gmail.com>
 <CAPJVwBm73w6UZdvkddTnhavd+WmFU-L2pBKFG=u+mC=nY2Y6Qg@mail.gmail.com>
 <CA+3bQGH2bk6Fv_EPnrndRTPVmnX_w4Q4RTkKv6Kx8cXSOJxJiA@mail.gmail.com>
 <CAGE7PN+ci_Pf_zsVDRssvdcnqmZrx=Q1n84XkwWUSNSTbnKuuw@mail.gmail.com>
Message-ID: <CA+3bQGF8r2M-97SZYDnUpQEha4HzDvxmvHCbdU3N1=N=KG7XRg@mail.gmail.com>

Le mar. 13 nov. 2018 ? 08:13, Gregory P. Smith <greg at krypto.org> a ?crit :
> When things have only ever been macros (Py_INCREF, etc) the name can be reused if there has never been a function of that name in an old C API.  But beware of reuse for anything where the semantics change to avoid misunderstandings about behavior from people familiar with the old API or googling API names to look up behavior.

My plan is to only keep an existing function if it has no flaw. If it
has a flaw, it should be removed and maybe replaced with a new
function (or suggest a replacement using existing APIs). I don't want
to modify the behavior depending if it's the "old" or the "new" API.
My plan reuses the same code base, I don't want to put the whole body
of a function inside a "#ifdef NEWCAPI".


> I suspect optimizing for ease of transition from code written to the existing C API to the new API by keeping names the same is the wrong thing to optimize for.

Not all functions in the current C API are bad. Many functions are
just fine. For example, PyObject_GetAttr() returns a strong reference.
I don't see anything wrong with this API. Only a small portion of the
C API is "bad".


> Using entirely new names may actually be a good thing as it makes it immediately clear which way a given piece of code is written. It'd also be good for PyObject* the old C API thing be a different type from PythonHandle* (a new API thing who's name I just made up) such that they could not be passed around and exchanged for one another without a compiler complaint.  Code written using both APIs should not be allowed to transit objects directly between different APIs.

On Windows, the HANDLE type is just an integer, it's not a pointer. If
it's a pointer, some developer may want to dereference it, whereas it
must really be a dummy integer. Consider tagged pointers: you don't
want to dereferenced a tagged pointer. But no, I don't plan to replace
"PyObject*". Again, I want to reduce the number of changes. If the
PyObject structure is not exposed, I don't think that it's an issue to
keep "PyObject*" type.

Example:
---
#include <stddef.h>

typedef struct _object PyObject;

PyObject* dummy(void)
{
    return (PyObject *)NULL;
}

int main()
{
    PyObject *obj = dummy();
    return obj->ob_type;
}
---

This program is valid, except of the single line which attempts to
dereference PyObject*:

x.c: In function 'main':
x.c:13:15: error: dereferencing pointer to incomplete type 'PyObject
{aka struct _object}'
     return obj->ob_type;

If I could restart from scratch, I would design the C API differently.
For example, I'm not sure that I would use "global variables" (Python
thread state) to store the current exception. I would use similar like
Rust error handling:
https://doc.rust-lang.org/book/first-edition/error-handling.html

But that's not my plan. My plan is not to write a new bright world. My
plan is to make a "small step" towards a better API to make PyPy more
efficient and to allow to write a new more optimized CPython.

I also plan to *iterate* on the API rather than having a frozen API.
It's just that we cannot jump towards the perfect API at once. We need
small steps and make sure that we don't break too many C extensions at
each milestone. Maybe the new API should be versioned as Android NDK
for example.

Victor

From nd at perlig.de  Tue Nov 13 14:21:59 2018
From: nd at perlig.de (=?ISO-8859-1?Q?Andr=E9?= Malo)
Date: Tue, 13 Nov 2018 20:21:59 +0100
Subject: [Python-Dev] Experiment an opt-in new C API for Python? (leave
 current API unchanged)
In-Reply-To: <CA+3bQGH2bk6Fv_EPnrndRTPVmnX_w4Q4RTkKv6Kx8cXSOJxJiA@mail.gmail.com>
References: <CA+3bQGGcuo_-fdJwrisGP6+h6CuNzcErSoacaQySEb5h4nOQEQ@mail.gmail.com>
 <CAPJVwBm73w6UZdvkddTnhavd+WmFU-L2pBKFG=u+mC=nY2Y6Qg@mail.gmail.com>
 <CA+3bQGH2bk6Fv_EPnrndRTPVmnX_w4Q4RTkKv6Kx8cXSOJxJiA@mail.gmail.com>
Message-ID: <1614616.psXdYk7axO@chryseis>

Victor Stinner wrote:

> Replacing macros with functions has little impact on backward
> compatibility. Most C extensions should still work if macros become
> functions.

As long as they are recompiled. However, they will lose a lot of performance. 
Both these points have been mentioned somewhere, I'm certain, but it cannot be 
stressed enough, IMHO.

> 
> I'm not sure yet how far we should go towards a perfect API which
> doesn't leak everything. We have to move slowly, and make sure that we
> don't break major C extensions. We need to write tools to fully
> automate the conversion. If it's not possible, maybe the whole project
> will fail.

I'm wondering, how you suggest to measure "major". I believe, every C 
extension, which is public and running in production somewhere, is major 
enough.

Maybe "easiness to fix"? Lines of code?

Cheers,
-- 
> R?tselnd, was ein Anthroposoph mit Unterwerfung zu tun hat...
                    ^^^^^^^^^^^^
[...] Dieses Wort gibt so viele Stellen f?r einen Spelling Flame her, und
Du g?nnst einem keine einzige.    -- Jean Claude und David Kastrup in dtl



From nd at perlig.de  Tue Nov 13 14:32:03 2018
From: nd at perlig.de (=?ISO-8859-1?Q?Andr=E9?= Malo)
Date: Tue, 13 Nov 2018 20:32:03 +0100
Subject: [Python-Dev] Experiment an opt-in new C API for Python? (leave
 current API unchanged)
In-Reply-To: <CA+3bQGH2bk6Fv_EPnrndRTPVmnX_w4Q4RTkKv6Kx8cXSOJxJiA@mail.gmail.com>
References: <CA+3bQGGcuo_-fdJwrisGP6+h6CuNzcErSoacaQySEb5h4nOQEQ@mail.gmail.com>
 <CAPJVwBm73w6UZdvkddTnhavd+WmFU-L2pBKFG=u+mC=nY2Y6Qg@mail.gmail.com>
 <CA+3bQGH2bk6Fv_EPnrndRTPVmnX_w4Q4RTkKv6Kx8cXSOJxJiA@mail.gmail.com>
Message-ID: <3346184.CCZ30flunD@chryseis>

Victor Stinner wrote:

> Replacing macros with functions has little impact on backward
> compatibility. Most C extensions should still work if macros become
> functions.

As long as they are recompiled. However, they will lose a lot of performance. 
Both these points have been mentioned somewhere, I'm certain, but it cannot be 
stressed enough, IMHO.

> 
> I'm not sure yet how far we should go towards a perfect API which
> doesn't leak everything. We have to move slowly, and make sure that we
> don't break major C extensions. We need to write tools to fully
> automate the conversion. If it's not possible, maybe the whole project
> will fail.

I'm wondering, how you suggest to measure "major". I believe, every C 
extension, which is public and running in production somewhere, is major 
enough.

Maybe "easiness to fix"? Lines of code?

Cheers,
-- 
> R?tselnd, was ein Anthroposoph mit Unterwerfung zu tun hat...
                    ^^^^^^^^^^^^
Du g?nnst einem keine einzige.    -- Jean Claude und David Kastrup in dtl[...] 
Dieses Wort gibt so viele Stellen f?r einen Spelling Flame her, und



From vstinner at redhat.com  Tue Nov 13 15:59:14 2018
From: vstinner at redhat.com (Victor Stinner)
Date: Tue, 13 Nov 2018 21:59:14 +0100
Subject: [Python-Dev] Experiment an opt-in new C API for Python? (leave
 current API unchanged)
In-Reply-To: <1614616.psXdYk7axO@chryseis>
References: <CA+3bQGGcuo_-fdJwrisGP6+h6CuNzcErSoacaQySEb5h4nOQEQ@mail.gmail.com>
 <CAPJVwBm73w6UZdvkddTnhavd+WmFU-L2pBKFG=u+mC=nY2Y6Qg@mail.gmail.com>
 <CA+3bQGH2bk6Fv_EPnrndRTPVmnX_w4Q4RTkKv6Kx8cXSOJxJiA@mail.gmail.com>
 <1614616.psXdYk7axO@chryseis>
Message-ID: <CA+3bQGFdafXR12MfQBzWz3jQf1VsKWeqgWhjNJ5dgaXphBSp+g@mail.gmail.com>

Le mar. 13 nov. 2018 ? 20:32, Andr? Malo <nd at perlig.de> a ?crit :
> As long as they are recompiled. However, they will lose a lot of performance.
> Both these points have been mentioned somewhere, I'm certain, but it cannot be
> stressed enough, IMHO.

Somewhere is here:
https://pythoncapi.readthedocs.io/performance.html

> I'm wondering, how you suggest to measure "major". I believe, every C
> extension, which is public and running in production somewhere, is major
> enough.

My plan is to select something like the top five most popular C
extensions based on PyPI download statistics. I cannot test
everything, I have to put practical limits.

Victor

From njs at pobox.com  Tue Nov 13 21:24:46 2018
From: njs at pobox.com (Nathaniel Smith)
Date: Tue, 13 Nov 2018 18:24:46 -0800
Subject: [Python-Dev] Experiment an opt-in new C API for Python? (leave
 current API unchanged)
In-Reply-To: <CAGE7PNJeKGiVA5i8=Xrh6bRS7M=AURUPr8TjadQXEhCQuNwbWw@mail.gmail.com>
References: <CA+3bQGGcuo_-fdJwrisGP6+h6CuNzcErSoacaQySEb5h4nOQEQ@mail.gmail.com>
 <CAPJVwBmKHMMKypLDhjhkWHSE7HnHSh_irqaRfCug_+YL4jOtqw@mail.gmail.com>
 <CAGE7PNJeKGiVA5i8=Xrh6bRS7M=AURUPr8TjadQXEhCQuNwbWw@mail.gmail.com>
Message-ID: <CAPJVwBnHefR1R84gC9Z2LzCZCd0VTV5ZR+m=+ri2spk6e2HZXA@mail.gmail.com>

On Mon, Nov 12, 2018 at 10:46 PM, Gregory P. Smith <greg at krypto.org> wrote:
>
> On Fri, Nov 9, 2018 at 5:50 PM Nathaniel Smith <njs at pobox.com> wrote:
>>
>> On Fri, Nov 9, 2018 at 4:30 PM, Victor Stinner <vstinner at redhat.com>
>> wrote:
>> > Ah, important points. I don't want to touch the current C API nor make
>> > it less efficient. And compatibility in both directions (current C API
>> > <=> new C API) is very important for me. There is no such plan as
>> > "Python 4" which would break the world and *force* everybody to
>> > upgrade to the new C API, or stay to Python 3 forever. No. The new C
>> > API must be an opt-in option, and current C API remains the default
>> > and not be changed.
>>
>> Doesn't this mean that you're just making the C API larger and more
>> complicated, rather than simplifying it? You cite some benefits
>> (tagged pointers, changing the layout of PyObject, making PyPy's life
>> easier), but I don't see how you can do any of those things so long as
>> the current C API remains supported.
[...]
> I'd love to get to a situation where the only valid ABI we support knows nothing about internal structs at all. Today, PyObject memory layout is exposed to the world and unchangable. :(
> This is a long process release wise (assume multiple stable releases go by before we could declare that).

It seems like the discussion so far is:

Victor: "I know people when people hear 'new API' they get scared and
think we're going to do a Python-3-like breaking transition, but don't
worry, we're never going to do that."
Nathaniel: "But then what does the new API add?"
Greg: "It lets us do a Python-3-like breaking transition!"

To make a new API work we need to *either* have some plan for how it
will produce benefits without a big breaking transition, *or* some
plan for how to make this kind of transition viable. These are both
super super hard questions -- that's why this discussion has been
dragging on for a decade now! But you do have to pick one or the other
:-).

> Experimentation with new internal implementations can begin once we have a new C API by explicitly breaking the old C API with-in such experiments (as is required for most anything interesting).  All code that is written to the new C API still works during this process, thus making the job of practical testing of such new VM internals easier.

So I think what you're saying is that your goal is to get a
new/better/shinier VM, and the plan to accomplish that is:

1. Define a new C API.
2. Migrate projects to the new C API.
3. Build a new VM that gets benefits from only supporting the new API.

This sounds exactly backwards to me?

If you define the new API before you build the VM, then no-one is
going to migrate, because why should they bother? You'd be asking
overworked third-party maintainers to do a bunch of work with no
benefit, except that maybe someday later something good might happen.

And if you define the new API first, then when you start building the
VM you're 100% guaranteed to discover that the new API isn't *quite*
right for the optimizations you want to do, and have to change it
again to make a new-new API. And then go back to the maintainers who
you did convince to put their neck out and do work on spec, and
explain that haha whoops actually they need to update their code
*again*.

There have been lots of Python VM projects at this point. They've
faced many challenges, but I don't think any have failed because there
just wasn't enough pure-Python code around to test the VM internals.
If I were trying to build a new Python VM, that's not even in the top
10 of issues I'd be worried about...

-n

-- 
Nathaniel J. Smith -- https://vorpus.org

From raymond.hettinger at gmail.com  Tue Nov 13 22:06:35 2018
From: raymond.hettinger at gmail.com (Raymond Hettinger)
Date: Tue, 13 Nov 2018 19:06:35 -0800
Subject: [Python-Dev] General concerns about C API changes
Message-ID: <62A87B15-0F0E-4242-BF44-9C58FE890D8B@gmail.com>

Overall, I support the efforts to improve the C API, but over the last few weeks have become worried.  I don't want to hold up progress with fear, uncertainty, and doubt.  Yet, I would like to be more comfortable that we're all aware of what is occurring and what are the potential benefits and risks.

* Inline functions are great.  They provide true local variables, better separation of concerns, are far less kludgy than text based macro substitution, and will typically generate the same code as the equivalent macro.  This is good tech when used with in a single source file where it has predictable results.   

However, I'm not at all confident about moving these into header files which are included in multiple target .c files which need be compiled into separate .o files and linked to other existing libraries.

With a macro, I know for sure that the substitution is taking place.  This happens at all levels of optimization and in a debug mode.  The effects are 100% predictable and have a well-established track record in our mature battle-tested code base.  With cross module function calls, I'm less confident about what is happening, partly because compilers are free to ignore inline directives and partly because the semantics of inlining are less clear when the crossing module boundaries.

* Other categories of changes that we make tend to have only a shallow reach.  However, these C API changes will likely touch every C extension that has ever been written, some of which is highly tuned but not actively re-examined.  If any mistakes are make, they will likely be pervasive.  Accordingly, caution is warranted.

My expectation was that the changes would be conducted in experimental branches. But extensive changes are already being made (or about to be made) on the 3.8 master. If a year from now, we decide that the changes were destabilizing or that the promised benefits didn't materialize, they will be difficult to undo because there are so many of them and because they will be interleaved with other changes.

The original motivation was to achieve a 2x speedup in return for significantly churning the C API. However, the current rearranging of the include files and macro-to-inline-function changes only give us churn.  At the very best, they will be performance neutral.  At worst, formerly cheap macro calls will become expensive in places that we haven't thought to run timings on.  Given that compilers don't have to honor an inline directive, we can't really know for sure -- perhaps today it works out fine, and perhaps tomorrow the compilers opt for a different behavior.

Maybe everything that is going on is fine.  Maybe it's not. I am not expert enough to know for sure, but we should be careful before green-lighting such an extensive series of changes directly to master.  Reasonable questions to ask are: 1) What are the risks to third party modules, 2) Do we really know that the macro-to-inline-function transformations are semantically neutral. 3) If there is no performance benefit (none has been seen so far, nor is any promised in the pending PRs), is it worth it?  

We do know that PyPy folks have had their share of issues with the C API, but I'm not sure that we can make any of this go away without changing the foundations of the whole ecosystem.  It is inconvenient for a full GC environment to interact with the API for a reference counted environment -- I don't think we can make this challenge go away without giving up reference counting.  It is inconvenient for a system that manifests objects on demand to interact with an API that assumes that objects have identity and never more once they are created -- I don't think we can make this go away either.  It is inconvenient to a system that uses unboxed data to interact with our API where everything is an object that includes a type pointer and reference count -- We have provided an API for boxing and boxing, but the trip back-and-forth is inconveniently expensive -- I don't think we can make that go away either because too much of the ecosystem depends on that API.  There are some things that can be mitigated such as challenges with borrowed references but that doesn't seem to have been the focus on any of the PRs.

In short, I'm somewhat concerned about the extensive changes that are occurring.  I do know they will touch substantially every C module in the entire ecosystem.  I don't know whether they are safe or whether they will give any real benefit.

FWIW, none of this is a criticism of the work being done.  Someone needs to think deeply about the C API or else progress will never be made.  That said, it is a high risk project with many PRs going directly into master, so it does warrant having buy in that the churn isn't destabilizing and will actually produce a benefit that is worth it.


Raymond








From njs at pobox.com  Tue Nov 13 22:17:31 2018
From: njs at pobox.com (Nathaniel Smith)
Date: Tue, 13 Nov 2018 19:17:31 -0800
Subject: [Python-Dev] Experiment an opt-in new C API for Python? (leave
 current API unchanged)
In-Reply-To: <CA+3bQGH2bk6Fv_EPnrndRTPVmnX_w4Q4RTkKv6Kx8cXSOJxJiA@mail.gmail.com>
References: <CA+3bQGGcuo_-fdJwrisGP6+h6CuNzcErSoacaQySEb5h4nOQEQ@mail.gmail.com>
 <CAPJVwBmKHMMKypLDhjhkWHSE7HnHSh_irqaRfCug_+YL4jOtqw@mail.gmail.com>
 <CA+3bQGFg23bYrSmxtzkXsHAGbrA5EkjxOExOfwZiBmDPu3-jZQ@mail.gmail.com>
 <CAPJVwBm73w6UZdvkddTnhavd+WmFU-L2pBKFG=u+mC=nY2Y6Qg@mail.gmail.com>
 <CA+3bQGH2bk6Fv_EPnrndRTPVmnX_w4Q4RTkKv6Kx8cXSOJxJiA@mail.gmail.com>
Message-ID: <CAPJVwB=iKT7733oaraoHe3OHbTdoANtUV29WbnB=_Dah3jXVtg@mail.gmail.com>

On Sun, Nov 11, 2018 at 3:19 PM, Victor Stinner <vstinner at redhat.com> wrote:
> I'm not sure yet how far we should go towards a perfect API which
> doesn't leak everything. We have to move slowly, and make sure that we
> don't break major C extensions. We need to write tools to fully
> automate the conversion. If it's not possible, maybe the whole project
> will fail.

This is why I'm nervous about adding this directly to CPython. If
we're just talking about adding a few new API calls to replace old
ones that are awkward to use, then that's fine, that's not very risky.
But if you're talking about a large project that makes fundamental
changes in the C API (e.g., disallowing pointer dereferences, like
tagged pointers do), then yeah, there's a very large risk that that
might fail.

>> If so, then would it make more sense to develop this as an actual>> separate abstraction layer? That would have the huge advantage that it
>> could be distributed and versioned separately from CPython, different
>> packages could use different versions of the abstraction layer, PyPy
>> isn't forced to immediately add a bunch of new APIs...
>
> I didn't investigate this option. But I expect that you will have to
> write a full new API using a different prefix than "Py_". Otherwise,
> I'm not sure how you want to handle PyTuple_GET_ITEM() as a macro on
> one side (Include/tupleobject.h) and PyTuple_GET_ITEM() on the other
> side (hypotetical_new_api.h).
>
> Would it mean to duplicate all functions to get a different prefix?
>
> If you keep the "Py_" prefix, what I would like to ensure is that some
> functions are no longer accessible. How you remove
> PySequence_Fast_GET_ITEM() for example?
>
> For me, it seems simpler to modify CPython headers than starting on
> something new. It seems simpler to choose the proper level of
> compatibility. I start from an API 100% compatible (the current C
> API), and decide what is changed and how.

It may be simpler, but it's hugely more risky. Once you add something
to CPython, you can't take it back again without a huge amount of
work. You said above that the whole project might fail. But if it's in
CPython, failure is not acceptable! The whole problem you're trying to
solve is that the C API is too big, but your proposed solution starts
by making it bigger, so if your project fails then it makes the
problem even bigger...

I don't know if making it a separate project is the best approach or
not, it was just an idea :-). But it would have the huge benefit that
you can actually experiment and try things out without committing to
supporting them forever.

And I don't know the best answer to all your questions above, that's
what experimenting is for :-). But it certainly is technically
possible to make a new API that shares a common subset with the old
API, e.g.:

/* NewPython.h */
#include <Python.h>
#define PyTuple_GET_ITEM PyTuple_Get_Item
#undef PySequence_Fast_GET_ITEM

-n

-- 
Nathaniel J. Smith -- https://vorpus.org

From njs at pobox.com  Tue Nov 13 23:40:48 2018
From: njs at pobox.com (Nathaniel Smith)
Date: Tue, 13 Nov 2018 20:40:48 -0800
Subject: [Python-Dev] General concerns about C API changes
In-Reply-To: <62A87B15-0F0E-4242-BF44-9C58FE890D8B@gmail.com>
References: <62A87B15-0F0E-4242-BF44-9C58FE890D8B@gmail.com>
Message-ID: <CAPJVwBmROGz0Nzmoiu0w_riEbkuaDRX9_fKHmEwVBm+pw5k=Xw@mail.gmail.com>

To me, the "new C API" discussion and the "converting macros into
inline functions" discussions are very different, almost unrelated.
There are always lots of small C API changes happening, and AFAIK the
macros->inline changes fall into that category. It sounds like you
want to discuss whether inline functions are a good idea? Or are there
other changes happening that you're worried about? Or is there some
connection between inline functions and API breakage that I'm not
aware of? Your email touches on a lot of different topics and I'm
having trouble understanding how they fit together. (And I guess like
most people here, I'm not watching every commit to the master branch
so I may not even know what changes you're referring to.)

On Tue, Nov 13, 2018 at 7:06 PM, Raymond Hettinger
<raymond.hettinger at gmail.com> wrote:
> Overall, I support the efforts to improve the C API, but over the last few weeks have become worried.  I don't want to hold up progress with fear, uncertainty, and doubt.  Yet, I would like to be more comfortable that we're all aware of what is occurring and what are the potential benefits and risks.
>
> * Inline functions are great.  They provide true local variables, better separation of concerns, are far less kludgy than text based macro substitution, and will typically generate the same code as the equivalent macro.  This is good tech when used with in a single source file where it has predictable results.
>
> However, I'm not at all confident about moving these into header files which are included in multiple target .c files which need be compiled into separate .o files and linked to other existing libraries.
>
> With a macro, I know for sure that the substitution is taking place.  This happens at all levels of optimization and in a debug mode.  The effects are 100% predictable and have a well-established track record in our mature battle-tested code base.  With cross module function calls, I'm less confident about what is happening, partly because compilers are free to ignore inline directives and partly because the semantics of inlining are less clear when the crossing module boundaries.
>
> * Other categories of changes that we make tend to have only a shallow reach.  However, these C API changes will likely touch every C extension that has ever been written, some of which is highly tuned but not actively re-examined.  If any mistakes are make, they will likely be pervasive.  Accordingly, caution is warranted.
>
> My expectation was that the changes would be conducted in experimental branches. But extensive changes are already being made (or about to be made) on the 3.8 master. If a year from now, we decide that the changes were destabilizing or that the promised benefits didn't materialize, they will be difficult to undo because there are so many of them and because they will be interleaved with other changes.
>
> The original motivation was to achieve a 2x speedup in return for significantly churning the C API. However, the current rearranging of the include files and macro-to-inline-function changes only give us churn.  At the very best, they will be performance neutral.  At worst, formerly cheap macro calls will become expensive in places that we haven't thought to run timings on.  Given that compilers don't have to honor an inline directive, we can't really know for sure -- perhaps today it works out fine, and perhaps tomorrow the compilers opt for a different behavior.
>
> Maybe everything that is going on is fine.  Maybe it's not. I am not expert enough to know for sure, but we should be careful before green-lighting such an extensive series of changes directly to master.  Reasonable questions to ask are: 1) What are the risks to third party modules, 2) Do we really know that the macro-to-inline-function transformations are semantically neutral. 3) If there is no performance benefit (none has been seen so far, nor is any promised in the pending PRs), is it worth it?
>
> We do know that PyPy folks have had their share of issues with the C API, but I'm not sure that we can make any of this go away without changing the foundations of the whole ecosystem.  It is inconvenient for a full GC environment to interact with the API for a reference counted environment -- I don't think we can make this challenge go away without giving up reference counting.  It is inconvenient for a system that manifests objects on demand to interact with an API that assumes that objects have identity and never more once they are created -- I don't think we can make this go away either.  It is inconvenient to a system that uses unboxed data to interact with our API where everything is an object that includes a type pointer and reference count -- We have provided an API for boxing and boxing, but the trip back-and-forth is inconveniently expensive -- I don't think we can make that go away either because too much of the ecosystem depends on that API.  There are some things that ca
>  n be mitigated such as challenges with borrowed references but that doesn't seem to have been the focus on any of the PRs.
>
> In short, I'm somewhat concerned about the extensive changes that are occurring.  I do know they will touch substantially every C module in the entire ecosystem.  I don't know whether they are safe or whether they will give any real benefit.
>
> FWIW, none of this is a criticism of the work being done.  Someone needs to think deeply about the C API or else progress will never be made.  That said, it is a high risk project with many PRs going directly into master, so it does warrant having buy in that the churn isn't destabilizing and will actually produce a benefit that is worth it.
>
>
> Raymond
>
>
>
>
>
>
>
> _______________________________________________
> Python-Dev mailing list
> Python-Dev at python.org
> https://mail.python.org/mailman/listinfo/python-dev
> Unsubscribe: https://mail.python.org/mailman/options/python-dev/njs%40pobox.com



-- 
Nathaniel J. Smith -- https://vorpus.org

From vstinner at redhat.com  Wed Nov 14 05:03:49 2018
From: vstinner at redhat.com (Victor Stinner)
Date: Wed, 14 Nov 2018 11:03:49 +0100
Subject: [Python-Dev] Experiment an opt-in new C API for Python? (leave
 current API unchanged)
In-Reply-To: <CAPJVwBnHefR1R84gC9Z2LzCZCd0VTV5ZR+m=+ri2spk6e2HZXA@mail.gmail.com>
References: <CA+3bQGGcuo_-fdJwrisGP6+h6CuNzcErSoacaQySEb5h4nOQEQ@mail.gmail.com>
 <CAPJVwBmKHMMKypLDhjhkWHSE7HnHSh_irqaRfCug_+YL4jOtqw@mail.gmail.com>
 <CAGE7PNJeKGiVA5i8=Xrh6bRS7M=AURUPr8TjadQXEhCQuNwbWw@mail.gmail.com>
 <CAPJVwBnHefR1R84gC9Z2LzCZCd0VTV5ZR+m=+ri2spk6e2HZXA@mail.gmail.com>
Message-ID: <CA+3bQGGizLP=DbRG1tZ15sXFWuEMjL+hdTw-noX1BY=kcDpAVA@mail.gmail.com>

Le mer. 14 nov. 2018 ? 03:24, Nathaniel Smith <njs at pobox.com> a ?crit :
> So I think what you're saying is that your goal is to get a
> new/better/shinier VM, and the plan to accomplish that is:
>
> 1. Define a new C API.
> 2. Migrate projects to the new C API.
> 3. Build a new VM that gets benefits from only supporting the new API.
>
> This sounds exactly backwards to me?
>
> If you define the new API before you build the VM, then no-one is
> going to migrate, because why should they bother? You'd be asking
> overworked third-party maintainers to do a bunch of work with no
> benefit, except that maybe someday later something good might happen.

Oh, I should stop to promote my "CPython fork" idea.

There is already an existing VM which is way faster than CPython but
its performances are limited by the current C API. The VM is called...
PyPy!

The bet is that migrating to a new C API would make your C extension faster.

Victor

From solipsis at pitrou.net  Wed Nov 14 05:20:55 2018
From: solipsis at pitrou.net (Antoine Pitrou)
Date: Wed, 14 Nov 2018 11:20:55 +0100
Subject: [Python-Dev] Experiment an opt-in new C API for Python? (leave
 current API unchanged)
References: <CA+3bQGGcuo_-fdJwrisGP6+h6CuNzcErSoacaQySEb5h4nOQEQ@mail.gmail.com>
 <CAPJVwBmKHMMKypLDhjhkWHSE7HnHSh_irqaRfCug_+YL4jOtqw@mail.gmail.com>
 <CAGE7PNJeKGiVA5i8=Xrh6bRS7M=AURUPr8TjadQXEhCQuNwbWw@mail.gmail.com>
 <CAPJVwBnHefR1R84gC9Z2LzCZCd0VTV5ZR+m=+ri2spk6e2HZXA@mail.gmail.com>
 <CA+3bQGGizLP=DbRG1tZ15sXFWuEMjL+hdTw-noX1BY=kcDpAVA@mail.gmail.com>
Message-ID: <20181114112055.2131d35b@fsol>

On Wed, 14 Nov 2018 11:03:49 +0100
Victor Stinner <vstinner at redhat.com> wrote:
> 
> Oh, I should stop to promote my "CPython fork" idea.
> 
> There is already an existing VM which is way faster than CPython but
> its performances are limited by the current C API. The VM is called...
> PyPy!
> 
> The bet is that migrating to a new C API would make your C extension faster.

Faster on PyPy... but potentially slower on CPython.  That's what we
(you :-)) need to investigate and solve.  Those macros and inline
functions are actually important for many use cases.

For example in PyArrow we use PySequence_Fast_GET_ITEM() (*) and even
PyType_HasFeature() (**) (to quickly check for multiple base types with
a single fetch and comparison).

(*)
https://github.com/apache/arrow/blob/master/cpp/src/arrow/python/iterators.h#L39-L86
(**)
https://github.com/apache/arrow/blob/master/cpp/src/arrow/python/helpers.cc#L266-L299

Regards

Antoine.



From vstinner at redhat.com  Wed Nov 14 05:48:15 2018
From: vstinner at redhat.com (Victor Stinner)
Date: Wed, 14 Nov 2018 11:48:15 +0100
Subject: [Python-Dev] Experiment an opt-in new C API for Python? (leave
 current API unchanged)
In-Reply-To: <20181114112055.2131d35b@fsol>
References: <CA+3bQGGcuo_-fdJwrisGP6+h6CuNzcErSoacaQySEb5h4nOQEQ@mail.gmail.com>
 <CAPJVwBmKHMMKypLDhjhkWHSE7HnHSh_irqaRfCug_+YL4jOtqw@mail.gmail.com>
 <CAGE7PNJeKGiVA5i8=Xrh6bRS7M=AURUPr8TjadQXEhCQuNwbWw@mail.gmail.com>
 <CAPJVwBnHefR1R84gC9Z2LzCZCd0VTV5ZR+m=+ri2spk6e2HZXA@mail.gmail.com>
 <CA+3bQGGizLP=DbRG1tZ15sXFWuEMjL+hdTw-noX1BY=kcDpAVA@mail.gmail.com>
 <20181114112055.2131d35b@fsol>
Message-ID: <CA+3bQGHhVjvwScaaMsnW1A2m3+F4JDV9wsa+r0F=tjnCVOce+A@mail.gmail.com>

Le mer. 14 nov. 2018 ? 11:24, Antoine Pitrou <solipsis at pitrou.net> a ?crit :
> For example in PyArrow we use PySequence_Fast_GET_ITEM() (*)

Maybe PyArrow is a kind of C extension which should have one
implementation for the new C API (PyPy) and one implementation for the
current C API (CPython)?

Cython can be used to generate two different C code from the same
source code using a different compilation mode.

> and even
> PyType_HasFeature() (**) (to quickly check for multiple base types with
> a single fetch and comparison).

I'm not sure that PyType_HasFeature() is an issue?

Victor

From vstinner at redhat.com  Wed Nov 14 06:23:03 2018
From: vstinner at redhat.com (Victor Stinner)
Date: Wed, 14 Nov 2018 12:23:03 +0100
Subject: [Python-Dev] General concerns about C API changes
In-Reply-To: <CAPJVwBmROGz0Nzmoiu0w_riEbkuaDRX9_fKHmEwVBm+pw5k=Xw@mail.gmail.com>
References: <62A87B15-0F0E-4242-BF44-9C58FE890D8B@gmail.com>
 <CAPJVwBmROGz0Nzmoiu0w_riEbkuaDRX9_fKHmEwVBm+pw5k=Xw@mail.gmail.com>
Message-ID: <CA+3bQGHx-GtLzgvDeWtTrK0W857DOYF=bBmjTSfTBTanUEyXQg@mail.gmail.com>

Hi,

I made many different kinds of changes to the C API last weeks. None
of them should impact the backward compatibility. If it's the case,
the changes causing the backward compatibility should be reverted. The
most controversial changes are the conversion of macros to static
inline functions, but these changes have been discussed in length and
approved by multiple core developers.


(*) Move private internal API outside Include/: continue the work
started in Python 3.7 to move it to Include/internal/

This work is almost complete. The remaining issue is the
_PyObject_GC_TRACK() function.

The main change is that an explicit #include "pycore_<header>.h" is
now required in C code.

https://bugs.python.org/issue35081
https://mail.python.org/pipermail/python-dev/2018-October/155587.html
https://mail.python.org/pipermail/python-dev/2018-November/155688.html


(*) Move "unstable" API outside Include/: move "#ifndef
Py_LIMITED_API" code to a new subdirectory

This work didn't start. It's still being discussed to see how we
should do it. I chose to try to finish Include/internal/ first.

https://bugs.python.org/issue35134


(*) Add a *new* C API which doesn't leak implementation details

This work didn't start. It's still under discussion, I'm not sure that
it's going to happen in the master branch in the short term.

https://pythoncapi.readthedocs.io/
https://bugs.python.org/issue35206
https://mail.python.org/pipermail/python-dev/2018-November/155702.html


(*) Convert macros to static inline functions

I guess that Raymond is worried by the impact on performance of these changes.

So far, the following macros have been converted to static inline functions:

* PyObject_INIT(), PyObject_INIT_VAR()
* _Py_NewReference(), _Py_ForgetReference()
* Py_INCREF(), Py_DECREF()
* Py_XINCREF(), Py_XDECREF()
* _Py_Dealloc()

First, I attempted for "force inlining" (ex:
__attribute__((always_inline)) for GCC/Clang), but it has been decided
to not do that. Please read the discussion on the issue for the
rationale.

https://bugs.python.org/issue35059

I modified the Visual Studio project to ask the compiler to respect
"inline" *hint* when CPython is compiled in debug mode: "Set
InlineFunctionExpansion to OnlyExplicitInline ("/Ob1" option) on all
projects (in pyproject.props) in Debug mode on Win32 and x64 platforms
to expand functions marked as inline." This change spotted a bug in
_decimal ("Add missing EXTINLINE in mpdecimal.h").

Macros have many pitfalls, and the intent here is to prevent these pitfalls.:
https://gcc.gnu.org/onlinedocs/cpp/Macro-Pitfalls.html


_Py_Dealloc() example:

#ifdef COUNT_ALLOCS
#define _Py_INC_TPFREES(OP)     dec_count(Py_TYPE(OP))
#define _Py_COUNT_ALLOCS_COMMA  ,
#else
#define _Py_INC_TPFREES(OP)
#define _Py_COUNT_ALLOCS_COMMA
#endif /* COUNT_ALLOCS */

#define _Py_Dealloc(op) (                               \
    _Py_INC_TPFREES(op) _Py_COUNT_ALLOCS_COMMA          \
    (*Py_TYPE(op)->tp_dealloc)((PyObject *)(op)))

_Py_Dealloc() produced something like "dealloc()" or "dec_count(),
dealloc()" depending on compiler options on Python 3.7. On Python 3.8,
it's now a well defined function call which returns "void" (no
result): "[static inline] void _Py_Dealloc(PyObject *);"


Another example:

#define Py_DECREF(op)                                   \
    do {                                                \
        PyObject *_py_decref_tmp = (PyObject *)(op);    \
        if (_Py_DEC_REFTOTAL  _Py_REF_DEBUG_COMMA       \
        --(_py_decref_tmp)->ob_refcnt != 0)             \
            _Py_CHECK_REFCNT(_py_decref_tmp)            \
        else                                            \
            _Py_Dealloc(_py_decref_tmp);                \
    } while (0)

This macro required a temporary "_py_decref_tmp" variable in Python
3.7, to cast the argument to PyObject*. It's gone in Python 3.8:

static inline void _Py_DECREF(const char *filename, int lineno,
                              PyObject *op)
{
    _Py_DEC_REFTOTAL;
    if (--op->ob_refcnt != 0) {
#ifdef Py_REF_DEBUG
        if (op->ob_refcnt < 0) {
            _Py_NegativeRefcount(filename, lineno, op);
        }
#endif
    }
    else {
        _Py_Dealloc(op);
    }
}

#define Py_DECREF(op) _Py_DECREF(__FILE__, __LINE__, (PyObject *)(op))

The cast is now done in Py_DECREF() macro.

The Py_DECREF() contract is that it accepts basically any pointer. I
chose to not change that (always require the exact PyObject* type and
nothing else), since it would create a compiler warning on basically
every usage of Py_DECREF() for no real benefit.

Victor

From vstinner at redhat.com  Wed Nov 14 06:47:33 2018
From: vstinner at redhat.com (Victor Stinner)
Date: Wed, 14 Nov 2018 12:47:33 +0100
Subject: [Python-Dev] General concerns about C API changes
In-Reply-To: <CA+3bQGHx-GtLzgvDeWtTrK0W857DOYF=bBmjTSfTBTanUEyXQg@mail.gmail.com>
References: <62A87B15-0F0E-4242-BF44-9C58FE890D8B@gmail.com>
 <CAPJVwBmROGz0Nzmoiu0w_riEbkuaDRX9_fKHmEwVBm+pw5k=Xw@mail.gmail.com>
 <CA+3bQGHx-GtLzgvDeWtTrK0W857DOYF=bBmjTSfTBTanUEyXQg@mail.gmail.com>
Message-ID: <CA+3bQGEy_MWgXgSZ-jFj8dZ+QU7iOYxzazVdDX8pf+LPoQ7N0w@mail.gmail.com>

> First, I attempted for "force inlining" (ex:
> __attribute__((always_inline)) for GCC/Clang), but it has been decided
> to not do that. Please read the discussion on the issue for the
> rationale.
>
> https://bugs.python.org/issue35059

It has been decided to use "static inline" syntax since it's the one
required by the PEP 7, but I'm open to switch to "inline" (without
static) or something else. Honestly, I don't understand exactly all
consequences of the exact syntax, so I relied on other core devs who
understand C99 that better than me :-)

Join the discussion on the issue ;-)

Victor

From solipsis at pitrou.net  Wed Nov 14 07:10:08 2018
From: solipsis at pitrou.net (Antoine Pitrou)
Date: Wed, 14 Nov 2018 13:10:08 +0100
Subject: [Python-Dev] Experiment an opt-in new C API for Python? (leave
 current API unchanged)
In-Reply-To: <CA+3bQGHhVjvwScaaMsnW1A2m3+F4JDV9wsa+r0F=tjnCVOce+A@mail.gmail.com>
References: <CA+3bQGGcuo_-fdJwrisGP6+h6CuNzcErSoacaQySEb5h4nOQEQ@mail.gmail.com>
 <CAPJVwBmKHMMKypLDhjhkWHSE7HnHSh_irqaRfCug_+YL4jOtqw@mail.gmail.com>
 <CAGE7PNJeKGiVA5i8=Xrh6bRS7M=AURUPr8TjadQXEhCQuNwbWw@mail.gmail.com>
 <CAPJVwBnHefR1R84gC9Z2LzCZCd0VTV5ZR+m=+ri2spk6e2HZXA@mail.gmail.com>
 <CA+3bQGGizLP=DbRG1tZ15sXFWuEMjL+hdTw-noX1BY=kcDpAVA@mail.gmail.com>
 <20181114112055.2131d35b@fsol>
 <CA+3bQGHhVjvwScaaMsnW1A2m3+F4JDV9wsa+r0F=tjnCVOce+A@mail.gmail.com>
Message-ID: <20181114131008.6ec6c7e0@fsol>

On Wed, 14 Nov 2018 11:48:15 +0100
Victor Stinner <vstinner at redhat.com> wrote:
> Le mer. 14 nov. 2018 ? 11:24, Antoine Pitrou <solipsis at pitrou.net> a ?crit :
> > For example in PyArrow we use PySequence_Fast_GET_ITEM() (*)  
> 
> Maybe PyArrow is a kind of C extension which should have one
> implementation for the new C API (PyPy) and one implementation for the
> current C API (CPython)?

Yes, maybe.  I'm just pointing out that we're using those macros and
removing them from the C API (or replacing them with non-inline
functions) would hurt us.

> > and even
> > PyType_HasFeature() (**) (to quickly check for multiple base types with
> > a single fetch and comparison).  
> 
> I'm not sure that PyType_HasFeature() is an issue?

I don't know.  You're the one who decides :-)

cheers

Antoine.

From nd at perlig.de  Wed Nov 14 08:11:00 2018
From: nd at perlig.de (=?ISO-8859-1?Q?Andr=E9?= Malo)
Date: Wed, 14 Nov 2018 14:11:00 +0100
Subject: [Python-Dev] Experiment an opt-in new C API for Python? (leave
 current API unchanged)
In-Reply-To: <CA+3bQGFdafXR12MfQBzWz3jQf1VsKWeqgWhjNJ5dgaXphBSp+g@mail.gmail.com>
References: <CA+3bQGGcuo_-fdJwrisGP6+h6CuNzcErSoacaQySEb5h4nOQEQ@mail.gmail.com>
 <1614616.psXdYk7axO@chryseis>
 <CA+3bQGFdafXR12MfQBzWz3jQf1VsKWeqgWhjNJ5dgaXphBSp+g@mail.gmail.com>
Message-ID: <220319772.FgY98erabj@finnegan>

On Dienstag, 13. November 2018 21:59:14 CET Victor Stinner wrote:
> Le mar. 13 nov. 2018 ? 20:32, Andr? Malo <nd at perlig.de> a ?crit :
> > As long as they are recompiled. However, they will lose a lot of
> > performance. Both these points have been mentioned somewhere, I'm
> > certain, but it cannot be stressed enough, IMHO.
> 
> Somewhere is here:
> https://pythoncapi.readthedocs.io/performance.html

> > I'm wondering, how you suggest to measure "major". I believe, every C
> > extension, which is public and running in production somewhere, is major
> > enough.
> 
> My plan is to select something like the top five most popular C
> extensions based on PyPI download statistics. I cannot test
> everything, I have to put practical limits.

You shouldn't. Chances are, that you don't even know them enough to do that. 
A scalable approach would be to talk to the projects and let them do it 
instead. No?

Cheers,
-- 
package Hacker::Perl::Another::Just;print
qq~@{[reverse split/::/ =>__PACKAGE__]}~;

#  Andr? Malo  #  http://www.perlig.de  #



From p.f.moore at gmail.com  Wed Nov 14 08:36:08 2018
From: p.f.moore at gmail.com (Paul Moore)
Date: Wed, 14 Nov 2018 13:36:08 +0000
Subject: [Python-Dev] Experiment an opt-in new C API for Python? (leave
 current API unchanged)
In-Reply-To: <CA+3bQGFdafXR12MfQBzWz3jQf1VsKWeqgWhjNJ5dgaXphBSp+g@mail.gmail.com>
References: <CA+3bQGGcuo_-fdJwrisGP6+h6CuNzcErSoacaQySEb5h4nOQEQ@mail.gmail.com>
 <CAPJVwBm73w6UZdvkddTnhavd+WmFU-L2pBKFG=u+mC=nY2Y6Qg@mail.gmail.com>
 <CA+3bQGH2bk6Fv_EPnrndRTPVmnX_w4Q4RTkKv6Kx8cXSOJxJiA@mail.gmail.com>
 <1614616.psXdYk7axO@chryseis>
 <CA+3bQGFdafXR12MfQBzWz3jQf1VsKWeqgWhjNJ5dgaXphBSp+g@mail.gmail.com>
Message-ID: <CACac1F9oSe=mOh7=Ee2JQ2Tx-upmcQtcmETSQUYz9CdSs1_GVg@mail.gmail.com>

On Tue, 13 Nov 2018 at 21:02, Victor Stinner <vstinner at redhat.com> wrote:

> My plan is to select something like the top five most popular C
> extensions based on PyPI download statistics. I cannot test
> everything, I have to put practical limits.

You should probably also consider embedding applications - these have
the potential to be adversely affected too. One example would be vim,
which embeds Python, and makes fairly heavy use of the API (in some
relatively nonstandard ways, for better or worse).

Paul

PS What percentage does "top 5" translate to? In terms of both
downloads and actual numbers of extensions? With only 5, it would be
very easy (I suspect) to get only scientific packages, and (for
example) miss out totally on database APIs, or web helpers. You'll
likely get a broader sense of where issues lie if you cover a wide
range of application domains.

PPS I'd like to see a summary of your backward compatibility plan.
I've not been following this thread so maybe I missed it (if so, a
pointer would be appreciated), but I'd expect as a user that
extensions and embedding applications would *not* need a major rewrite
to work with Python 3.8 - that being the implication of "opt in". I'd
also expect that to remain true for any future version of Python -
assuming the experiment is successful, forced (as opposed to opt-in)
migration to the new API would be handled in a gradual, backward
compatibility respecting manner, exactly as any other changes to the C
API are. A hard break like Python 3, even if limited to the C API,
would be bad for users (for example, preventing adoption of Python 3.X
until the scientific stack migrates to the new API and works out how
to handle supporting old-API versions of Python...)

From vstinner at redhat.com  Wed Nov 14 09:28:19 2018
From: vstinner at redhat.com (Victor Stinner)
Date: Wed, 14 Nov 2018 15:28:19 +0100
Subject: [Python-Dev] Experiment an opt-in new C API for Python? (leave
 current API unchanged)
In-Reply-To: <CACac1F9oSe=mOh7=Ee2JQ2Tx-upmcQtcmETSQUYz9CdSs1_GVg@mail.gmail.com>
References: <CA+3bQGGcuo_-fdJwrisGP6+h6CuNzcErSoacaQySEb5h4nOQEQ@mail.gmail.com>
 <CAPJVwBm73w6UZdvkddTnhavd+WmFU-L2pBKFG=u+mC=nY2Y6Qg@mail.gmail.com>
 <CA+3bQGH2bk6Fv_EPnrndRTPVmnX_w4Q4RTkKv6Kx8cXSOJxJiA@mail.gmail.com>
 <1614616.psXdYk7axO@chryseis>
 <CA+3bQGFdafXR12MfQBzWz3jQf1VsKWeqgWhjNJ5dgaXphBSp+g@mail.gmail.com>
 <CACac1F9oSe=mOh7=Ee2JQ2Tx-upmcQtcmETSQUYz9CdSs1_GVg@mail.gmail.com>
Message-ID: <CA+3bQGGaH0mkn5JNYyq7CpLD36B2cOyKBHOG+aRquTKzjmi6Wg@mail.gmail.com>

Le mer. 14 nov. 2018 ? 14:36, Paul Moore <p.f.moore at gmail.com> a ?crit :
> PS What percentage does "top 5" translate to? In terms of both
> downloads and actual numbers of extensions? With only 5, it would be
> very easy (I suspect) to get only scientific packages, and (for
> example) miss out totally on database APIs, or web helpers. You'll
> likely get a broader sense of where issues lie if you cover a wide
> range of application domains.

I don't want to force anyone to move to a new experimental API. I
don't want to propose patches to third party modules for example. I
would like to ensure that I don't break too many C extensions, or that
tools to convert C extensions to the new API work as expected :-)

Everything is experimental.

> PPS I'd like to see a summary of your backward compatibility plan.

https://pythoncapi.readthedocs.io/backward_compatibility.html

> assuming the experiment is successful, forced (as opposed to opt-in)
> migration to the new API would be handled in a gradual,

No, the current C API will remain available. No one is forced to do
anything. That's not part of my plan.

Victor

From p.f.moore at gmail.com  Wed Nov 14 09:39:11 2018
From: p.f.moore at gmail.com (Paul Moore)
Date: Wed, 14 Nov 2018 14:39:11 +0000
Subject: [Python-Dev] Experiment an opt-in new C API for Python? (leave
 current API unchanged)
In-Reply-To: <CA+3bQGGaH0mkn5JNYyq7CpLD36B2cOyKBHOG+aRquTKzjmi6Wg@mail.gmail.com>
References: <CA+3bQGGcuo_-fdJwrisGP6+h6CuNzcErSoacaQySEb5h4nOQEQ@mail.gmail.com>
 <CAPJVwBm73w6UZdvkddTnhavd+WmFU-L2pBKFG=u+mC=nY2Y6Qg@mail.gmail.com>
 <CA+3bQGH2bk6Fv_EPnrndRTPVmnX_w4Q4RTkKv6Kx8cXSOJxJiA@mail.gmail.com>
 <1614616.psXdYk7axO@chryseis>
 <CA+3bQGFdafXR12MfQBzWz3jQf1VsKWeqgWhjNJ5dgaXphBSp+g@mail.gmail.com>
 <CACac1F9oSe=mOh7=Ee2JQ2Tx-upmcQtcmETSQUYz9CdSs1_GVg@mail.gmail.com>
 <CA+3bQGGaH0mkn5JNYyq7CpLD36B2cOyKBHOG+aRquTKzjmi6Wg@mail.gmail.com>
Message-ID: <CACac1F-smfjmc=X638YGgVokvFKY=j5i37mimu2QZT_m=xCmfA@mail.gmail.com>

On Wed, 14 Nov 2018 at 14:28, Victor Stinner <vstinner at redhat.com> wrote:
> > assuming the experiment is successful, forced (as opposed to opt-in)
> > migration to the new API would be handled in a gradual,
>
> No, the current C API will remain available. No one is forced to do
> anything. That's not part of my plan.

Oh, cool. So current code will continue working indefinitely? What's
the incentive for projects to switch to the new API in that case?
Won't we just end up having to carry two APIs indefinitely? Sorry if
this is all obvious, or was explained previously - as I said I've not
been following precisely because I assumed it was all being handled on
an "if you don't care you can ignore it and nothing will change"
basis, but Raymond's comments plus your suggestion that you needed to
test existing C extensions, made me wonder.

If it is the case that there's no need for any 3rd party code to
change in order to continue working with 3.8+, then I apologise for
the interruption.
Paul

From p.f.moore at gmail.com  Wed Nov 14 09:53:25 2018
From: p.f.moore at gmail.com (Paul Moore)
Date: Wed, 14 Nov 2018 14:53:25 +0000
Subject: [Python-Dev] Experiment an opt-in new C API for Python? (leave
 current API unchanged)
In-Reply-To: <CACac1F-smfjmc=X638YGgVokvFKY=j5i37mimu2QZT_m=xCmfA@mail.gmail.com>
References: <CA+3bQGGcuo_-fdJwrisGP6+h6CuNzcErSoacaQySEb5h4nOQEQ@mail.gmail.com>
 <CAPJVwBm73w6UZdvkddTnhavd+WmFU-L2pBKFG=u+mC=nY2Y6Qg@mail.gmail.com>
 <CA+3bQGH2bk6Fv_EPnrndRTPVmnX_w4Q4RTkKv6Kx8cXSOJxJiA@mail.gmail.com>
 <1614616.psXdYk7axO@chryseis>
 <CA+3bQGFdafXR12MfQBzWz3jQf1VsKWeqgWhjNJ5dgaXphBSp+g@mail.gmail.com>
 <CACac1F9oSe=mOh7=Ee2JQ2Tx-upmcQtcmETSQUYz9CdSs1_GVg@mail.gmail.com>
 <CA+3bQGGaH0mkn5JNYyq7CpLD36B2cOyKBHOG+aRquTKzjmi6Wg@mail.gmail.com>
 <CACac1F-smfjmc=X638YGgVokvFKY=j5i37mimu2QZT_m=xCmfA@mail.gmail.com>
Message-ID: <CACac1F_2xzOifYVS4uOf+zk_NmX9oDJORAaBWT9uSMJMELdjqg@mail.gmail.com>

On Wed, 14 Nov 2018 at 14:39, Paul Moore <p.f.moore at gmail.com> wrote:

> If it is the case that there's no need for any 3rd party code to
> change in order to continue working with 3.8+, then I apologise for
> the interruption.

This is where being able to edit posts, a la Discourse would be useful :-)

It occurs to me that we may be talking at cross purposes. I noticed
https://pythoncapi.readthedocs.io/backward_compatibility.html#forward-compatibility-with-python-3-8-and-newer
which seems to be saying that 3rd party code *will* need to change for
3.8. You mention removed functions there, so I guess "stop using the
removed functions and you'll work with 3.8+ and <=3.7" is the
compatible approach - but it doesn't offer a way for projects that
*need* the functionality that's been removed to move forward. That's
the type of hard break that I was trying to ask about, and which I
thought you said would not happen when you stated "I don't want to
force anyone to move to a new experimental API", and "No, the current
C API will remain available. No one is forced to do anything. That's
not part of my plan".

So to try to be clear, your proposal is that in 3.8:

1. The existing C API will remain
2. A new C API will be *added* that 3rd party projects can use should
they wish to.

And in 3.9 onwards, both C APIs will remain, maybe with gradual and
incremental changes that move users of the existing C API closer and
closer to the new one (via deprecations, replacement APIs etc as per
our normal compatibility rules). Or is the intention that at *some*
point there will be a compatibility break and the existing API will
simply be removed in favour of the "new" API? Fundamentally, that's
what I'm trying to get a clear picture of.

The above is clear, but I don't see what incentive there is in that
scenario for anyone to actually migrate to the new API...
Paul

From J.Demeyer at UGent.be  Wed Nov 14 09:48:43 2018
From: J.Demeyer at UGent.be (Jeroen Demeyer)
Date: Wed, 14 Nov 2018 15:48:43 +0100
Subject: [Python-Dev] General concerns about C API changes
In-Reply-To: <60176b8d36074e1381b301a515467327@xmail203.UGent.be>
References: <60176b8d36074e1381b301a515467327@xmail203.UGent.be>
Message-ID: <5BEC35CB.9010101@UGent.be>

On 2018-11-14 04:06, Raymond Hettinger wrote:
> With cross module function calls, I'm less confident about what is happening

If the functions are "static inline" (as opposed to plain "inline"), 
those aren't really cross-module function calls. Because the functions 
are "static" and defined in a header file, every module has its own copy 
of the function.

If the function is not inlined in the end, this would inflate the 
compiled size because you end up with multiple compilations of the same 
code in the CPython library. It would not affect correct functioning in 
any way though. If the function *is* inlined, then the result should be 
no different from using a macro.


Jeroen.

From vstinner at redhat.com  Wed Nov 14 11:00:35 2018
From: vstinner at redhat.com (Victor Stinner)
Date: Wed, 14 Nov 2018 17:00:35 +0100
Subject: [Python-Dev] Experiment an opt-in new C API for Python? (leave
 current API unchanged)
In-Reply-To: <CACac1F_2xzOifYVS4uOf+zk_NmX9oDJORAaBWT9uSMJMELdjqg@mail.gmail.com>
References: <CA+3bQGGcuo_-fdJwrisGP6+h6CuNzcErSoacaQySEb5h4nOQEQ@mail.gmail.com>
 <CAPJVwBm73w6UZdvkddTnhavd+WmFU-L2pBKFG=u+mC=nY2Y6Qg@mail.gmail.com>
 <CA+3bQGH2bk6Fv_EPnrndRTPVmnX_w4Q4RTkKv6Kx8cXSOJxJiA@mail.gmail.com>
 <1614616.psXdYk7axO@chryseis>
 <CA+3bQGFdafXR12MfQBzWz3jQf1VsKWeqgWhjNJ5dgaXphBSp+g@mail.gmail.com>
 <CACac1F9oSe=mOh7=Ee2JQ2Tx-upmcQtcmETSQUYz9CdSs1_GVg@mail.gmail.com>
 <CA+3bQGGaH0mkn5JNYyq7CpLD36B2cOyKBHOG+aRquTKzjmi6Wg@mail.gmail.com>
 <CACac1F-smfjmc=X638YGgVokvFKY=j5i37mimu2QZT_m=xCmfA@mail.gmail.com>
 <CACac1F_2xzOifYVS4uOf+zk_NmX9oDJORAaBWT9uSMJMELdjqg@mail.gmail.com>
Message-ID: <CA+3bQGFVTXw+6sT-=FG6rrOFQcOHo0p8+mgYY0poTK-+3uyxzw@mail.gmail.com>

In short, you don't have to modify your C extensions and they will
continue to work as before on Python 3.8.

I only propose to add a new C API, don't touch the existing one in any
way. Introducing backward incompatible changes to the existing C API
is out of my plan.

/usr/bin/python3.8 will support C extensions compiled with the old C
API and C extensions compiled with the new C API.

My plan also includes to be able to write C extensions compatible with
the old and new C API in a single code base. As we have Python code
working nicely on Python 2 and Python 3 (thanks to six, mostly). In my
experience, having two branches or two repositories for two flavors of
the same code is a nice recipe towards inconsistent code and painful
workflow.

Le mer. 14 nov. 2018 ? 15:53, Paul Moore <p.f.moore at gmail.com> a ?crit :
> It occurs to me that we may be talking at cross purposes. I noticed
> https://pythoncapi.readthedocs.io/backward_compatibility.html#forward-compatibility-with-python-3-8-and-newer
> which seems to be saying that 3rd party code *will* need to change for
> 3.8.

Oh. It's badly explained in that case. This section is only about C
extensions which really want to become compatible with the new C API.

> You mention removed functions there, so I guess "stop using the
> removed functions and you'll work with 3.8+ and <=3.7" is the
> compatible approach - but it doesn't offer a way for projects that
> *need* the functionality that's been removed to move forward.

If you need a removed functions, don't use the new C API.

> So to try to be clear, your proposal is that in 3.8:
>
> 1. The existing C API will remain
> 2. A new C API will be *added* that 3rd party projects can use should
> they wish to.

Yes, that's it. Add a new API, don't touch existing API.

> And in 3.9 onwards, both C APIs will remain, maybe with gradual and
> incremental changes that move users of the existing C API closer and
> closer to the new one (via deprecations, replacement APIs etc as per
> our normal compatibility rules).

Honestly, it's too early to say if we should modify the current C API
in any way.

I only plan to put advices in the *documentation*. Something like
"this function is really broken, don't use it" :-) Or "you can use xxx
instead which makes your code compatible with the new C API". But I
don't plan it to modify the doc soon. It's too early at this point.

> Or is the intention that at *some*
> point there will be a compatibility break and the existing API will
> simply be removed in favour of the "new" API?

That's out of the scope of *my* plan.

Maybe someone else will show up in 10 years and say "ok, let's
deprecate the old C API". But in my experience, legacy stuff never
goes away :-) (Python 2, anyone?)

> The above is clear, but I don't see what incentive there is in that
> scenario for anyone to actually migrate to the new API...

https://pythoncapi.readthedocs.io/ tries to explain why you should
want to be compatible with the new C API.

The main advantage of the new C API is to compile your C extension
once and use it on multiple runtimes:

* use PyPy for better performances (better than with the old C API)
* use a Python Debug Runtime which contains additional runtime checks
to detect various kinds of bugs in your C extension
* distribute a single binary working on multiple Python versions
(compile on 3.8, use it on 3.9): "stable ABI" -- we are no there yet,
I didn't check what should be done in practice for that

I hope that "later" we will get a faster CPython using <put amazing
new optimizations there>, only compatible with C extensions compiled
with the new C API. My secret hope is that it should ease the
experimentation of a (yet another) JIT compiler for CPython :-)

Victor

From p.f.moore at gmail.com  Wed Nov 14 11:28:02 2018
From: p.f.moore at gmail.com (Paul Moore)
Date: Wed, 14 Nov 2018 16:28:02 +0000
Subject: [Python-Dev] Experiment an opt-in new C API for Python? (leave
 current API unchanged)
In-Reply-To: <CA+3bQGFVTXw+6sT-=FG6rrOFQcOHo0p8+mgYY0poTK-+3uyxzw@mail.gmail.com>
References: <CA+3bQGGcuo_-fdJwrisGP6+h6CuNzcErSoacaQySEb5h4nOQEQ@mail.gmail.com>
 <CAPJVwBm73w6UZdvkddTnhavd+WmFU-L2pBKFG=u+mC=nY2Y6Qg@mail.gmail.com>
 <CA+3bQGH2bk6Fv_EPnrndRTPVmnX_w4Q4RTkKv6Kx8cXSOJxJiA@mail.gmail.com>
 <1614616.psXdYk7axO@chryseis>
 <CA+3bQGFdafXR12MfQBzWz3jQf1VsKWeqgWhjNJ5dgaXphBSp+g@mail.gmail.com>
 <CACac1F9oSe=mOh7=Ee2JQ2Tx-upmcQtcmETSQUYz9CdSs1_GVg@mail.gmail.com>
 <CA+3bQGGaH0mkn5JNYyq7CpLD36B2cOyKBHOG+aRquTKzjmi6Wg@mail.gmail.com>
 <CACac1F-smfjmc=X638YGgVokvFKY=j5i37mimu2QZT_m=xCmfA@mail.gmail.com>
 <CACac1F_2xzOifYVS4uOf+zk_NmX9oDJORAaBWT9uSMJMELdjqg@mail.gmail.com>
 <CA+3bQGFVTXw+6sT-=FG6rrOFQcOHo0p8+mgYY0poTK-+3uyxzw@mail.gmail.com>
Message-ID: <CACac1F9wV_z8-UgeOM1Ss_Z=-ZSK9Ohj53JKUUucw8AOZWunVw@mail.gmail.com>

On Wed, 14 Nov 2018 at 16:00, Victor Stinner <vstinner at redhat.com> wrote:
>
> In short, you don't have to modify your C extensions and they will
> continue to work as before on Python 3.8.
[...]
> I hope that "later" we will get a faster CPython using <put amazing
> new optimizations there>, only compatible with C extensions compiled
> with the new C API. My secret hope is that it should ease the
> experimentation of a (yet another) JIT compiler for CPython :-)

OK, got it. Thanks for taking the time to clarify and respond to my
concerns. Much appreciated.
Paul

From vstinner at redhat.com  Wed Nov 14 12:25:09 2018
From: vstinner at redhat.com (Victor Stinner)
Date: Wed, 14 Nov 2018 18:25:09 +0100
Subject: [Python-Dev] Experiment an opt-in new C API for Python? (leave
 current API unchanged)
In-Reply-To: <CACac1F9wV_z8-UgeOM1Ss_Z=-ZSK9Ohj53JKUUucw8AOZWunVw@mail.gmail.com>
References: <CA+3bQGGcuo_-fdJwrisGP6+h6CuNzcErSoacaQySEb5h4nOQEQ@mail.gmail.com>
 <CAPJVwBm73w6UZdvkddTnhavd+WmFU-L2pBKFG=u+mC=nY2Y6Qg@mail.gmail.com>
 <CA+3bQGH2bk6Fv_EPnrndRTPVmnX_w4Q4RTkKv6Kx8cXSOJxJiA@mail.gmail.com>
 <1614616.psXdYk7axO@chryseis>
 <CA+3bQGFdafXR12MfQBzWz3jQf1VsKWeqgWhjNJ5dgaXphBSp+g@mail.gmail.com>
 <CACac1F9oSe=mOh7=Ee2JQ2Tx-upmcQtcmETSQUYz9CdSs1_GVg@mail.gmail.com>
 <CA+3bQGGaH0mkn5JNYyq7CpLD36B2cOyKBHOG+aRquTKzjmi6Wg@mail.gmail.com>
 <CACac1F-smfjmc=X638YGgVokvFKY=j5i37mimu2QZT_m=xCmfA@mail.gmail.com>
 <CACac1F_2xzOifYVS4uOf+zk_NmX9oDJORAaBWT9uSMJMELdjqg@mail.gmail.com>
 <CA+3bQGFVTXw+6sT-=FG6rrOFQcOHo0p8+mgYY0poTK-+3uyxzw@mail.gmail.com>
 <CACac1F9wV_z8-UgeOM1Ss_Z=-ZSK9Ohj53JKUUucw8AOZWunVw@mail.gmail.com>
Message-ID: <CA+3bQGEhXeN2a_FbfFT5Ra6dJMhw-i=qMiPfB3YA4ZJpZiYGPw@mail.gmail.com>

Le mer. 14 nov. 2018 ? 17:28, Paul Moore <p.f.moore at gmail.com> a ?crit :
> OK, got it. Thanks for taking the time to clarify and respond to my
> concerns. Much appreciated.

I'm my fault. I am failing to explain my plan proplerly. It seems like
I had to update my website to better explain :-)

Victor

From maik.riechert at arcor.de  Wed Nov 14 12:44:18 2018
From: maik.riechert at arcor.de (Maik Riechert)
Date: Wed, 14 Nov 2018 17:44:18 +0000
Subject: [Python-Dev] Clarify required Visual C++ compiler for binary
 extensions in 3.7
Message-ID: <35aa558e-9595-c0f4-24bd-9e8cfcc79d4d@arcor.de>

Hi,

I just wanted to point out that the page 
https://wiki.python.org/moin/WindowsCompilers doesn't mention Python 3.7 
in the table. Is the compiler still Visual C++ 14.0?

Thanks
Maik


From vstinner at redhat.com  Wed Nov 14 18:20:56 2018
From: vstinner at redhat.com (Victor Stinner)
Date: Thu, 15 Nov 2018 00:20:56 +0100
Subject: [Python-Dev] Clarify required Visual C++ compiler for binary
 extensions in 3.7
In-Reply-To: <35aa558e-9595-c0f4-24bd-9e8cfcc79d4d@arcor.de>
References: <35aa558e-9595-c0f4-24bd-9e8cfcc79d4d@arcor.de>
Message-ID: <CA+3bQGFskKd5wjGojDNNs=ZbTTW3D0k0=iVX7dFfcgWLZc9J2g@mail.gmail.com>

I maintain my own compatibility matrix:
https://pythondev.readthedocs.io/windows.html#python-and-visual-studio-version-matrix

Ned Deily asked to update the devguide from my table :-)
https://github.com/python/devguide/issues/433

Victor
Le mer. 14 nov. 2018 ? 18:56, Maik Riechert <maik.riechert at arcor.de> a ?crit :
>
> Hi,
>
> I just wanted to point out that the page
> https://wiki.python.org/moin/WindowsCompilers doesn't mention Python 3.7
> in the table. Is the compiler still Visual C++ 14.0?
>
> Thanks
> Maik
>
> _______________________________________________
> Python-Dev mailing list
> Python-Dev at python.org
> https://mail.python.org/mailman/listinfo/python-dev
> Unsubscribe: https://mail.python.org/mailman/options/python-dev/vstinner%40redhat.com

From greg at krypto.org  Wed Nov 14 19:03:09 2018
From: greg at krypto.org (Gregory P. Smith)
Date: Wed, 14 Nov 2018 16:03:09 -0800
Subject: [Python-Dev] General concerns about C API changes
In-Reply-To: <62A87B15-0F0E-4242-BF44-9C58FE890D8B@gmail.com>
References: <62A87B15-0F0E-4242-BF44-9C58FE890D8B@gmail.com>
Message-ID: <CAGE7PNLmd3r7jrEwSNQd+ELXoGNkt2JUm-rhaAPkXZpna_A8WQ@mail.gmail.com>

On Tue, Nov 13, 2018 at 7:06 PM Raymond Hettinger <
raymond.hettinger at gmail.com> wrote:

> Overall, I support the efforts to improve the C API, but over the last few
> weeks have become worried.  I don't want to hold up progress with fear,
> uncertainty, and doubt.  Yet, I would like to be more comfortable that
> we're all aware of what is occurring and what are the potential benefits
> and risks.
>
> * Inline functions are great.  They provide true local variables, better
> separation of concerns, are far less kludgy than text based macro
> substitution, and will typically generate the same code as the equivalent
> macro.  This is good tech when used with in a single source file where it
> has predictable results.
>
> However, I'm not at all confident about moving these into header files
> which are included in multiple target .c files which need be compiled into
> separate .o files and linked to other existing libraries.
>
> With a macro, I know for sure that the substitution is taking place.  This
> happens at all levels of optimization and in a debug mode.  The effects are
> 100% predictable and have a well-established track record in our mature
> battle-tested code base.  With cross module function calls, I'm less
> confident about what is happening, partly because compilers are free to
> ignore inline directives and partly because the semantics of inlining are
> less clear when the crossing module boundaries.
>
> * Other categories of changes that we make tend to have only a shallow
> reach.  However, these C API changes will likely touch every C extension
> that has ever been written, some of which is highly tuned but not actively
> re-examined.  If any mistakes are make, they will likely be pervasive.
> Accordingly, caution is warranted.
>
> My expectation was that the changes would be conducted in experimental
> branches. But extensive changes are already being made (or about to be
> made) on the 3.8 master. If a year from now, we decide that the changes
> were destabilizing or that the promised benefits didn't materialize, they
> will be difficult to undo because there are so many of them and because
> they will be interleaved with other changes.
>
> The original motivation was to achieve a 2x speedup in return for
> significantly churning the C API. However, the current rearranging of the
> include files and macro-to-inline-function changes only give us churn.  At
> the very best, they will be performance neutral.  At worst, formerly cheap
> macro calls will become expensive in places that we haven't thought to run
> timings on.  Given that compilers don't have to honor an inline directive,
> we can't really know for sure -- perhaps today it works out fine, and
> perhaps tomorrow the compilers opt for a different behavior.
>
> Maybe everything that is going on is fine.  Maybe it's not. I am not
> expert enough to know for sure, but we should be careful before
> green-lighting such an extensive series of changes directly to master.
> Reasonable questions to ask are: 1) What are the risks to third party
> modules, 2) Do we really know that the macro-to-inline-function
> transformations are semantically neutral. 3) If there is no performance
> benefit (none has been seen so far, nor is any promised in the pending
> PRs), is it worth it?
>
> We do know that PyPy folks have had their share of issues with the C API,
> but I'm not sure that we can make any of this go away without changing the
> foundations of the whole ecosystem.  It is inconvenient for a full GC
> environment to interact with the API for a reference counted environment --
> I don't think we can make this challenge go away without giving up
> reference counting.  It is inconvenient for a system that manifests objects
> on demand to interact with an API that assumes that objects have identity
> and never more once they are created -- I don't think we can make this go
> away either.  It is inconvenient to a system that uses unboxed data to
> interact with our API where everything is an object that includes a type
> pointer and reference count -- We have provided an API for boxing and
> boxing, but the trip back-and-forth is inconveniently expensive -- I don't
> think we can make that go away either because too much of the ecosystem
> depends on that API.  There are some things that ca
>  n be mitigated such as challenges with borrowed references but that
> doesn't seem to have been the focus on any of the PRs.
>
> In short, I'm somewhat concerned about the extensive changes that are
> occurring.  I do know they will touch substantially every C module in the
> entire ecosystem.  I don't know whether they are safe or whether they will
> give any real benefit.
>
> FWIW, none of this is a criticism of the work being done.  Someone needs
> to think deeply about the C API or else progress will never be made.  That
> said, it is a high risk project with many PRs going directly into master,
> so it does warrant having buy in that the churn isn't destabilizing and
> will actually produce a benefit that is worth it.
>
>
> Raymond
>
>
While I haven't looked at *all* of the existing changes, glancing at an
example one, the XINCREF and XDECREF macro -> static inline .h function
change from
https://github.com/python/cpython/commit/541497e6197268517b0d492856027774c43e0949,
I don't have any concerns.  Because I am confident that gcc and clang will
behave well with this type of change.

>From my point of view: A static inline function is a much nicer modern code
style than a C preprocessor macro.

I expect the largest visible impact may be that a profiler may now
attribute CPU cycles takes by these code snippets to the function from the
.h file rather than directly to the functions the macro expanded in in the
past due to additional debug symbol info attribution. Just more data.
Consider that a win.

I do not believe any compiler will generate poor code from this on any
meaningful system and compiler configuration (-O0 or -Og code seems
irrelevant, nothing ships that way).  Regardless, pablogsal appears to be
doing the homework to double check which seems like a good plan before we
release 3.8. :)

-gps
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://mail.python.org/pipermail/python-dev/attachments/20181114/0224b774/attachment.html>

From greg at krypto.org  Wed Nov 14 19:08:41 2018
From: greg at krypto.org (Gregory P. Smith)
Date: Wed, 14 Nov 2018 16:08:41 -0800
Subject: [Python-Dev] Experiment an opt-in new C API for Python? (leave
 current API unchanged)
In-Reply-To: <CAPJVwBnHefR1R84gC9Z2LzCZCd0VTV5ZR+m=+ri2spk6e2HZXA@mail.gmail.com>
References: <CA+3bQGGcuo_-fdJwrisGP6+h6CuNzcErSoacaQySEb5h4nOQEQ@mail.gmail.com>
 <CAPJVwBmKHMMKypLDhjhkWHSE7HnHSh_irqaRfCug_+YL4jOtqw@mail.gmail.com>
 <CAGE7PNJeKGiVA5i8=Xrh6bRS7M=AURUPr8TjadQXEhCQuNwbWw@mail.gmail.com>
 <CAPJVwBnHefR1R84gC9Z2LzCZCd0VTV5ZR+m=+ri2spk6e2HZXA@mail.gmail.com>
Message-ID: <CAGE7PNJWuZBYV0kRRO0n2yiRROkmtmFY7RKfDNsY0dTxY+dFww@mail.gmail.com>

>
> It seems like the discussion so far is:
>
> Victor: "I know people when people hear 'new API' they get scared and
> think we're going to do a Python-3-like breaking transition, but don't
> worry, we're never going to do that."
> Nathaniel: "But then what does the new API add?"
> Greg: "It lets us do a Python-3-like breaking transition!"
>

That is not what I am proposing but it seems too easy for people to
misunderstand it as such. Sorry.

Between everything discussed across this thread I believe we have enough
information to suggest that we can avoid an "everyone's afraid of a new 3"
mistake by instead making a shim available with a proposed new API that
works on top of existing Python VM(s) so that if we decide to drop the old
API being public in the future, we could do so *without a breaking
transition*.

Given that, I suggest not worrying about defining a new C API within the
CPython project and release itself (yet).

Without an available benefit, little will use it (and given the function
call overhead we want to isolate some concepts, we know it will perform
worse on today's VMs).

That "top-5" module using it idea?  Maintain forks (hooray for git) of
whatever your definition of "top-5" projects is that use the new API
instead of the CPython API.  If you attempt this on things like NumPy, you
may be shocked at the states (plural on purpose) of their extension module
code.  That holds true for a lot of popular modules.

Part of the point of this work is to demonstrate that non-incremental order
of magnitude performance change can be had on a Python VM that only
supports such an API can be done in its own fork of CPython, PyPy,
VictorBikeshedPy, FbIsAfraidToReleaseANewGcVmPy, etc. implementation to
help argue for figuring out a viable not-breaking-the-world transition plan
to do such a C API change thing in CPython itself.

-gps
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://mail.python.org/pipermail/python-dev/attachments/20181114/94a8ca08/attachment.html>

From vstinner at redhat.com  Wed Nov 14 20:28:19 2018
From: vstinner at redhat.com (Victor Stinner)
Date: Thu, 15 Nov 2018 02:28:19 +0100
Subject: [Python-Dev] General concerns about C API changes
In-Reply-To: <CAGE7PNLmd3r7jrEwSNQd+ELXoGNkt2JUm-rhaAPkXZpna_A8WQ@mail.gmail.com>
References: <62A87B15-0F0E-4242-BF44-9C58FE890D8B@gmail.com>
 <CAGE7PNLmd3r7jrEwSNQd+ELXoGNkt2JUm-rhaAPkXZpna_A8WQ@mail.gmail.com>
Message-ID: <CA+3bQGFCA9WmWqEgoUfUC2yLdMS5euE_0ezqX7Mw5CZjrG4mqw@mail.gmail.com>

Le jeu. 15 nov. 2018 ? 01:06, Gregory P. Smith <greg at krypto.org> a ?crit :
> I expect the largest visible impact may be that a profiler may now attribute CPU cycles takes by these code snippets to the function from the .h file rather than directly to the functions the macro expanded in in the past due to additional debug symbol info attribution. Just more data. Consider that a win.

Oh. That's very interesting.

I just tried gdb and I confirm that gdb understands well inlined
function. When I debug Python, gdb moves into Py_INCREF() or
Py_DECREF() when I use "next".

I also tried perf record/perf report: if I annotate a function
(assembler code of the function), perf shows me the C code of inlined
Py_INCREF and Py_DECREF!

That's nice!

Victor

From maik.riechert at arcor.de  Thu Nov 15 03:43:35 2018
From: maik.riechert at arcor.de (Maik Riechert)
Date: Thu, 15 Nov 2018 08:43:35 +0000
Subject: [Python-Dev] Clarify required Visual C++ compiler for binary
 extensions in 3.7
In-Reply-To: <CA+3bQGFskKd5wjGojDNNs=ZbTTW3D0k0=iVX7dFfcgWLZc9J2g@mail.gmail.com>
References: <35aa558e-9595-c0f4-24bd-9e8cfcc79d4d@arcor.de>
 <CA+3bQGFskKd5wjGojDNNs=ZbTTW3D0k0=iVX7dFfcgWLZc9J2g@mail.gmail.com>
Message-ID: <85d6be18-d4b3-8b9f-ec63-502721629afe@arcor.de>

Thanks Victor. I noticed you write "For Python 3.7, the minimum is VS 
2017 Community, minimum installer options:" but then in the table the 
version listed is 2015 or 2017, so the minimum then probably is 2015?

Maybe it should be mentioned on this page (or a separate one) that those 
versions have to be used as well when building binary extensions for Python.

Maik

On 14/11/2018 23:20, Victor Stinner wrote:
> I maintain my own compatibility matrix:
> https://pythondev.readthedocs.io/windows.html#python-and-visual-studio-version-matrix
>
> Ned Deily asked to update the devguide from my table :-)
> https://github.com/python/devguide/issues/433
>
> Victor
> Le mer. 14 nov. 2018 ? 18:56, Maik Riechert <maik.riechert at arcor.de> a ?crit :
>> Hi,
>>
>> I just wanted to point out that the page
>> https://wiki.python.org/moin/WindowsCompilers doesn't mention Python 3.7
>> in the table. Is the compiler still Visual C++ 14.0?
>>
>> Thanks
>> Maik
>>
>> _______________________________________________
>> Python-Dev mailing list
>> Python-Dev at python.org
>> https://mail.python.org/mailman/listinfo/python-dev
>> Unsubscribe: https://mail.python.org/mailman/options/python-dev/vstinner%40redhat.com

From status at bugs.python.org  Fri Nov 16 12:10:03 2018
From: status at bugs.python.org (Python tracker)
Date: Fri, 16 Nov 2018 18:10:03 +0100 (CET)
Subject: [Python-Dev] Summary of Python tracker Issues
Message-ID: <20181116171003.B8BAB13390C@psf.upfronthosting.co.za>


ACTIVITY SUMMARY (2018-11-09 - 2018-11-16)
Python tracker at https://bugs.python.org/

To view or respond to any of the issues listed below, click on the issue.
Do NOT respond to this message.

Issues counts and deltas:
  open    6863 (+29)
  closed 40154 (+36)
  total  47017 (+65)

Open issues with patches: 2741 


Issues opened (46)
==================

#31354: Fixing a bug related to LTO only build
https://bugs.python.org/issue31354  reopened by ned.deily

#33826: enable discovery of class source code in IPython interactively
https://bugs.python.org/issue33826  reopened by xtreak

#35177: Add missing dependencies between AST/parser header files
https://bugs.python.org/issue35177  reopened by vstinner

#35202: Remove unused imports in standard library
https://bugs.python.org/issue35202  opened by thatiparthy

#35203: Windows Installer Ignores Launcher Installer Options Where The
https://bugs.python.org/issue35203  opened by gr-dexterl

#35206: [WIP] Add a new experimental _Py_CAPI2 API
https://bugs.python.org/issue35206  opened by vstinner

#35208: IDLE: Squeezed lines count ignores window width
https://bugs.python.org/issue35208  opened by taleinat

#35210: Use bytes + memoryview + resize instead of bytesarray + array 
https://bugs.python.org/issue35210  opened by tzickel

#35212: Expressions with format specifiers in f-strings give wrong cod
https://bugs.python.org/issue35212  opened by arminius

#35213: IDLE: use 'macOS' where appropriate.
https://bugs.python.org/issue35213  opened by terry.reedy

#35214: Get the test suite passing with clang Memory Sanitizer enabled
https://bugs.python.org/issue35214  opened by gregory.p.smith

#35216: misleading error message from shutil.copy()
https://bugs.python.org/issue35216  opened by cedricvanrompay

#35217: REPL history is broken when python is invoked with cmd /c
https://bugs.python.org/issue35217  opened by ?????????

#35218: decompressing and then re-compressing zipfiles with Python 3 z
https://bugs.python.org/issue35218  opened by keeely

#35220: delete "how do I emulate os.kill" section in Windows FAQ
https://bugs.python.org/issue35220  opened by deronnax

#35221: Enhance venv activate commands readability
https://bugs.python.org/issue35221  opened by mdk

#35224: PEP 572: Assignment Expressions
https://bugs.python.org/issue35224  opened by emilyemorehouse

#35225: test_faulthandler fails under ubsan
https://bugs.python.org/issue35225  opened by benjamin.peterson

#35226: mock.call equality surprisingly broken
https://bugs.python.org/issue35226  opened by cjw296

#35227: [RFE] tarfile: support adding file objects without prior known
https://bugs.python.org/issue35227  opened by mgorny

#35228: Index search in CHM help crashes viewer
https://bugs.python.org/issue35228  opened by chrullrich

#35231: make install may not call ldconfig on GNU/Linux when using --e
https://bugs.python.org/issue35231  opened by pmpp

#35232: Add `module`/`qualname` arguments to make_dataclass for pickla
https://bugs.python.org/issue35232  opened by Antony.Lee

#35234: ssl module falls over with internationalized domain names
https://bugs.python.org/issue35234  opened by mcasadevall

#35235: Access violation on alloc in Windows x86-64 python, pymalloc_a
https://bugs.python.org/issue35235  opened by markind

#35236: urllib.request.urlopen throws on some valid FTP files
https://bugs.python.org/issue35236  opened by Ian Liu Rodrigues

#35238: Alleviate memory reservation of fork_exec in subprocess.Popen 
https://bugs.python.org/issue35238  opened by oesteban

#35240: Travis CI: xvfb-run: error: Xvfb failed to start
https://bugs.python.org/issue35240  opened by vstinner

#35242: multiprocessing.Queue in an inconsistent state and a traceback
https://bugs.python.org/issue35242  opened by szobov

#35243: readline timeout too long for async gfx use
https://bugs.python.org/issue35243  opened by pmpp

#35244: Allow to setup Clang as default compiler for modules build
https://bugs.python.org/issue35244  opened by Jaime Torres

#35246: asyncio.create_subprocess_exec doesn't accept pathlib.Path lik
https://bugs.python.org/issue35246  opened by lilydjwg

#35247: test.test_socket.RDSTest.testPeek hangs indefinitely
https://bugs.python.org/issue35247  opened by markmcclain

#35248: RawArray causes FileNotFoundError at cleanup
https://bugs.python.org/issue35248  opened by Mathieu Lamarre

#35250: Minor parameter documentation mismatch for turtle
https://bugs.python.org/issue35250  opened by Shane Smith

#35251: FTPHandler.ftp_open documentation error
https://bugs.python.org/issue35251  opened by lys.nikolaou

#35252: test_functools dead code after FIXME
https://bugs.python.org/issue35252  opened by lys.nikolaou

#35253: Linker warning LNK4281
https://bugs.python.org/issue35253  opened by neyuru

#35255: delete "How do I extract the downloaded documentation" section
https://bugs.python.org/issue35255  opened by deronnax

#35257: Add LDFLAGS_NODIST for the LDFLAGS not intended for propagatio
https://bugs.python.org/issue35257  opened by cstratak

#35258: Consider enabling -Wmissing-prototypes
https://bugs.python.org/issue35258  opened by izbyshev

#35259: Py_FinalizeEx unconditionally exists in Py_LIMITED_API
https://bugs.python.org/issue35259  opened by AJNeufeld

#35263: Add None handling for get_saved() in IDLE
https://bugs.python.org/issue35263  opened by rhettinger

#35264: SSL Module build fails with OpenSSL 1.1.0 for Python 2.7
https://bugs.python.org/issue35264  opened by Alexandru Ardelean

#35265: Internal C API: pass the memory allocator in a context
https://bugs.python.org/issue35265  opened by vstinner

#35266: Add _PyPreConfig and rework _PyCoreConfig and _PyMainInterpret
https://bugs.python.org/issue35266  opened by vstinner



Most recent 15 issues with no replies (15)
==========================================

#35266: Add _PyPreConfig and rework _PyCoreConfig and _PyMainInterpret
https://bugs.python.org/issue35266

#35265: Internal C API: pass the memory allocator in a context
https://bugs.python.org/issue35265

#35264: SSL Module build fails with OpenSSL 1.1.0 for Python 2.7
https://bugs.python.org/issue35264

#35263: Add None handling for get_saved() in IDLE
https://bugs.python.org/issue35263

#35259: Py_FinalizeEx unconditionally exists in Py_LIMITED_API
https://bugs.python.org/issue35259

#35258: Consider enabling -Wmissing-prototypes
https://bugs.python.org/issue35258

#35255: delete "How do I extract the downloaded documentation" section
https://bugs.python.org/issue35255

#35251: FTPHandler.ftp_open documentation error
https://bugs.python.org/issue35251

#35246: asyncio.create_subprocess_exec doesn't accept pathlib.Path lik
https://bugs.python.org/issue35246

#35243: readline timeout too long for async gfx use
https://bugs.python.org/issue35243

#35238: Alleviate memory reservation of fork_exec in subprocess.Popen 
https://bugs.python.org/issue35238

#35236: urllib.request.urlopen throws on some valid FTP files
https://bugs.python.org/issue35236

#35232: Add `module`/`qualname` arguments to make_dataclass for pickla
https://bugs.python.org/issue35232

#35231: make install may not call ldconfig on GNU/Linux when using --e
https://bugs.python.org/issue35231

#35228: Index search in CHM help crashes viewer
https://bugs.python.org/issue35228



Most recent 15 issues waiting for review (15)
=============================================

#35266: Add _PyPreConfig and rework _PyCoreConfig and _PyMainInterpret
https://bugs.python.org/issue35266

#35265: Internal C API: pass the memory allocator in a context
https://bugs.python.org/issue35265

#35264: SSL Module build fails with OpenSSL 1.1.0 for Python 2.7
https://bugs.python.org/issue35264

#35263: Add None handling for get_saved() in IDLE
https://bugs.python.org/issue35263

#35255: delete "How do I extract the downloaded documentation" section
https://bugs.python.org/issue35255

#35252: test_functools dead code after FIXME
https://bugs.python.org/issue35252

#35250: Minor parameter documentation mismatch for turtle
https://bugs.python.org/issue35250

#35236: urllib.request.urlopen throws on some valid FTP files
https://bugs.python.org/issue35236

#35226: mock.call equality surprisingly broken
https://bugs.python.org/issue35226

#35224: PEP 572: Assignment Expressions
https://bugs.python.org/issue35224

#35218: decompressing and then re-compressing zipfiles with Python 3 z
https://bugs.python.org/issue35218

#35214: Get the test suite passing with clang Memory Sanitizer enabled
https://bugs.python.org/issue35214

#35213: IDLE: use 'macOS' where appropriate.
https://bugs.python.org/issue35213

#35210: Use bytes + memoryview + resize instead of bytesarray + array 
https://bugs.python.org/issue35210

#35208: IDLE: Squeezed lines count ignores window width
https://bugs.python.org/issue35208



Top 10 most discussed issues (10)
=================================

#34160: ElementTree not preserving attribute order
https://bugs.python.org/issue34160  20 msgs

#35195: [Windows] Python 3.7 initializes LC_CTYPE locale at startup, c
https://bugs.python.org/issue35195  19 msgs

#35214: Get the test suite passing with clang Memory Sanitizer enabled
https://bugs.python.org/issue35214  16 msgs

#35196: IDLE text squeezer is too aggressive and is slow
https://bugs.python.org/issue35196  15 msgs

#33725: Python crashes on macOS after fork with no exec
https://bugs.python.org/issue33725  10 msgs

#35202: Remove unused imports in standard library
https://bugs.python.org/issue35202  10 msgs

#35200: Range repr could be better
https://bugs.python.org/issue35200   9 msgs

#35213: IDLE: use 'macOS' where appropriate.
https://bugs.python.org/issue35213   9 msgs

#33196: multiprocessing: serialization must ensure that contexts are c
https://bugs.python.org/issue33196   8 msgs

#35081: Move internal headers to Include/internal/
https://bugs.python.org/issue35081   8 msgs



Issues closed (38)
==================

#23220: IDLE: Document how Shell displays user code output
https://bugs.python.org/issue23220  closed by terry.reedy

#23734: zipimport should not check pyc timestamps against zipped py fi
https://bugs.python.org/issue23734  closed by gregory.p.smith

#28709: PyStructSequence_NewType is broken; makes GC type without sett
https://bugs.python.org/issue28709  closed by petr.viktorin

#30064: BaseSelectorEventLoop.sock_{recv,sendall}() don't remove their
https://bugs.python.org/issue30064  closed by asvetlov

#31541: Mock called_with does not ensure self/cls argument is used
https://bugs.python.org/issue31541  closed by pablogsal

#32429: Outdated Modules/Setup warning is invisible
https://bugs.python.org/issue32429  closed by mdk

#32485: Multiprocessing dict sharing between forked processes
https://bugs.python.org/issue32485  closed by pitrou

#32613: Use PEP 397 py launcher in windows faq
https://bugs.python.org/issue32613  closed by mdk

#33052: Sporadic segmentation fault in test_datetime.test_check_arg_ty
https://bugs.python.org/issue33052  closed by vstinner

#33695: Have shutil.copytree(), copy() and copystat() use cached scand
https://bugs.python.org/issue33695  closed by giampaolo.rodola

#33699: Don't describe try's else clause in a footnote
https://bugs.python.org/issue33699  closed by Mariatta

#33878: Doc: Assignment statement to tuple or list: case missing.
https://bugs.python.org/issue33878  closed by mdk

#34864: In Idle, Mac tabs make editor status line disappear.
https://bugs.python.org/issue34864  closed by terry.reedy

#34949: ntpath.abspath no longer uses normpath
https://bugs.python.org/issue34949  closed by eryksun

#35193: Off by one error in peephole call to find_op on case RETURN_VA
https://bugs.python.org/issue35193  closed by gregory.p.smith

#35199: Convert PyTuple_GET_ITEM() macro to a function call with addit
https://bugs.python.org/issue35199  closed by vstinner

#35204: Disable thread and memory sanitizers for address_in_range()
https://bugs.python.org/issue35204  closed by benjamin.peterson

#35205: os.path.realpath preserves the trailing backslash on Windows i
https://bugs.python.org/issue35205  closed by eryksun

#35207: Disallow expressions like (a) = 42
https://bugs.python.org/issue35207  closed by pablogsal

#35209: Crash with tkinter text on osx
https://bugs.python.org/issue35209  closed by ned.deily

#35211: Turtle Shutdown Problem(s)
https://bugs.python.org/issue35211  closed by ned.deily

#35215: Replacing CPython memory allocation
https://bugs.python.org/issue35215  closed by pablogsal

#35219: macOS 10.14 Mojave crashes in multiprocessing
https://bugs.python.org/issue35219  closed by barry

#35222: email.utils.formataddr is not exactly the reverse of email.uti
https://bugs.python.org/issue35222  closed by r.david.murray

#35223: Pathlib incorrectly merges strings.
https://bugs.python.org/issue35223  closed by eryksun

#35229: Deprecate _PyObject_GC_TRACK() in Python 3.6
https://bugs.python.org/issue35229  closed by vstinner

#35230: Remove _Py_REF_DEBUG_COMMA
https://bugs.python.org/issue35230  closed by inada.naoki

#35233: _PyMainInterpreterConfig_Copy() doesn't copy install_signal_ha
https://bugs.python.org/issue35233  closed by vstinner

#35237: Allow Path instances in sys.path ?
https://bugs.python.org/issue35237  closed by ammar2

#35239: _PySys_EndInit() doesn't copy main interpreter configuration
https://bugs.python.org/issue35239  closed by vstinner

#35241: [3.7] test_embed fails on MacOS buildbots
https://bugs.python.org/issue35241  closed by vstinner

#35245: list comprehension for flattened or nested list differ too muc
https://bugs.python.org/issue35245  closed by steven.daprano

#35249: Docs Makefile always rebuilds entire doc
https://bugs.python.org/issue35249  closed by seluj78

#35254: Process finished with exit code -1073741795 (0xC000001D)
https://bugs.python.org/issue35254  closed by eryksun

#35256: The Console of Python 3.7.0.
https://bugs.python.org/issue35256  closed by eric.smith

#35260: 2to3 Parse Error on Python 3 print() with arguments
https://bugs.python.org/issue35260  closed by mark.dickinson

#35261: readline.c: PyOS_InputHook not protected against SIGWINCH
https://bugs.python.org/issue35261  closed by vstinner

#35262: There should be a list.get just like dict.get
https://bugs.python.org/issue35262  closed by rhettinger

From brett at python.org  Fri Nov 16 12:17:50 2018
From: brett at python.org (Brett Cannon)
Date: Fri, 16 Nov 2018 09:17:50 -0800
Subject: [Python-Dev] Get a running instance of the doc for a PR.
In-Reply-To: <20181104224842.GZ3817@ando.pearwood.info>
References: <20181104133827.GA25586@xps>
 <203B5254-326E-43EC-A80D-4A8147791A9D@python.org>
 <20181104151239.GA14162@xps> <20181104155017.GX3817@ando.pearwood.info>
 <20181104160507.GF12103@xps> <20181104224842.GZ3817@ando.pearwood.info>
Message-ID: <CAP1=2W71qH=fx-132J=a8P-gO-eu+g7Do3U1D6A0+jDTEzZfww@mail.gmail.com>

On Sun, 4 Nov 2018 at 14:49, Steven D'Aprano <steve at pearwood.info> wrote:

> On Sun, Nov 04, 2018 at 05:05:07PM +0100, Stephane Wirtel wrote:
>
> > >If I am making doc patches, shouldn't I be doing that *before* I
> > >submit the PR? How else will I know that my changes haven't broken the
> > >docs?
> >
> > You can use the web interface of Github and just add/remove/modify a
> > paragraph.
>
> Does Github show a preview? If not, then my question still stands: how
> do I know my changes aren't broken?
>
> If Github does show a preview, then couldn't the reviewer look at that
> too?
>

GitHub provides a "View" button for files while viewing a diff which will
do a basic render for reST files. It won't change all the references like
sealso and such, but basic stuff like literals and links will show up
appropriately.

I think baby steps are probably best here, so getting a zip file as Steve
pointed out to start is still an improvement than the status quo and much
easier to implement.

And any further discussion should probably happen over on core-workflow.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://mail.python.org/pipermail/python-dev/attachments/20181116/3bfd7537/attachment.html>

From brett at python.org  Fri Nov 16 12:46:36 2018
From: brett at python.org (Brett Cannon)
Date: Fri, 16 Nov 2018 09:46:36 -0800
Subject: [Python-Dev] Experiment an opt-in new C API for Python? (leave
 current API unchanged)
In-Reply-To: <CAGE7PNJWuZBYV0kRRO0n2yiRROkmtmFY7RKfDNsY0dTxY+dFww@mail.gmail.com>
References: <CA+3bQGGcuo_-fdJwrisGP6+h6CuNzcErSoacaQySEb5h4nOQEQ@mail.gmail.com>
 <CAPJVwBmKHMMKypLDhjhkWHSE7HnHSh_irqaRfCug_+YL4jOtqw@mail.gmail.com>
 <CAGE7PNJeKGiVA5i8=Xrh6bRS7M=AURUPr8TjadQXEhCQuNwbWw@mail.gmail.com>
 <CAPJVwBnHefR1R84gC9Z2LzCZCd0VTV5ZR+m=+ri2spk6e2HZXA@mail.gmail.com>
 <CAGE7PNJWuZBYV0kRRO0n2yiRROkmtmFY7RKfDNsY0dTxY+dFww@mail.gmail.com>
Message-ID: <CAP1=2W47ccNeZBsBjoRpz6XX_St1Qf0XVMPmZqAO1xJ+-53C=w@mail.gmail.com>

On Wed, 14 Nov 2018 at 16:09, Gregory P. Smith <greg at krypto.org> wrote:

> It seems like the discussion so far is:
>>
>> Victor: "I know people when people hear 'new API' they get scared and
>> think we're going to do a Python-3-like breaking transition, but don't
>> worry, we're never going to do that."
>> Nathaniel: "But then what does the new API add?"
>> Greg: "It lets us do a Python-3-like breaking transition!"
>>
>
> That is not what I am proposing but it seems too easy for people to
> misunderstand it as such. Sorry.
>
> Between everything discussed across this thread I believe we have enough
> information to suggest that we can avoid an "everyone's afraid of a new 3"
> mistake by instead making a shim available with a proposed new API that
> works on top of existing Python VM(s) so that if we decide to drop the old
> API being public in the future, we could do so *without a breaking
> transition*.
>

I know that has always been my hope, especially if any new API is actually
going to be more restrictive instead of broader.


>
> Given that, I suggest not worrying about defining a new C API within the
> CPython project and release itself (yet).
>

+1 from me. Until we have a PEP outlining the actual proposed API I'm not
ready to have it go into 'master'. Helping show the shape of the API by
wrapping pre-existing APIs I think that's going to be the way to sell it.


>
> Without an available benefit, little will use it (and given the function
> call overhead we want to isolate some concepts, we know it will perform
> worse on today's VMs).
>
> That "top-5" module using it idea?  Maintain forks (hooray for git) of
> whatever your definition of "top-5" projects is that use the new API
> instead of the CPython API.  If you attempt this on things like NumPy, you
> may be shocked at the states (plural on purpose) of their extension module
> code.  That holds true for a lot of popular modules.
>
> Part of the point of this work is to demonstrate that non-incremental
> order of magnitude performance change can be had on a Python VM that only
> supports such an API can be done in its own fork of CPython, PyPy,
> VictorBikeshedPy, FbIsAfraidToReleaseANewGcVmPy, etc. implementation to
> help argue for figuring out a viable not-breaking-the-world transition plan
> to do such a C API change thing in CPython itself.
>

I think part of the challenge here (and I believe it has been brought up
elsewhere) is no one knows what kind of API is necessary for some faster VM
other than PyPy. To me, the only C API that would could potentially start
working toward and promoting **today** is one which is stripped to its bare
bones and worst mirrors Python syntax. For instance, I have seen
PyTuple_GET_ITEM() brought up a couple of times. But that's not syntax in
Python, so I wouldn't feel comfortable including that in a simplified API.
You really only need attribute access and object calling to make object
indexing work, although for simplicity I can see wanting to provide an
indexing API.

But otherwise I think we are making assumptions here. For me, unless we are
trying to trim the C API down to just what is syntactically supported in
Python and in such a way that it hides all C-level details I feel like we
are guessing at what's best for other VMs, both today and in the future,
until they can tell us that e.g. tuple indexing is actually not a problem
performance-wise.

And Just to be clear, I totally support coming up with a totally
stripped-down C API as I have outlined above as that shouldn't be
controversial for any VM that wants to have a C-level API.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://mail.python.org/pipermail/python-dev/attachments/20181116/02918191/attachment.html>

From vstinner at redhat.com  Fri Nov 16 13:03:12 2018
From: vstinner at redhat.com (Victor Stinner)
Date: Fri, 16 Nov 2018 19:03:12 +0100
Subject: [Python-Dev] Experiment an opt-in new C API for Python? (leave
 current API unchanged)
In-Reply-To: <CAP1=2W47ccNeZBsBjoRpz6XX_St1Qf0XVMPmZqAO1xJ+-53C=w@mail.gmail.com>
References: <CA+3bQGGcuo_-fdJwrisGP6+h6CuNzcErSoacaQySEb5h4nOQEQ@mail.gmail.com>
 <CAPJVwBmKHMMKypLDhjhkWHSE7HnHSh_irqaRfCug_+YL4jOtqw@mail.gmail.com>
 <CAGE7PNJeKGiVA5i8=Xrh6bRS7M=AURUPr8TjadQXEhCQuNwbWw@mail.gmail.com>
 <CAPJVwBnHefR1R84gC9Z2LzCZCd0VTV5ZR+m=+ri2spk6e2HZXA@mail.gmail.com>
 <CAGE7PNJWuZBYV0kRRO0n2yiRROkmtmFY7RKfDNsY0dTxY+dFww@mail.gmail.com>
 <CAP1=2W47ccNeZBsBjoRpz6XX_St1Qf0XVMPmZqAO1xJ+-53C=w@mail.gmail.com>
Message-ID: <CA+3bQGFJ7CLYRHuu5n9QcPft5aRic-0bpwD1iZC4xHj8wihmEA@mail.gmail.com>

Brett:
> But otherwise I think we are making assumptions here. For me, unless we are trying to trim the C API down to just what is syntactically supported in Python and in such a way that it hides all C-level details I feel like we are guessing at what's best for other VMs, both today and in the future, until they can tell us that e.g. tuple indexing is actually not a problem performance-wise.

The current API of PyTuple_GET_ITEM() allows to write:

   PyObject **items = &PyTuple_GET_ITEM(tuple, 0);

to access PyTupleObject.ob_item. Not only it's possible, but it's used
commonly in the CPython code base. Last week I replaced
&PyTuple_GET_ITEM() pattern with a new _PyTuple_ITEMS() macro which is
private.

To be able to return PyObject**, you have to convert the full tuple
into PyObject* objects which is inefficient if your VM uses something
different (again, PyPy doesn't use PyObject* at all).

More generally, I like to use PyTuple_GET_ITEM() example, just because
it's easy to understand this macro. But it's maybe not a good example
:-)

Victor

From p.f.moore at gmail.com  Fri Nov 16 13:10:59 2018
From: p.f.moore at gmail.com (Paul Moore)
Date: Fri, 16 Nov 2018 18:10:59 +0000
Subject: [Python-Dev] Experiment an opt-in new C API for Python? (leave
 current API unchanged)
In-Reply-To: <CAP1=2W47ccNeZBsBjoRpz6XX_St1Qf0XVMPmZqAO1xJ+-53C=w@mail.gmail.com>
References: <CA+3bQGGcuo_-fdJwrisGP6+h6CuNzcErSoacaQySEb5h4nOQEQ@mail.gmail.com>
 <CAPJVwBmKHMMKypLDhjhkWHSE7HnHSh_irqaRfCug_+YL4jOtqw@mail.gmail.com>
 <CAGE7PNJeKGiVA5i8=Xrh6bRS7M=AURUPr8TjadQXEhCQuNwbWw@mail.gmail.com>
 <CAPJVwBnHefR1R84gC9Z2LzCZCd0VTV5ZR+m=+ri2spk6e2HZXA@mail.gmail.com>
 <CAGE7PNJWuZBYV0kRRO0n2yiRROkmtmFY7RKfDNsY0dTxY+dFww@mail.gmail.com>
 <CAP1=2W47ccNeZBsBjoRpz6XX_St1Qf0XVMPmZqAO1xJ+-53C=w@mail.gmail.com>
Message-ID: <CACac1F8P7vog9ZXqB_G-y=4DZxpuNmaOfdPhwweW5iA+O9PLhg@mail.gmail.com>

On Fri, 16 Nov 2018 at 17:49, Brett Cannon <brett at python.org> wrote:
> And Just to be clear, I totally support coming up with a totally stripped-down C API as I have outlined above as that shouldn't be controversial for any VM that wants to have a C-level API.

If a stripped down API like this is intended as "use this and you get
compatibility across multiple Python interpreters and multiple Python
versions" (essentially a much stronger and more effective version of
the stable ABI) then I'm solidly in favour (and such an API has clear
trade-offs that allow people to judge whether it's the right choice
for them).

Having this alongside the existing API, which would still be supported
for projects that need low-level access or backward compatibility (or
simply don't have the resources to change), but which will remain
CPython-specific, seems like a perfectly fine idea.

Paul

From nas-python at arctrix.com  Fri Nov 16 18:10:24 2018
From: nas-python at arctrix.com (Neil Schemenauer)
Date: Fri, 16 Nov 2018 17:10:24 -0600
Subject: [Python-Dev] Experiment an opt-in new C API for Python? (leave
 current API unchanged)
In-Reply-To: <CAP1=2W47ccNeZBsBjoRpz6XX_St1Qf0XVMPmZqAO1xJ+-53C=w@mail.gmail.com>
References: <CA+3bQGGcuo_-fdJwrisGP6+h6CuNzcErSoacaQySEb5h4nOQEQ@mail.gmail.com>
 <CAPJVwBmKHMMKypLDhjhkWHSE7HnHSh_irqaRfCug_+YL4jOtqw@mail.gmail.com>
 <CAGE7PNJeKGiVA5i8=Xrh6bRS7M=AURUPr8TjadQXEhCQuNwbWw@mail.gmail.com>
 <CAPJVwBnHefR1R84gC9Z2LzCZCd0VTV5ZR+m=+ri2spk6e2HZXA@mail.gmail.com>
 <CAGE7PNJWuZBYV0kRRO0n2yiRROkmtmFY7RKfDNsY0dTxY+dFww@mail.gmail.com>
 <CAP1=2W47ccNeZBsBjoRpz6XX_St1Qf0XVMPmZqAO1xJ+-53C=w@mail.gmail.com>
Message-ID: <20181116231024.bqkn67s2anhdgfk5@python.ca>

On 2018-11-16, Brett Cannon wrote:
> I think part of the challenge here (and I believe it has been
> brought up elsewhere) is no one knows what kind of API is
> necessary for some faster VM other than PyPy.

I think we have some pretty good ideas as to what are the
problematic parts of the current API.  Victor's C-API web site has
details[1].  We can ask other implementors which parts are hard to
support.

Here are my thoughts about some desired changes:

- We are *not* getting rid of refcounting for extension modules.  That
  would require a whole new API.  We might as well start from
  scratch with Python 4.  No one wants that.  However, it is likely
  different VMs use a different GC internally and only use
  refcounting for objects passed through the C-API.  Using
  refcounted handles is the usual implementation approach.  We can
  make some changes to make that easier.  I think making PyObject an
  opaque pointer would help.

- Borrowed references are a problem.  However, because they are so
  commonly used and because the source code changes needed to change
  to a non-borrowed API is non-trivial, I don't think we should try
  to change this.  Maybe we could just discourage their use?  For
  CPython, using a borrowed reference API is faster.  For other
  Python implementations, it is likely slower and maybe much slower.
  So, if you are an extension module that wants to work well with
  other VMs, you should avoid those APIs.

- It would be nice to make PyTypeObject an opaque pointer as well.
  I think that's a lot more difficult than making PyObject opaque.
  So, I don't think we should attempt it in the near future.  Maybe
  we could make a half-way step and discourage accessing ob_type
  directly.  We would provide functions (probably inline) to do what
  you would otherwise do by using op->ob_type-><something>.

  One reason you want to discourage access to ob_type is that
  internally there is not necessarily one PyTypeObject structure for
  each Python level type.  E.g. the VM might have specialized types
  for certain sub-domains.  This is like the different flavours of
  strings, depending on the set of characters stored in them.  Or,
  you could have different list types.  One type of list if all
  values are ints, for example.

  Basically, with CPython op->ob_type is super fast.  For other VMs,
  it could be a lot slower.  By accessing ob_type you are saying
  "give me all possible type information for this object pointer".
  By using functions to get just what you need, you could be putting
  less burden on the VM.  E.g. "is this object an instance of some
  type" is faster to compute.

- APIs that return pointers to the internals of objects are a
  problem.  E.g. PySequence_Fast_ITEMS().  For CPython, this is
  really fast because it is just exposing the internal details of
  the layout that is already in the correct format.  For other VMs,
  that API could be expensive to emulate.  E.g. you have a list to
  store only ints.  If someone calls PySequence_Fast_ITEMS(), you
  have to create real PyObjects for all of the list elements.

- Reducing the size of the API seems helpful.  E.g. we don't need
  PyObject_CallObject() *and* PyObject_Call().  Also, do we really
  need all the type specific APIs, PyList_GetItem() vs
  PyObject_GetItem()?  In some cases maybe we can justify the bigger
  API due to performance.  To add a new API, someone should have a
  benchmark that shows a real speedup (not just that they imagine it
  makes a difference).

I don't think we should change CPython internals to try to use this
new API.  E.g. we know that getting ob_type is fast so just leave
the code that does that alone.  Maybe in the far distant future,
if we have successfully got extension modules to switch to using
the new API, we could consider changing CPython internals.  There
would have to be a big benefit though to justify the code churn.
E.g. if my tagged pointers experiment shows significant performance
gains (it hasn't yet).

I like Nathaniel Smith's idea of doing the new API as a separate
project, outside the cpython repo.  It is possible that in that
effort, we would like some minor changes to cpython in order to make
the new API more efficient, for example.  Those should be pretty
limited changes because we are hoping that the new API will work on
top of old Python versions, e.g. 3.6.

To avoid exposing APIs that should be hidden, re-organizing include
files is an idea.  However, that doesn't help for old versions of
Python.  So, I'm thinking that Dino's idea of just duplicating the
prototypes would be better.  We would like a minimal API and so the
number of duplicated prototypes shouldn't be too large.

Victor's recent work in changing some macros to inline functions is
not really related to the new API project, IMHO.  I don't think
there is a problem to leave an existing macro as a macro.  If we
need to introduce new APIs, e.g. to help hide PyTypeObject, those
APIs could use inline functions.  That way, if using CPython then
using the new API would be just as fast as accessing ob_type
directly.  You are getting an essentially zero cost abstraction.
For the limited API builds, maybe it would be okay to change the
inline functions into non-inlined versions (same function name).

If the new API is going to be successful, it needs to be realatively
easy to change extension source code to use it.  E.g. replacing one
function with another is pretty easy (PyObject_GetItem vs
PyList_GetItem).  If too many difficult changes are required,
extensions are never going to get ported.  The ported extension
*must* be usable with older Python versions.  That's a big mistake
we made with the Python 2 to 3 migration.  Let's not repeat it.

Also, the extension module should not take a big performance hit.
So, you can't change all APIs that were macros into non-inlined
functions.  People are not going to accept that and rightly so.
However, it could be that we introduce a new ifdef like
Py_LIMITED_API that gives a stable ABI.  E.g. when that's enabled,
most everything would turn into non-inline functions.  In exchange
for the performance hit, your extension would become ABI compatible
between a range of CPython releases.  That would be a nice feature.
Basically a more useful version of Py_LIMITED_API.

Regards,

  Neil


1. https://pythoncapi.readthedocs.io/bad_api.html

From njs at pobox.com  Fri Nov 16 18:27:50 2018
From: njs at pobox.com (Nathaniel Smith)
Date: Fri, 16 Nov 2018 15:27:50 -0800
Subject: [Python-Dev] Experiment an opt-in new C API for Python? (leave
 current API unchanged)
In-Reply-To: <20181116231024.bqkn67s2anhdgfk5@python.ca>
References: <CA+3bQGGcuo_-fdJwrisGP6+h6CuNzcErSoacaQySEb5h4nOQEQ@mail.gmail.com>
 <CAPJVwBmKHMMKypLDhjhkWHSE7HnHSh_irqaRfCug_+YL4jOtqw@mail.gmail.com>
 <CAGE7PNJeKGiVA5i8=Xrh6bRS7M=AURUPr8TjadQXEhCQuNwbWw@mail.gmail.com>
 <CAPJVwBnHefR1R84gC9Z2LzCZCd0VTV5ZR+m=+ri2spk6e2HZXA@mail.gmail.com>
 <CAGE7PNJWuZBYV0kRRO0n2yiRROkmtmFY7RKfDNsY0dTxY+dFww@mail.gmail.com>
 <CAP1=2W47ccNeZBsBjoRpz6XX_St1Qf0XVMPmZqAO1xJ+-53C=w@mail.gmail.com>
 <20181116231024.bqkn67s2anhdgfk5@python.ca>
Message-ID: <CAPJVwBn=TUw3wMFz1OO7OpdNao9xZNgjLvU2wRf1jm7-Xjd9ew@mail.gmail.com>

On Fri, Nov 16, 2018 at 3:12 PM Neil Schemenauer <nas-python at arctrix.com> wrote:
> Also, the extension module should not take a big performance hit.
> So, you can't change all APIs that were macros into non-inlined
> functions.  People are not going to accept that and rightly so.
> However, it could be that we introduce a new ifdef like
> Py_LIMITED_API that gives a stable ABI.  E.g. when that's enabled,
> most everything would turn into non-inline functions.  In exchange
> for the performance hit, your extension would become ABI compatible
> between a range of CPython releases.  That would be a nice feature.
> Basically a more useful version of Py_LIMITED_API.

It seems like a lot of the things being talked about here actually
*are* features of Py_LIMITED_API. E.g. it does a lot of work to hide
the internal layout of PyTypeObject, and of course the whole selling
point is that it's stable across multiple Python versions.

If that's the kind of ABI you're looking for, then it seems like you
should investigate (a) whether you can make Py_LIMITED_API *be* that
API, instead of having two different ifdefs, (b) why no popular
extension modules actually use Py_LIMITED_API. I'm guessing it's
partly due to limits of the API, but also things like: lack of docs
and examples, lack of py2 support, ...

-n

-- 
Nathaniel J. Smith -- https://vorpus.org

From nas-python at arctrix.com  Fri Nov 16 19:40:23 2018
From: nas-python at arctrix.com (Neil Schemenauer)
Date: Fri, 16 Nov 2018 18:40:23 -0600
Subject: [Python-Dev] Experiment an opt-in new C API for Python? (leave
 current API unchanged)
In-Reply-To: <CAPJVwBn=TUw3wMFz1OO7OpdNao9xZNgjLvU2wRf1jm7-Xjd9ew@mail.gmail.com>
References: <CA+3bQGGcuo_-fdJwrisGP6+h6CuNzcErSoacaQySEb5h4nOQEQ@mail.gmail.com>
 <CAPJVwBmKHMMKypLDhjhkWHSE7HnHSh_irqaRfCug_+YL4jOtqw@mail.gmail.com>
 <CAGE7PNJeKGiVA5i8=Xrh6bRS7M=AURUPr8TjadQXEhCQuNwbWw@mail.gmail.com>
 <CAPJVwBnHefR1R84gC9Z2LzCZCd0VTV5ZR+m=+ri2spk6e2HZXA@mail.gmail.com>
 <CAGE7PNJWuZBYV0kRRO0n2yiRROkmtmFY7RKfDNsY0dTxY+dFww@mail.gmail.com>
 <CAP1=2W47ccNeZBsBjoRpz6XX_St1Qf0XVMPmZqAO1xJ+-53C=w@mail.gmail.com>
 <20181116231024.bqkn67s2anhdgfk5@python.ca>
 <CAPJVwBn=TUw3wMFz1OO7OpdNao9xZNgjLvU2wRf1jm7-Xjd9ew@mail.gmail.com>
Message-ID: <20181117004023.kwitipxsotj6sv62@python.ca>

On 2018-11-16, Nathaniel Smith wrote:
> [..] it seems like you should investigate (a) whether you can make
> Py_LIMITED_API *be* that API, instead of having two different
> ifdefs

That might be a good idea.  One problem is that we might like to
make backwards incompatible changes to Py_LIMITED_API.  Maybe it
doesn't matter if no extensions actually use Py_LIMITED_API.
Keeping API and ABI compatibility with the existing Py_LIMITED_API
could be difficult.

What would be the downside of using a new CPP define?  We could
deprecate Py_LIMITED_API and the new API could do the job.

Also, I think extensions should have to option to turn the ABI
compatibility off.  For some extensions, they will not want to
convert if there is a big performance hit (some macros turn into
non-inlined functions, call functions rather than access a
non-opaque structure).

Maybe there is a reason my toggling idea won't work.  If we can use
a CPP define to toggle between inline and non-inline functions, I
think it should work.  Maybe it will get complicated.

Providing ABI compatibility like Py_LIMITED_API is a different goal
than making the API more friendly to alternative Python VMs.  So,
maybe it is a mistake to try to tackle both goals at once.  However,
the goals seem closely related and so it would be a shame to do a
bunch of work and not achieve both.


Regards,

  Neil

From ncoghlan at gmail.com  Sun Nov 18 07:32:35 2018
From: ncoghlan at gmail.com (Nick Coghlan)
Date: Sun, 18 Nov 2018 22:32:35 +1000
Subject: [Python-Dev] Need discussion for a PR about memory and objects
In-Reply-To: <20181104130314.GU3817@ando.pearwood.info>
References: <20181104104350.GA12859@xps>
 <20181104130314.GU3817@ando.pearwood.info>
Message-ID: <CADiSq7c4YZfaXZUWZ_J3z4d80MMxuoKcKUyCSaYU=awMN5C5WQ@mail.gmail.com>

On Sun, 4 Nov 2018 at 23:33, Steven D'Aprano <steve at pearwood.info> wrote:
>
> On Sun, Nov 04, 2018 at 11:43:50AM +0100, Stephane Wirtel wrote:
> > In this PR [https://github.com/python/cpython/pull/3382] "Remove reference
> > to
> > address from the docs, as it only causes confusion", opened by Chris
> > Angelico, there is a discussion about the right term to use for the
> > address of an object in memory.
>
> Why do we need to refer to the address of objects in memory?

Following up on this discussion from a couple of weeks ago, note that
Stephane misstated Chris's question/proposal from the PR slightly.

The context is that the data model documentation for objects currently
describes them as having an identity, a type, and a value, and then
uses "address in memory" as an analogy for the properties that the
object identity has (i.e. only one object can have a given identifier
at any particular point in time, but identifiers can be re-used over
time as objects are created and destroyed).

That analogy is problematic, since it encourages the "object
identities are memory addresses" mindset that happens to be true in
CPython, but isn't true for Python implementations in general, and
also isn't helpful for folks that have never learned a lower level
language where you're manipulating pointers directly.

However, simply removing the analogy entirely leaves that paragraph in
the documentation feeling incomplete, so it would be valuable to
replace it with a different real world analogy that will make sense to
a broad audience.

Chris's initial suggestion was to use "license number" or "social
security number" (i.e. numbers governments assign to people), but I'm
thinking a better comparison might be to vehicle registration numbers,
since that analogy can be extended to the type and value
characteristics in a fairly straightforward way:

- the object identity is like the registration number or license plate
(unique within the particular system of registering vehicles, but not
unique across systems, and may sometimes be transferred to a new
vehicle after the old one is destroyed)
- the object type is like the make and model (e.g. a 2007 Toyota
Corolla Ascent Sedan)
- the object value is a specific car (e.g. "that white Corolla over
there with 89000 km on the odometer")

On the other hand, we're talking about the language reference here,
not the tutorial, and understanding memory addressing seems like a
reasonable assumed pre-requisite in that context.

Cheers,
Nick.

--
Nick Coghlan   |   ncoghlan at gmail.com   |   Brisbane, Australia

From stefan_ml at behnel.de  Sun Nov 18 10:53:19 2018
From: stefan_ml at behnel.de (Stefan Behnel)
Date: Sun, 18 Nov 2018 16:53:19 +0100
Subject: [Python-Dev] Experiment an opt-in new C API for Python? (leave
 current API unchanged)
In-Reply-To: <20181116231024.bqkn67s2anhdgfk5@python.ca>
References: <CA+3bQGGcuo_-fdJwrisGP6+h6CuNzcErSoacaQySEb5h4nOQEQ@mail.gmail.com>
 <CAPJVwBmKHMMKypLDhjhkWHSE7HnHSh_irqaRfCug_+YL4jOtqw@mail.gmail.com>
 <CAGE7PNJeKGiVA5i8=Xrh6bRS7M=AURUPr8TjadQXEhCQuNwbWw@mail.gmail.com>
 <CAPJVwBnHefR1R84gC9Z2LzCZCd0VTV5ZR+m=+ri2spk6e2HZXA@mail.gmail.com>
 <CAGE7PNJWuZBYV0kRRO0n2yiRROkmtmFY7RKfDNsY0dTxY+dFww@mail.gmail.com>
 <CAP1=2W47ccNeZBsBjoRpz6XX_St1Qf0XVMPmZqAO1xJ+-53C=w@mail.gmail.com>
 <20181116231024.bqkn67s2anhdgfk5@python.ca>
Message-ID: <pss1pc$aqc$1@blaine.gmane.org>

Neil Schemenauer schrieb am 17.11.18 um 00:10:
> I think making PyObject an opaque pointer would help.

... well, as long as type checks are still as fast as with "ob_type", and
visible to the C compiler so that it can eliminate redundant ones, I
wouldn't mind. :)


> - Borrowed references are a problem.  However, because they are so
>   commonly used and because the source code changes needed to change
>   to a non-borrowed API is non-trivial, I don't think we should try
>   to change this.  Maybe we could just discourage their use?

FWIW, the code that Cython generates has a macro guard [1] that makes it
avoid borrowed references where possible, e.g. when it detects compilation
under PyPy. That's definitely doable already, right now.


> - It would be nice to make PyTypeObject an opaque pointer as well.
>   I think that's a lot more difficult than making PyObject opaque.
>   So, I don't think we should attempt it in the near future.  Maybe
>   we could make a half-way step and discourage accessing ob_type
>   directly.  We would provide functions (probably inline) to do what
>   you would otherwise do by using op->ob_type-><something>.

I've sometimes been annoyed by the fact that protocol checks require two
pointer indirections in CPython (or even three in some cases), so that the
C compiler is essentially prevented from making any assumptions, and the
CPU branch prediction is also stretched a bit more than necessary. At
least, the slot check usually comes right before the call, so that the
lookups are not wasted. Inline functions are unlikely to improve that
situation, but at least they shouldn't make it worse, and they would be
more explicit.

Needless to say that Cython also has a macro guard in [1] that disables
direct slot access and makes it fall back to C-API calls, for users and
Python implementations where direct slot support is not wanted/available.


>   One reason you want to discourage access to ob_type is that
>   internally there is not necessarily one PyTypeObject structure for
>   each Python level type.  E.g. the VM might have specialized types
>   for certain sub-domains.  This is like the different flavours of
>   strings, depending on the set of characters stored in them.  Or,
>   you could have different list types.  One type of list if all
>   values are ints, for example.

An implementation like this could also be based on the buffer protocol.
It's already supported by the array.array type (which people probably also
just use when they have a need like this and don't want to resort to NumPy).


>   Basically, with CPython op->ob_type is super fast.  For other VMs,
>   it could be a lot slower.  By accessing ob_type you are saying
>   "give me all possible type information for this object pointer".
>   By using functions to get just what you need, you could be putting
>   less burden on the VM.  E.g. "is this object an instance of some
>   type" is faster to compute.

Agreed. I think that inline functions (well, or macros, because why not?)
that check for certain protocols explicitly could be helpful.


> - APIs that return pointers to the internals of objects are a
>   problem.  E.g. PySequence_Fast_ITEMS().  For CPython, this is
>   really fast because it is just exposing the internal details of
>   the layout that is already in the correct format.  For other VMs,
>   that API could be expensive to emulate.  E.g. you have a list to
>   store only ints.  If someone calls PySequence_Fast_ITEMS(), you
>   have to create real PyObjects for all of the list elements.

But that's intended by the caller, right? They want a flat serial
representation of the sequence, with potential conversion to a (list) array
if necessary. They might be a bit badly named, but that's exactly the
contract of the "PySequence_Fast_*()" line of functions.

In Cython, we completely avoid these functions, because they are way too
generic for optimisation purposes. Direct type checks and code
specialisation are much more effective.


> - Reducing the size of the API seems helpful.  E.g. we don't need
>   PyObject_CallObject() *and* PyObject_Call().  Also, do we really
>   need all the type specific APIs, PyList_GetItem() vs
>   PyObject_GetItem()?  In some cases maybe we can justify the bigger
>   API due to performance.  To add a new API, someone should have a
>   benchmark that shows a real speedup (not just that they imagine it
>   makes a difference).

So, in Cython, we use macros wherever possible, and often avoid generic
protocols in favour of type specialisations. We sometimes keep local copies
of C-API helper functions, because inlining them allows the C compiler to
strip down and streamline the implementation at compile time, rather than
jumping through generic code. (Also, it's sometimes required in order to
backport new CPython features to Py2.7+.)

PyPy's cpyext often just maps type specific C-API functions to the same
generic code, obviously, but in CPython, having a way to bypass protocols
and going straight to the type is really nice. I've sometimes been thinking
about how to get access to the actual implementations in CPython, because
hopping through slots when Cython already knows that, say, "float_add()"
will be called in the end is just wasteful.

I actually wonder if a more low-level C call interface [2] could also apply
to protocols. It would be great to have an iteration protocol, for example,
that would allow its user to choose whether she wants objects, integers or
C doubles as return values, and then adapt accordingly, depending on the
runtime data.

So, "reducing the size of the API", maybe not. Rather, make it more
specialised and provide a more low-level C integration of Python's
protocols that avoids the current object indirections. That would also help
projects like PyPy or Numba where things are inherently low-level
internally, but currently have to go through static signatures that require
wrapping and unwrapping things in inefficient containers.


> E.g. if my tagged pointers experiment shows significant performance
> gains (it hasn't yet).

In case it ever does, I'd certainly like to see the internals exposed in
order to make direct use of them. :)


> Victor's recent work in changing some macros to inline functions is
> not really related to the new API project, IMHO.  I don't think
> there is a problem to leave an existing macro as a macro.

Yeah, it feels more like code churn. There are some things that cannot be
done in macros (such as deciding whether to handle an error or to return a
result unchanged), in which case an inline function is nice. For simple
things, macros are just as good as inline functions. Minus some compile
time type checking, perhaps.


> However, it could be that we introduce a new ifdef like
> Py_LIMITED_API that gives a stable ABI.  E.g. when that's enabled,
> most everything would turn into non-inline functions.  In exchange
> for the performance hit, your extension would become ABI compatible
> between a range of CPython releases.  That would be a nice feature.
> Basically a more useful version of Py_LIMITED_API.

I actually wouldn't mind adding such a binary compatibility mode to Cython.
Probably some work, but in the end, it would just be another macro guard
for us. The overall size of the generated C files has rarely been a matter
of debates. :)

Stefan



[1]
https://github.com/cython/cython/blob/f158e490b9e8515cf47cf301f996c1b7e631eebb/Cython/Utility/ModuleSetupCode.c#L43-L191

[2] https://github.com/cython/peps/blob/master/pep-ccalls.rst


From stefan_ml at behnel.de  Sun Nov 18 11:50:44 2018
From: stefan_ml at behnel.de (Stefan Behnel)
Date: Sun, 18 Nov 2018 17:50:44 +0100
Subject: [Python-Dev] General concerns about C API changes
In-Reply-To: <CAGE7PNLmd3r7jrEwSNQd+ELXoGNkt2JUm-rhaAPkXZpna_A8WQ@mail.gmail.com>
References: <62A87B15-0F0E-4242-BF44-9C58FE890D8B@gmail.com>
 <CAGE7PNLmd3r7jrEwSNQd+ELXoGNkt2JUm-rhaAPkXZpna_A8WQ@mail.gmail.com>
Message-ID: <pss552$33r$1@blaine.gmane.org>

Gregory P. Smith schrieb am 15.11.18 um 01:03:
> From my point of view: A static inline function is a much nicer modern code
> style than a C preprocessor macro.

It's also slower to compile, given that function inlining happens at a much
later point in the compiler pipeline than macro expansion. The C compiler
won't even get to see macros in fact, whereas whether to inline a function
or not is a dedicated decision during the optimisation phase based on
metrics collected in earlier stages. For something as ubiquitous as
Py_INCREF/Py_DECREF, it might even be visible in the compilation times.

Oh, BTW, I don't know if this was mentioned in the discussion before, but
transitive inlining can easily be impacted by the switch from a macro to an
inline function. Since inlining happens long before the final CPU code
generation, the C compiler needs to uses heuristics for estimating the
eventual "code weight" of an inline function, and then sums up all weights
within a calling function to decide whether to also inline that calling
function into the transitive callers or not.

Now imagine that you have an inline function that executes several
Py_INCREF/Py_DECREF call cycles, and the C compiler happens to slightly
overestimate the weights of these two. Then it might end up deciding
against inlining the function now, whereas it previously might have decided
for it since it was able to see the exact source code expanded from the
macros. I think that's what Raymond meant with his concerns regarding
changing macros into inline functions. C compilers might be smart enough to
always inline CPython's new inline functions themselves, but the style
change can still have unexpected transitive impacts on code that uses them.

I agree with Raymond that as long as there is no clear gain in this code
churn, we should not underestimate the risk of degarding code on user side.

Stefan


From Richard at Damon-Family.org  Sun Nov 18 14:00:08 2018
From: Richard at Damon-Family.org (Richard Damon)
Date: Sun, 18 Nov 2018 14:00:08 -0500
Subject: [Python-Dev] Need discussion for a PR about memory and objects
In-Reply-To: <CADiSq7c4YZfaXZUWZ_J3z4d80MMxuoKcKUyCSaYU=awMN5C5WQ@mail.gmail.com>
References: <20181104104350.GA12859@xps>
 <20181104130314.GU3817@ando.pearwood.info>
 <CADiSq7c4YZfaXZUWZ_J3z4d80MMxuoKcKUyCSaYU=awMN5C5WQ@mail.gmail.com>
Message-ID: <022f855a-671d-1de6-e01c-24eda52006c7@Damon-Family.org>

On 11/18/18 7:32 AM, Nick Coghlan wrote:
> On Sun, 4 Nov 2018 at 23:33, Steven D'Aprano <steve at pearwood.info> wrote:
>> On Sun, Nov 04, 2018 at 11:43:50AM +0100, Stephane Wirtel wrote:
>>> In this PR [https://github.com/python/cpython/pull/3382] "Remove reference
>>> to
>>> address from the docs, as it only causes confusion", opened by Chris
>>> Angelico, there is a discussion about the right term to use for the
>>> address of an object in memory.
>> Why do we need to refer to the address of objects in memory?
> Following up on this discussion from a couple of weeks ago, note that
> Stephane misstated Chris's question/proposal from the PR slightly.
>
> The context is that the data model documentation for objects currently
> describes them as having an identity, a type, and a value, and then
> uses "address in memory" as an analogy for the properties that the
> object identity has (i.e. only one object can have a given identifier
> at any particular point in time, but identifiers can be re-used over
> time as objects are created and destroyed).
>
> That analogy is problematic, since it encourages the "object
> identities are memory addresses" mindset that happens to be true in
> CPython, but isn't true for Python implementations in general, and
> also isn't helpful for folks that have never learned a lower level
> language where you're manipulating pointers directly.
>
> However, simply removing the analogy entirely leaves that paragraph in
> the documentation feeling incomplete, so it would be valuable to
> replace it with a different real world analogy that will make sense to
> a broad audience.
>
> Chris's initial suggestion was to use "license number" or "social
> security number" (i.e. numbers governments assign to people), but I'm
> thinking a better comparison might be to vehicle registration numbers,
> since that analogy can be extended to the type and value
> characteristics in a fairly straightforward way:
>
> - the object identity is like the registration number or license plate
> (unique within the particular system of registering vehicles, but not
> unique across systems, and may sometimes be transferred to a new
> vehicle after the old one is destroyed)
> - the object type is like the make and model (e.g. a 2007 Toyota
> Corolla Ascent Sedan)
> - the object value is a specific car (e.g. "that white Corolla over
> there with 89000 km on the odometer")
>
> On the other hand, we're talking about the language reference here,
> not the tutorial, and understanding memory addressing seems like a
> reasonable assumed pre-requisite in that context.
>
> Cheers,
> Nick.

One issue with things like vehicle registration numbers is that the VIN
of a vehicle is really a UUID, it is globally unique no other vehicle
will every have that same ID number, and people may not think of the
fact that some other ID numbers, like the SSN do get reused. Since the
Python Object Identities can get reused after the object goes away, the
analogy really needs to keep that clear, and not give the other extreme
of a false impression that the ID won't get reused after the object goes
away.

-- 
Richard Damon


From rosuav at gmail.com  Sun Nov 18 14:05:14 2018
From: rosuav at gmail.com (Chris Angelico)
Date: Mon, 19 Nov 2018 06:05:14 +1100
Subject: [Python-Dev] Need discussion for a PR about memory and objects
In-Reply-To: <022f855a-671d-1de6-e01c-24eda52006c7@Damon-Family.org>
References: <20181104104350.GA12859@xps>
 <20181104130314.GU3817@ando.pearwood.info>
 <CADiSq7c4YZfaXZUWZ_J3z4d80MMxuoKcKUyCSaYU=awMN5C5WQ@mail.gmail.com>
 <022f855a-671d-1de6-e01c-24eda52006c7@Damon-Family.org>
Message-ID: <CAPTjJmpwb=Zip5ayCf21yqGreRdoFwtX883y4iRq=pAGfF7cpA@mail.gmail.com>

On Mon, Nov 19, 2018 at 6:01 AM Richard Damon <Richard at damon-family.org> wrote:
> One issue with things like vehicle registration numbers is that the VIN
> of a vehicle is really a UUID, it is globally unique no other vehicle
> will every have that same ID number, and people may not think of the
> fact that some other ID numbers, like the SSN do get reused. Since the
> Python Object Identities can get reused after the object goes away, the
> analogy really needs to keep that clear, and not give the other extreme
> of a false impression that the ID won't get reused after the object goes
> away.

Licence plate numbers do get reused.

ChrisA

From brett at python.org  Sun Nov 18 14:06:15 2018
From: brett at python.org (Brett Cannon)
Date: Sun, 18 Nov 2018 11:06:15 -0800
Subject: [Python-Dev] Experiment an opt-in new C API for Python? (leave
 current API unchanged)
In-Reply-To: <CACac1F8P7vog9ZXqB_G-y=4DZxpuNmaOfdPhwweW5iA+O9PLhg@mail.gmail.com>
References: <CA+3bQGGcuo_-fdJwrisGP6+h6CuNzcErSoacaQySEb5h4nOQEQ@mail.gmail.com>
 <CAPJVwBmKHMMKypLDhjhkWHSE7HnHSh_irqaRfCug_+YL4jOtqw@mail.gmail.com>
 <CAGE7PNJeKGiVA5i8=Xrh6bRS7M=AURUPr8TjadQXEhCQuNwbWw@mail.gmail.com>
 <CAPJVwBnHefR1R84gC9Z2LzCZCd0VTV5ZR+m=+ri2spk6e2HZXA@mail.gmail.com>
 <CAGE7PNJWuZBYV0kRRO0n2yiRROkmtmFY7RKfDNsY0dTxY+dFww@mail.gmail.com>
 <CAP1=2W47ccNeZBsBjoRpz6XX_St1Qf0XVMPmZqAO1xJ+-53C=w@mail.gmail.com>
 <CACac1F8P7vog9ZXqB_G-y=4DZxpuNmaOfdPhwweW5iA+O9PLhg@mail.gmail.com>
Message-ID: <CAP1=2W4wPCA1gTD5dHW=1xLA1dxzPtXGHb-TzcHFZDc-hSSVhw@mail.gmail.com>

On Fri, 16 Nov 2018 at 10:11, Paul Moore <p.f.moore at gmail.com> wrote:

> On Fri, 16 Nov 2018 at 17:49, Brett Cannon <brett at python.org> wrote:
> > And Just to be clear, I totally support coming up with a totally
> stripped-down C API as I have outlined above as that shouldn't be
> controversial for any VM that wants to have a C-level API.
>
> If a stripped down API like this is intended as "use this and you get
> compatibility across multiple Python interpreters and multiple Python
> versions" (essentially a much stronger and more effective version of
> the stable ABI) then I'm solidly in favour (and such an API has clear
> trade-offs that allow people to judge whether it's the right choice
> for them).
>

Yes, that's what I'm getting at. Basically we have to approach this from
the "start with nothing and build up until we have _just_ enough and thus
we know **everyone** now and into the future can support it", or we
approach with "take what we have now and start peeling back until we
_think_ it's good enough". Personally, I think the former is more
future-proof.


>
> Having this alongside the existing API, which would still be supported
> for projects that need low-level access or backward compatibility (or
> simply don't have the resources to change), but which will remain
> CPython-specific, seems like a perfectly fine idea.
>

And it can be done as wrappers around the current C API and as an external
project to start. As Nathaniel pointed out in another thread, this is
somewhat like what Py_LIMITED_API was meant to be, but I think we all admit
we slightly messed up by making it opt-out instead of opt-in and so we
didn't explicitly control that API as well as we probably should have (I
know I have probably screwed up by accidentally including import functions
by forgetting it was opt-out).

I also don't think it was necessarily designed from a minimalist
perspective to begin with as it defines things in terms of what's _not_ in
Py_LIMITED_API instead of explicitly listing what _is_. So it may (or may
not) lead to a different set of APIs in the end when you have to explicitly
list every API to include.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://mail.python.org/pipermail/python-dev/attachments/20181118/8bcee959/attachment.html>

From ja.py at farowl.co.uk  Sun Nov 18 13:58:04 2018
From: ja.py at farowl.co.uk (Jeff Allen)
Date: Sun, 18 Nov 2018 18:58:04 +0000
Subject: [Python-Dev] Need discussion for a PR about memory and objects
In-Reply-To: <CADiSq7c4YZfaXZUWZ_J3z4d80MMxuoKcKUyCSaYU=awMN5C5WQ@mail.gmail.com>
References: <20181104104350.GA12859@xps>
 <20181104130314.GU3817@ando.pearwood.info>
 <CADiSq7c4YZfaXZUWZ_J3z4d80MMxuoKcKUyCSaYU=awMN5C5WQ@mail.gmail.com>
Message-ID: <029f5d5f-7cab-d932-0556-bbfe9eb61f8d@farowl.co.uk>

I found this (very good) summary ended in a surprising conclusion.

On 18/11/2018 12:32, Nick Coghlan wrote:
> On Sun, 4 Nov 2018 at 23:33, Steven D'Aprano <steve at pearwood.info> wrote:
>> On Sun, Nov 04, 2018 at 11:43:50AM +0100, Stephane Wirtel wrote:
>>> In this PR [https://github.com/python/cpython/pull/3382] "Remove reference
>>> to
>>> address from the docs, as it only causes confusion", opened by Chris
>>> Angelico, there is a discussion about the right term to use for the
>>> address of an object in memory.
>> Why do we need to refer to the address of objects in memory?
> ...
> Chris's initial suggestion was to use "license number" or "social
> security number" (i.e. numbers governments assign to people), but I'm
> thinking a better comparison might be to vehicle registration numbers,
> ...
> On the other hand, we're talking about the language reference here,
> not the tutorial, and understanding memory addressing seems like a
> reasonable assumed pre-requisite in that context.
>
> Cheers,
> Nick.
It is a good point that this is in the language reference, not a 
tutorial. Could we not expect readers of that to be prepared for a 
notion of object identity as the abstraction of what we mean by "the 
same object" vs "a distinct object"? If it were necessary to be explicit 
about what Python means by it, one could unpack the idea by its 
properties: distinct names may be given to the same object 
(is-operator); distinct objects may have the same value (==-operator); 
an object may change in value (if allowed by its type) while keeping its 
identity.

And then there is the id() function. That is an imperfect reflection of 
the identity. id() guarantees that for a given object (identity) it will 
always return the same integer during the life of that object, and a 
different integer for any distinct object (distinct identity) with an 
overlapping lifetime. We note that, in an implementation of Python where 
objects are fixed in memory for life, a conformant id() may return the 
object's address.

Jeff Allen




-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://mail.python.org/pipermail/python-dev/attachments/20181118/448a5c3a/attachment.html>

From hugo.fisher at gmail.com  Sun Nov 18 15:51:22 2018
From: hugo.fisher at gmail.com (Hugh Fisher)
Date: Mon, 19 Nov 2018 07:51:22 +1100
Subject: [Python-Dev] Need discussion for a PR about memory and > objects
In-Reply-To: <mailman.30.1542560403.14897.python-dev@python.org>
References: <mailman.30.1542560403.14897.python-dev@python.org>
Message-ID: <CAAahdHMx=zsQgkXxvgiLLi=EEmE_paw=1+YARmrh_8cFL9T=rA@mail.gmail.com>

> Date: Sun, 18 Nov 2018 22:32:35 +1000
> From: Nick Coghlan <ncoghlan at gmail.com>
> To: "Steven D'Aprano" <steve at pearwood.info>
> Cc: python-dev <python-dev at python.org>
> Subject: Re: [Python-Dev] Need discussion for a PR about memory and
>         objects

[  munch background ]
>
> Chris's initial suggestion was to use "license number" or "social
> security number" (i.e. numbers governments assign to people), but I'm
> thinking a better comparison might be to vehicle registration numbers,
> since that analogy can be extended to the type and value
> characteristics in a fairly straightforward way:
>
> - the object identity is like the registration number or license plate
> (unique within the particular system of registering vehicles, but not
> unique across systems, and may sometimes be transferred to a new
> vehicle after the old one is destroyed)
> - the object type is like the make and model (e.g. a 2007 Toyota
> Corolla Ascent Sedan)
> - the object value is a specific car (e.g. "that white Corolla over
> there with 89000 km on the odometer")
>
> On the other hand, we're talking about the language reference here,
> not the tutorial, and understanding memory addressing seems like a
> reasonable assumed pre-requisite in that context.

"Handle" has been used since the 1980s among Macintosh and
Win32 programmers as "unique identifier of some object but isn't
the memory address". The usage within those APIs seems to
match what's being proposed for the new Python C API, in that
programmers used functions to ask "what type are you?" "what
value do you have?" but couldn't, or at least shouldn't, rely on
actual memory layout.

I suggest that for the language reference, use the license plate
or registration analogy to introduce "handle" and after that use
handle throughout. It's short, distinctive, and either will match
up with what the programmer already knows or won't clash if
or when they encounter handles elsewhere.

-- 

        cheers,
        Hugh Fisher

From njs at pobox.com  Sun Nov 18 16:53:54 2018
From: njs at pobox.com (Nathaniel Smith)
Date: Sun, 18 Nov 2018 13:53:54 -0800
Subject: [Python-Dev] General concerns about C API changes
In-Reply-To: <pss552$33r$1@blaine.gmane.org>
References: <62A87B15-0F0E-4242-BF44-9C58FE890D8B@gmail.com>
 <CAGE7PNLmd3r7jrEwSNQd+ELXoGNkt2JUm-rhaAPkXZpna_A8WQ@mail.gmail.com>
 <pss552$33r$1@blaine.gmane.org>
Message-ID: <CAPJVwBkm1iQ2-7pOmHGvyYJ=Z7FNALE-q-7HOi+2x1i+-3OkGA@mail.gmail.com>

On Sun, Nov 18, 2018 at 8:52 AM Stefan Behnel <stefan_ml at behnel.de> wrote:
>
> Gregory P. Smith schrieb am 15.11.18 um 01:03:
> > From my point of view: A static inline function is a much nicer modern code
> > style than a C preprocessor macro.
>
> It's also slower to compile, given that function inlining happens at a much
> later point in the compiler pipeline than macro expansion. The C compiler
> won't even get to see macros in fact, whereas whether to inline a function
> or not is a dedicated decision during the optimisation phase based on
> metrics collected in earlier stages. For something as ubiquitous as
> Py_INCREF/Py_DECREF, it might even be visible in the compilation times.

Have you measured this? I had the opposite intuition, that macros on
average will be slower to compile because they increase the amount of
code that the frontend has to process. But I've never checked...

-n

-- 
Nathaniel J. Smith -- https://vorpus.org

From greg.ewing at canterbury.ac.nz  Sun Nov 18 17:39:50 2018
From: greg.ewing at canterbury.ac.nz (Greg Ewing)
Date: Mon, 19 Nov 2018 11:39:50 +1300
Subject: [Python-Dev] Need discussion for a PR about memory and objects
In-Reply-To: <CADiSq7c4YZfaXZUWZ_J3z4d80MMxuoKcKUyCSaYU=awMN5C5WQ@mail.gmail.com>
References: <20181104104350.GA12859@xps>
 <20181104130314.GU3817@ando.pearwood.info>
 <CADiSq7c4YZfaXZUWZ_J3z4d80MMxuoKcKUyCSaYU=awMN5C5WQ@mail.gmail.com>
Message-ID: <5BF1EA36.1040603@canterbury.ac.nz>

Nick Coghlan wrote:
> - the object identity is like the registration number or license plate
> (unique within the particular system of registering vehicles, but not
> unique across systems, and may sometimes be transferred to a new
> vehicle after the old one is destroyed)
> - the object type is like the make and model (e.g. a 2007 Toyota
> Corolla Ascent Sedan)
> - the object value is a specific car (e.g. "that white Corolla over
> there with 89000 km on the odometer")

A bit confusing, because "that white Corolla over there" is referring
to its identity.

-- 
Greg

From greg.ewing at canterbury.ac.nz  Sun Nov 18 18:21:05 2018
From: greg.ewing at canterbury.ac.nz (Greg Ewing)
Date: Mon, 19 Nov 2018 12:21:05 +1300
Subject: [Python-Dev] Need discussion for a PR about memory and objects
In-Reply-To: <CAPTjJmpwb=Zip5ayCf21yqGreRdoFwtX883y4iRq=pAGfF7cpA@mail.gmail.com>
References: <20181104104350.GA12859@xps>
 <20181104130314.GU3817@ando.pearwood.info>
 <CADiSq7c4YZfaXZUWZ_J3z4d80MMxuoKcKUyCSaYU=awMN5C5WQ@mail.gmail.com>
 <022f855a-671d-1de6-e01c-24eda52006c7@Damon-Family.org>
 <CAPTjJmpwb=Zip5ayCf21yqGreRdoFwtX883y4iRq=pAGfF7cpA@mail.gmail.com>
Message-ID: <5BF1F3E1.6070804@canterbury.ac.nz>

Chris Angelico wrote:
> Licence plate numbers do get reused.

And they can change, e.g. if you get a personalised plate.

-- 
Greg

From solipsis at pitrou.net  Mon Nov 19 04:37:36 2018
From: solipsis at pitrou.net (Antoine Pitrou)
Date: Mon, 19 Nov 2018 10:37:36 +0100
Subject: [Python-Dev] Need discussion for a PR about memory and objects
References: <20181104104350.GA12859@xps>
 <20181104130314.GU3817@ando.pearwood.info>
 <CADiSq7c4YZfaXZUWZ_J3z4d80MMxuoKcKUyCSaYU=awMN5C5WQ@mail.gmail.com>
Message-ID: <20181119103736.690ef0d7@fsol>

On Sun, 18 Nov 2018 22:32:35 +1000
Nick Coghlan <ncoghlan at gmail.com> wrote:
> 
> Chris's initial suggestion was to use "license number" or "social
> security number" (i.e. numbers governments assign to people), but I'm
> thinking a better comparison might be to vehicle registration numbers,
> since that analogy can be extended to the type and value
> characteristics in a fairly straightforward way:
> 
> - the object identity is like the registration number or license plate
> (unique within the particular system of registering vehicles, but not
> unique across systems, and may sometimes be transferred to a new
> vehicle after the old one is destroyed)
> - the object type is like the make and model (e.g. a 2007 Toyota
> Corolla Ascent Sedan)
> - the object value is a specific car (e.g. "that white Corolla over
> there with 89000 km on the odometer")
> 
> On the other hand, we're talking about the language reference here,
> not the tutorial, and understanding memory addressing seems like a
> reasonable assumed pre-requisite in that context.

I'd rather keep the reference to memory addressing than start doing car
analogies in the reference documentation.

Regards

Antoine.



From solipsis at pitrou.net  Mon Nov 19 04:44:22 2018
From: solipsis at pitrou.net (Antoine Pitrou)
Date: Mon, 19 Nov 2018 10:44:22 +0100
Subject: [Python-Dev] Experiment an opt-in new C API for Python? (leave
 current API unchanged)
References: <CA+3bQGGcuo_-fdJwrisGP6+h6CuNzcErSoacaQySEb5h4nOQEQ@mail.gmail.com>
 <CAPJVwBmKHMMKypLDhjhkWHSE7HnHSh_irqaRfCug_+YL4jOtqw@mail.gmail.com>
 <CAGE7PNJeKGiVA5i8=Xrh6bRS7M=AURUPr8TjadQXEhCQuNwbWw@mail.gmail.com>
 <CAPJVwBnHefR1R84gC9Z2LzCZCd0VTV5ZR+m=+ri2spk6e2HZXA@mail.gmail.com>
 <CAGE7PNJWuZBYV0kRRO0n2yiRROkmtmFY7RKfDNsY0dTxY+dFww@mail.gmail.com>
 <CAP1=2W47ccNeZBsBjoRpz6XX_St1Qf0XVMPmZqAO1xJ+-53C=w@mail.gmail.com>
Message-ID: <20181119104422.46d4bb29@fsol>

On Fri, 16 Nov 2018 09:46:36 -0800
Brett Cannon <brett at python.org> wrote:
> 
> I think part of the challenge here (and I believe it has been brought up
> elsewhere) is no one knows what kind of API is necessary for some faster VM
> other than PyPy. To me, the only C API that would could potentially start
> working toward and promoting **today** is one which is stripped to its bare
> bones and worst mirrors Python syntax. For instance, I have seen
> PyTuple_GET_ITEM() brought up a couple of times. But that's not syntax in
> Python, so I wouldn't feel comfortable including that in a simplified API.
> You really only need attribute access and object calling to make object
> indexing work, although for simplicity I can see wanting to provide an
> indexing API.

If the C API only provides Python-level semantics, then it will
roughly have the speed of pure Python (modulo bytecode execution).

There are important use cases for the C API where it is desired to have
fast type-specific access to Python objects such as tuples, ints,
strings, etc.  This is relied upon by modules such as _json and _pickle,
and third-party extensions as well.

Regards

Antoine.



From solipsis at pitrou.net  Mon Nov 19 04:50:58 2018
From: solipsis at pitrou.net (Antoine Pitrou)
Date: Mon, 19 Nov 2018 10:50:58 +0100
Subject: [Python-Dev] Experiment an opt-in new C API for Python? (leave
 current API unchanged)
References: <CA+3bQGGcuo_-fdJwrisGP6+h6CuNzcErSoacaQySEb5h4nOQEQ@mail.gmail.com>
 <CAPJVwBmKHMMKypLDhjhkWHSE7HnHSh_irqaRfCug_+YL4jOtqw@mail.gmail.com>
 <CAGE7PNJeKGiVA5i8=Xrh6bRS7M=AURUPr8TjadQXEhCQuNwbWw@mail.gmail.com>
 <CAPJVwBnHefR1R84gC9Z2LzCZCd0VTV5ZR+m=+ri2spk6e2HZXA@mail.gmail.com>
 <CAGE7PNJWuZBYV0kRRO0n2yiRROkmtmFY7RKfDNsY0dTxY+dFww@mail.gmail.com>
 <CAP1=2W47ccNeZBsBjoRpz6XX_St1Qf0XVMPmZqAO1xJ+-53C=w@mail.gmail.com>
 <20181116231024.bqkn67s2anhdgfk5@python.ca>
 <pss1pc$aqc$1@blaine.gmane.org>
Message-ID: <20181119105058.1f95eb58@fsol>

On Sun, 18 Nov 2018 16:53:19 +0100
Stefan Behnel <stefan_ml at behnel.de> wrote:
> 
> So, in Cython, we use macros wherever possible, and often avoid generic
> protocols in favour of type specialisations. We sometimes keep local copies
> of C-API helper functions, because inlining them allows the C compiler to
> strip down and streamline the implementation at compile time, rather than
> jumping through generic code. (Also, it's sometimes required in order to
> backport new CPython features to Py2.7+.)

Also this approach allows those ballooning compile times that are part
of Cython's charm and appeal ;-)
(sorry, couldn't resist)

Regards

Antoine.



From solipsis at pitrou.net  Mon Nov 19 04:52:55 2018
From: solipsis at pitrou.net (Antoine Pitrou)
Date: Mon, 19 Nov 2018 10:52:55 +0100
Subject: [Python-Dev] General concerns about C API changes
References: <62A87B15-0F0E-4242-BF44-9C58FE890D8B@gmail.com>
 <CAGE7PNLmd3r7jrEwSNQd+ELXoGNkt2JUm-rhaAPkXZpna_A8WQ@mail.gmail.com>
 <pss552$33r$1@blaine.gmane.org>
 <CAPJVwBkm1iQ2-7pOmHGvyYJ=Z7FNALE-q-7HOi+2x1i+-3OkGA@mail.gmail.com>
Message-ID: <20181119105255.63201e93@fsol>

On Sun, 18 Nov 2018 13:53:54 -0800
Nathaniel Smith <njs at pobox.com> wrote:
> On Sun, Nov 18, 2018 at 8:52 AM Stefan Behnel <stefan_ml at behnel.de> wrote:
> >
> > Gregory P. Smith schrieb am 15.11.18 um 01:03:  
> > > From my point of view: A static inline function is a much nicer modern code
> > > style than a C preprocessor macro.  
> >
> > It's also slower to compile, given that function inlining happens at a much
> > later point in the compiler pipeline than macro expansion. The C compiler
> > won't even get to see macros in fact, whereas whether to inline a function
> > or not is a dedicated decision during the optimisation phase based on
> > metrics collected in earlier stages. For something as ubiquitous as
> > Py_INCREF/Py_DECREF, it might even be visible in the compilation times.  
> 
> Have you measured this? I had the opposite intuition, that macros on
> average will be slower to compile because they increase the amount of
> code that the frontend has to process. But I've never checked...

It will certainly depend on how much code the macro expands to.
Py_INCREF is an extremely simple macro, so expanding everywhere doesn't
sound like a problem.

On the other hand, modern "macros" that are C++ templates can inline
vast amounts of code at the call site, and that's a common cause of
slow C++ compiles.

Regards

Antoine.



From vstinner at redhat.com  Mon Nov 19 05:28:46 2018
From: vstinner at redhat.com (Victor Stinner)
Date: Mon, 19 Nov 2018 11:28:46 +0100
Subject: [Python-Dev] Experiment an opt-in new C API for Python? (leave
 current API unchanged)
In-Reply-To: <20181119104422.46d4bb29@fsol>
References: <CA+3bQGGcuo_-fdJwrisGP6+h6CuNzcErSoacaQySEb5h4nOQEQ@mail.gmail.com>
 <CAPJVwBmKHMMKypLDhjhkWHSE7HnHSh_irqaRfCug_+YL4jOtqw@mail.gmail.com>
 <CAGE7PNJeKGiVA5i8=Xrh6bRS7M=AURUPr8TjadQXEhCQuNwbWw@mail.gmail.com>
 <CAPJVwBnHefR1R84gC9Z2LzCZCd0VTV5ZR+m=+ri2spk6e2HZXA@mail.gmail.com>
 <CAGE7PNJWuZBYV0kRRO0n2yiRROkmtmFY7RKfDNsY0dTxY+dFww@mail.gmail.com>
 <CAP1=2W47ccNeZBsBjoRpz6XX_St1Qf0XVMPmZqAO1xJ+-53C=w@mail.gmail.com>
 <20181119104422.46d4bb29@fsol>
Message-ID: <CA+3bQGGJ93-UYZDH9ffe7ryQbBs4vTHa6sc_CGukFutsfef+uw@mail.gmail.com>

Le lun. 19 nov. 2018 ? 10:48, Antoine Pitrou <solipsis at pitrou.net> a ?crit :
> If the C API only provides Python-level semantics, then it will
> roughly have the speed of pure Python (modulo bytecode execution).
>
> There are important use cases for the C API where it is desired to have
> fast type-specific access to Python objects such as tuples, ints,
> strings, etc.  This is relied upon by modules such as _json and _pickle,
> and third-party extensions as well.

Are you sure that using PyDict_GetItem() is really way faster than
PyObject_GetItem()? Did someone run a benchmark to have numbers?

I would expect that the most common source of speed up of a C
extension is the removal of the cost of bytecode evaluation (ceval.c
loop).

Python internals rely on internals to implement further optimizations,
than modifying an "immutable" tuple, bytes or str object, because you
can do that at the C level. But I'm not sure that I would like 3rd
party extensions to rely on such things. For example, unicodeobject.c
uses the following function to check if a str object can be modified
in-place, or if a new str object must be created:

#ifdef Py_DEBUG
static int
unicode_is_singleton(PyObject *unicode)
{
    PyASCIIObject *ascii = (PyASCIIObject *)unicode;
    if (unicode == unicode_empty)
        return 1;
    if (ascii->state.kind != PyUnicode_WCHAR_KIND && ascii->length == 1)
    {
        Py_UCS4 ch = PyUnicode_READ_CHAR(unicode, 0);
        if (ch < 256 && unicode_latin1[ch] == unicode)
            return 1;
    }
    return 0;
}
#endif

static int
unicode_modifiable(PyObject *unicode)
{
    assert(_PyUnicode_CHECK(unicode));
    if (Py_REFCNT(unicode) != 1)
        return 0;
    if (_PyUnicode_HASH(unicode) != -1)
        return 0;
    if (PyUnicode_CHECK_INTERNED(unicode))
        return 0;
    if (!PyUnicode_CheckExact(unicode))
        return 0;
#ifdef Py_DEBUG
    /* singleton refcount is greater than 1 */
    assert(!unicode_is_singleton(unicode));
#endif
    return 1;
}

Victor

From solipsis at pitrou.net  Mon Nov 19 05:53:42 2018
From: solipsis at pitrou.net (Antoine Pitrou)
Date: Mon, 19 Nov 2018 11:53:42 +0100
Subject: [Python-Dev] Experiment an opt-in new C API for Python? (leave
 current API unchanged)
In-Reply-To: <CA+3bQGGJ93-UYZDH9ffe7ryQbBs4vTHa6sc_CGukFutsfef+uw@mail.gmail.com>
References: <CA+3bQGGcuo_-fdJwrisGP6+h6CuNzcErSoacaQySEb5h4nOQEQ@mail.gmail.com>
 <CAPJVwBmKHMMKypLDhjhkWHSE7HnHSh_irqaRfCug_+YL4jOtqw@mail.gmail.com>
 <CAGE7PNJeKGiVA5i8=Xrh6bRS7M=AURUPr8TjadQXEhCQuNwbWw@mail.gmail.com>
 <CAPJVwBnHefR1R84gC9Z2LzCZCd0VTV5ZR+m=+ri2spk6e2HZXA@mail.gmail.com>
 <CAGE7PNJWuZBYV0kRRO0n2yiRROkmtmFY7RKfDNsY0dTxY+dFww@mail.gmail.com>
 <CAP1=2W47ccNeZBsBjoRpz6XX_St1Qf0XVMPmZqAO1xJ+-53C=w@mail.gmail.com>
 <20181119104422.46d4bb29@fsol>
 <CA+3bQGGJ93-UYZDH9ffe7ryQbBs4vTHa6sc_CGukFutsfef+uw@mail.gmail.com>
Message-ID: <20181119115342.5a538507@fsol>

On Mon, 19 Nov 2018 11:28:46 +0100
Victor Stinner <vstinner at redhat.com> wrote:
> I would expect that the most common source of speed up of a C
> extension is the removal of the cost of bytecode evaluation (ceval.c
> loop).

Well, I don't.  All previous experiments showed that simply compiling
Python code to C code using the "generic" C API yielded a 30%
improvement.

Conversely, the C _pickle module can be 100x faster than the pure
Python pickle module.  It's doing it *not* by using the generic C
API, but by special-casing access to concrete types.  You don't get
that level of performance simply by removing the cost of bytecode
evaluation:

# C version
$ python3 -m timeit -s "import pickle; x = list(range(1000))"
"pickle.dumps(x)" 100000 loops, best of 3: 19 usec per loop

# Python version
$ python3 -m timeit -s "import pickle; x = list(range(1000))"
"pickle._dumps(x)" 100 loops, best of 3: 2.25 msec per loop

So, the numbers are on my side.  So is the abundant experience of
experts such as the Cython developers.

> Python internals rely on internals to implement further optimizations,
> than modifying an "immutable" tuple, bytes or str object, because you
> can do that at the C level. But I'm not sure that I would like 3rd
> party extensions to rely on such things.

I'm not even talking about *modifying* tuples or str objects, I'm
talking about *accessing* their value without going through an abstract
API that does slot lookups, indirect function calls and object unboxing.

For example, people may need a fast way to access the UTF-8
representation of a unicode object.  Without making indirect function
calls, and ideally without making a copy of the data either.  How do
you do that using the generic C API?

Regards

Antoine.

From mal at egenix.com  Mon Nov 19 05:59:21 2018
From: mal at egenix.com (M.-A. Lemburg)
Date: Mon, 19 Nov 2018 11:59:21 +0100
Subject: [Python-Dev] Experiment an opt-in new C API for Python? (leave
 current API unchanged)
In-Reply-To: <20181119115342.5a538507@fsol>
References: <CA+3bQGGcuo_-fdJwrisGP6+h6CuNzcErSoacaQySEb5h4nOQEQ@mail.gmail.com>
 <CAPJVwBmKHMMKypLDhjhkWHSE7HnHSh_irqaRfCug_+YL4jOtqw@mail.gmail.com>
 <CAGE7PNJeKGiVA5i8=Xrh6bRS7M=AURUPr8TjadQXEhCQuNwbWw@mail.gmail.com>
 <CAPJVwBnHefR1R84gC9Z2LzCZCd0VTV5ZR+m=+ri2spk6e2HZXA@mail.gmail.com>
 <CAGE7PNJWuZBYV0kRRO0n2yiRROkmtmFY7RKfDNsY0dTxY+dFww@mail.gmail.com>
 <CAP1=2W47ccNeZBsBjoRpz6XX_St1Qf0XVMPmZqAO1xJ+-53C=w@mail.gmail.com>
 <20181119104422.46d4bb29@fsol>
 <CA+3bQGGJ93-UYZDH9ffe7ryQbBs4vTHa6sc_CGukFutsfef+uw@mail.gmail.com>
 <20181119115342.5a538507@fsol>
Message-ID: <460193ad-6ae0-c54a-4335-8422268db84e@egenix.com>

On 19.11.2018 11:53, Antoine Pitrou wrote:
> On Mon, 19 Nov 2018 11:28:46 +0100
> Victor Stinner <vstinner at redhat.com> wrote:
>> Python internals rely on internals to implement further optimizations,
>> than modifying an "immutable" tuple, bytes or str object, because you
>> can do that at the C level. But I'm not sure that I would like 3rd
>> party extensions to rely on such things.
> 
> I'm not even talking about *modifying* tuples or str objects, I'm
> talking about *accessing* their value without going through an abstract
> API that does slot lookups, indirect function calls and object unboxing.
> 
> For example, people may need a fast way to access the UTF-8
> representation of a unicode object.  Without making indirect function
> calls, and ideally without making a copy of the data either.  How do
> you do that using the generic C API?

Something else you need to consider is creating instances of
types, e.g. a tuple. In C you will have to be able to put
values into the data structure before it is passed outside
the function in order to build the tuple.

If you remove this possibility to have to copy data all the
time, losing the advantages of having a rich C API.
 --
Marc-Andre Lemburg
eGenix.com

Professional Python Services directly from the Experts (#1, Nov 19 2018)
>>> Python Projects, Coaching and Consulting ...  http://www.egenix.com/
>>> Python Database Interfaces ...           http://products.egenix.com/
>>> Plone/Zope Database Interfaces ...           http://zope.egenix.com/
________________________________________________________________________

::: We implement business ideas - efficiently in both time and costs :::

   eGenix.com Software, Skills and Services GmbH  Pastor-Loeh-Str.48
    D-40764 Langenfeld, Germany. CEO Dipl.-Math. Marc-Andre Lemburg
           Registered at Amtsgericht Duesseldorf: HRB 46611
               http://www.egenix.com/company/contact/
                      http://www.malemburg.com/


From solipsis at pitrou.net  Mon Nov 19 06:10:19 2018
From: solipsis at pitrou.net (Antoine Pitrou)
Date: Mon, 19 Nov 2018 12:10:19 +0100
Subject: [Python-Dev] Experiment an opt-in new C API for Python? (leave
 current API unchanged)
References: <CA+3bQGGcuo_-fdJwrisGP6+h6CuNzcErSoacaQySEb5h4nOQEQ@mail.gmail.com>
 <CAPJVwBmKHMMKypLDhjhkWHSE7HnHSh_irqaRfCug_+YL4jOtqw@mail.gmail.com>
 <CAGE7PNJeKGiVA5i8=Xrh6bRS7M=AURUPr8TjadQXEhCQuNwbWw@mail.gmail.com>
 <CAPJVwBnHefR1R84gC9Z2LzCZCd0VTV5ZR+m=+ri2spk6e2HZXA@mail.gmail.com>
 <CAGE7PNJWuZBYV0kRRO0n2yiRROkmtmFY7RKfDNsY0dTxY+dFww@mail.gmail.com>
 <CAP1=2W47ccNeZBsBjoRpz6XX_St1Qf0XVMPmZqAO1xJ+-53C=w@mail.gmail.com>
 <20181119104422.46d4bb29@fsol>
 <CA+3bQGGJ93-UYZDH9ffe7ryQbBs4vTHa6sc_CGukFutsfef+uw@mail.gmail.com>
 <20181119115342.5a538507@fsol>
Message-ID: <20181119121019.69f7ba63@fsol>

On Mon, 19 Nov 2018 11:53:42 +0100
Antoine Pitrou <solipsis at pitrou.net> wrote:
> On Mon, 19 Nov 2018 11:28:46 +0100
> Victor Stinner <vstinner at redhat.com> wrote:
> > I would expect that the most common source of speed up of a C
> > extension is the removal of the cost of bytecode evaluation (ceval.c
> > loop).  
> 
> Well, I don't.  All previous experiments showed that simply compiling
> Python code to C code using the "generic" C API yielded a 30%
> improvement.
> 
> Conversely, the C _pickle module can be 100x faster than the pure
> Python pickle module.  It's doing it *not* by using the generic C
> API, but by special-casing access to concrete types.  You don't get
> that level of performance simply by removing the cost of bytecode
> evaluation:
> 
> # C version
> $ python3 -m timeit -s "import pickle; x = list(range(1000))"
> "pickle.dumps(x)" 100000 loops, best of 3: 19 usec per loop
> 
> # Python version
> $ python3 -m timeit -s "import pickle; x = list(range(1000))"
> "pickle._dumps(x)" 100 loops, best of 3: 2.25 msec per loop

And to show that this is important for third-party C extensions as
well, PyArrow (*) has comparable performance using similar techniques:

$ python -m timeit -s "import pyarrow as pa; x = list(range(1000))"
"pa.array(x, type=pa.int64())"
10000 loops, best of 5: 27.2 usec per loop

(*) https://arrow.apache.org/docs/python/

Regards

Antoine.



From vstinner at redhat.com  Mon Nov 19 06:14:52 2018
From: vstinner at redhat.com (Victor Stinner)
Date: Mon, 19 Nov 2018 12:14:52 +0100
Subject: [Python-Dev] Experiment an opt-in new C API for Python? (leave
 current API unchanged)
In-Reply-To: <460193ad-6ae0-c54a-4335-8422268db84e@egenix.com>
References: <CA+3bQGGcuo_-fdJwrisGP6+h6CuNzcErSoacaQySEb5h4nOQEQ@mail.gmail.com>
 <CAPJVwBmKHMMKypLDhjhkWHSE7HnHSh_irqaRfCug_+YL4jOtqw@mail.gmail.com>
 <CAGE7PNJeKGiVA5i8=Xrh6bRS7M=AURUPr8TjadQXEhCQuNwbWw@mail.gmail.com>
 <CAPJVwBnHefR1R84gC9Z2LzCZCd0VTV5ZR+m=+ri2spk6e2HZXA@mail.gmail.com>
 <CAGE7PNJWuZBYV0kRRO0n2yiRROkmtmFY7RKfDNsY0dTxY+dFww@mail.gmail.com>
 <CAP1=2W47ccNeZBsBjoRpz6XX_St1Qf0XVMPmZqAO1xJ+-53C=w@mail.gmail.com>
 <20181119104422.46d4bb29@fsol>
 <CA+3bQGGJ93-UYZDH9ffe7ryQbBs4vTHa6sc_CGukFutsfef+uw@mail.gmail.com>
 <20181119115342.5a538507@fsol>
 <460193ad-6ae0-c54a-4335-8422268db84e@egenix.com>
Message-ID: <CA+3bQGEoUDA_+_oK45oqSFxHTNDNJ8k9Ux-gSSP+hGZgx3WBGQ@mail.gmail.com>

To design a new C API, I see 3 options:

(1) add more functions to the existing Py_LIMITED_API
(2) "fork" the current public C API: remove functions and hide as much
implementation details as possible
(3) write a new C API from scratch, based on the current C API.
Something like #define newcapi_Object_GetItem PyObject_GetItem"?
Sorry, but "#undef <private_function>" doesn't work. Only very few
functions are defined using "#define ...".

I dislike (1) because it's too far from what is currently used in
practice. Moreover, I failed to find anyone who can explain me how the
C API is used in the wild, which functions are important or not, what
is the C API, etc.

I propose (2). We control how much changes we do at each milestone,
and we start from the maximum compatibility with current C API. Each
change can be discussed and experimented to define what is the C API,
what we want, etc. I'm working on this approach for 1 year, that's why
many discussions popped up around specific changes :-)

Some people recently proposed (3) on python-dev. I dislike this option
because it starts by breaking the backward compatibility. It looks
like (1), but worse. The goal and the implementation are unclear to
me.

--

Replacing PyDict_GetItem() (specialized call) with PyObject_Dict()
(generic API) is not part of my short term plan. I wrote it in the
roadmap, but as I wrote before, each change should be discusssed,
experimented, benchmarked, etc.

Victor
Le lun. 19 nov. 2018 ? 12:02, M.-A. Lemburg <mal at egenix.com> a ?crit :
>
> On 19.11.2018 11:53, Antoine Pitrou wrote:
> > On Mon, 19 Nov 2018 11:28:46 +0100
> > Victor Stinner <vstinner at redhat.com> wrote:
> >> Python internals rely on internals to implement further optimizations,
> >> than modifying an "immutable" tuple, bytes or str object, because you
> >> can do that at the C level. But I'm not sure that I would like 3rd
> >> party extensions to rely on such things.
> >
> > I'm not even talking about *modifying* tuples or str objects, I'm
> > talking about *accessing* their value without going through an abstract
> > API that does slot lookups, indirect function calls and object unboxing.
> >
> > For example, people may need a fast way to access the UTF-8
> > representation of a unicode object.  Without making indirect function
> > calls, and ideally without making a copy of the data either.  How do
> > you do that using the generic C API?
>
> Something else you need to consider is creating instances of
> types, e.g. a tuple. In C you will have to be able to put
> values into the data structure before it is passed outside
> the function in order to build the tuple.
>
> If you remove this possibility to have to copy data all the
> time, losing the advantages of having a rich C API.
>  --
> Marc-Andre Lemburg
> eGenix.com
>
> Professional Python Services directly from the Experts (#1, Nov 19 2018)
> >>> Python Projects, Coaching and Consulting ...  http://www.egenix.com/
> >>> Python Database Interfaces ...           http://products.egenix.com/
> >>> Plone/Zope Database Interfaces ...           http://zope.egenix.com/
> ________________________________________________________________________
>
> ::: We implement business ideas - efficiently in both time and costs :::
>
>    eGenix.com Software, Skills and Services GmbH  Pastor-Loeh-Str.48
>     D-40764 Langenfeld, Germany. CEO Dipl.-Math. Marc-Andre Lemburg
>            Registered at Amtsgericht Duesseldorf: HRB 46611
>                http://www.egenix.com/company/contact/
>                       http://www.malemburg.com/
>
> _______________________________________________
> Python-Dev mailing list
> Python-Dev at python.org
> https://mail.python.org/mailman/listinfo/python-dev
> Unsubscribe: https://mail.python.org/mailman/options/python-dev/vstinner%40redhat.com

From stefan at bytereef.org  Mon Nov 19 06:59:34 2018
From: stefan at bytereef.org (Stefan Krah)
Date: Mon, 19 Nov 2018 12:59:34 +0100
Subject: [Python-Dev] Experiment an opt-in new C API for Python? (leave
 current API unchanged)
Message-ID: <20181119115933.GA4918@bytereef.org>


Victor Stinner wrote:

> Moreover, I failed to find anyone who can explain me how the C API is used
> in the wild, which functions are important or not, what is the C API, etc.

In practice people desperately *have* to use whatever is there, including
functions with underscores that are not even officially in the C-API.

I have to use _PyFloat_Pack* in order to be compatible with CPython, I need
PySlice_Unpack() etc., I need PyUnicode_KIND(), need PyUnicode_AsUTF8AndSize(),
I *wish* there were PyUnicode_AsAsciiAndSize().


In general, in daily use of the C-API I wish it were *larger* and not smaller.

I often want functions that return C instead of Python values ot functions
that take C instead of Python values.

The ideal situation for me would be a lower layer library, say libcpython.a
that has all those functions like _PyFloat_Pack*.

It would be an enormous amount of work though, especially since the status quo
kind of works.



Stefan Krah




From vstinner at redhat.com  Mon Nov 19 10:08:07 2018
From: vstinner at redhat.com (Victor Stinner)
Date: Mon, 19 Nov 2018 16:08:07 +0100
Subject: [Python-Dev] Experiment an opt-in new C API for Python? (leave
 current API unchanged)
In-Reply-To: <20181119115933.GA4918@bytereef.org>
References: <20181119115933.GA4918@bytereef.org>
Message-ID: <CA+3bQGFzBcX25LO_Ert2XVckWB9MG-gMFF9pd2o=y-sc=Gqpuw@mail.gmail.com>

Hi Stefan,

Le lun. 19 nov. 2018 ? 13:18, Stefan Krah <stefan at bytereef.org> a ?crit :
> In practice people desperately *have* to use whatever is there, including
> functions with underscores that are not even officially in the C-API.
>
> I have to use _PyFloat_Pack* in order to be compatible with CPython,

Oh, I never used this function. These functions are private (name
prefixed by "_") and excluded from the limited API.

For me, the limited API should be functions available on all Python
implementations. Does it make sense to provide PyFloat_Pack4() in
MicroPython, Jython, IronPython and PyPy? Or is it something more
specific to CPython? I don't know the answer. If yes, open an issue to
propose to make this function public?

> I need PyUnicode_KIND()

IMHO this one should not be part of the public API. The only usage
would be to micro-optimize, but such API is very specific to one
Python implementation. For example, PyPy doesn't use "compact string"
but UTF-8 internally. If you use PyUnicode_KIND(), your code becomes
incompatible with PyPy.

What is your use case?

I would prefer to expose the "_PyUnicodeWriter" API than PyUnicode_KIND().

> need PyUnicode_AsUTF8AndSize(),

Again, that's a micro-optimization and it's very specific to CPython:
result cached in the "immutable" str object. I don't want to put it in
a public API. PyUnicode_AsUTF8String() is better since it doesn't
require an internal cache.

> I *wish* there were PyUnicode_AsAsciiAndSize().

PyUnicode_AsASCIIString() looks good to me. Sadly, it doesn't return
the length, but usually the length is not needed.

Victor

From nas-python at arctrix.com  Mon Nov 19 13:13:30 2018
From: nas-python at arctrix.com (Neil Schemenauer)
Date: Mon, 19 Nov 2018 12:13:30 -0600
Subject: [Python-Dev] Experiment an opt-in new C API for Python? (leave
 current API unchanged)
In-Reply-To: <CA+3bQGEoUDA_+_oK45oqSFxHTNDNJ8k9Ux-gSSP+hGZgx3WBGQ@mail.gmail.com>
References: <CAPJVwBmKHMMKypLDhjhkWHSE7HnHSh_irqaRfCug_+YL4jOtqw@mail.gmail.com>
 <CAGE7PNJeKGiVA5i8=Xrh6bRS7M=AURUPr8TjadQXEhCQuNwbWw@mail.gmail.com>
 <CAPJVwBnHefR1R84gC9Z2LzCZCd0VTV5ZR+m=+ri2spk6e2HZXA@mail.gmail.com>
 <CAGE7PNJWuZBYV0kRRO0n2yiRROkmtmFY7RKfDNsY0dTxY+dFww@mail.gmail.com>
 <CAP1=2W47ccNeZBsBjoRpz6XX_St1Qf0XVMPmZqAO1xJ+-53C=w@mail.gmail.com>
 <20181119104422.46d4bb29@fsol>
 <CA+3bQGGJ93-UYZDH9ffe7ryQbBs4vTHa6sc_CGukFutsfef+uw@mail.gmail.com>
 <20181119115342.5a538507@fsol>
 <460193ad-6ae0-c54a-4335-8422268db84e@egenix.com>
 <CA+3bQGEoUDA_+_oK45oqSFxHTNDNJ8k9Ux-gSSP+hGZgx3WBGQ@mail.gmail.com>
Message-ID: <20181119181330.fb26vkhhkbyxsokd@python.ca>

On 2018-11-19, Victor Stinner wrote:
> Moreover, I failed to find anyone who can explain me how the C API
> is used in the wild, which functions are important or not, what is
> the C API, etc.

One idea is to download a large sample of extension modules from
PyPI and then analyze them with some automated tool (maybe
libclang).  I guess it is possible there is a large non-public set
of extensions that we would miss.

Regards,

  Neil

From ja.py at farowl.co.uk  Mon Nov 19 14:16:21 2018
From: ja.py at farowl.co.uk (Jeff Allen)
Date: Mon, 19 Nov 2018 19:16:21 +0000
Subject: [Python-Dev] Experiment an opt-in new C API for Python? (leave
 current API unchanged)
In-Reply-To: <CA+3bQGFzBcX25LO_Ert2XVckWB9MG-gMFF9pd2o=y-sc=Gqpuw@mail.gmail.com>
References: <20181119115933.GA4918@bytereef.org>
 <CA+3bQGFzBcX25LO_Ert2XVckWB9MG-gMFF9pd2o=y-sc=Gqpuw@mail.gmail.com>
Message-ID: <377de449-f028-fdb1-992c-7d96e8d1cea8@farowl.co.uk>

On 19/11/2018 15:08, Victor Stinner wrote:
> ...
> For me, the limited API should be functions available on all Python
> implementations. Does it make sense to provide PyFloat_Pack4() in
> ..., Jython, ... ? Or is it something more
> specific to CPython? I don't know the answer.
I'd say it's a CPython thing. It is helpful to copy a lot of things from 
the reference implementation, but generally the lexical conventions of 
the C-API would seem ludicrous in Java, where scope is already provided 
by a class. And then there's the impossibility of a C-like pointer to 
byte. Names related to C-API have mnemonic value, though, in 
translation. Maybe "static void PyFloat.pack4(double, ByteBuffer, 
boolean)" would do the trick.

It makes sense for JyNI to supply it by the exact C API name, and all 
other API that C extensions are likely to use.

Jeff Allen

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://mail.python.org/pipermail/python-dev/attachments/20181119/11561f7b/attachment.html>

From nas-python at arctrix.com  Mon Nov 19 17:03:19 2018
From: nas-python at arctrix.com (Neil Schemenauer)
Date: Mon, 19 Nov 2018 16:03:19 -0600
Subject: [Python-Dev] Experiment an opt-in new C API for Python? (leave
 current API unchanged)
In-Reply-To: <20181119104422.46d4bb29@fsol>
References: <CA+3bQGGcuo_-fdJwrisGP6+h6CuNzcErSoacaQySEb5h4nOQEQ@mail.gmail.com>
 <CAPJVwBmKHMMKypLDhjhkWHSE7HnHSh_irqaRfCug_+YL4jOtqw@mail.gmail.com>
 <CAGE7PNJeKGiVA5i8=Xrh6bRS7M=AURUPr8TjadQXEhCQuNwbWw@mail.gmail.com>
 <CAPJVwBnHefR1R84gC9Z2LzCZCd0VTV5ZR+m=+ri2spk6e2HZXA@mail.gmail.com>
 <CAGE7PNJWuZBYV0kRRO0n2yiRROkmtmFY7RKfDNsY0dTxY+dFww@mail.gmail.com>
 <CAP1=2W47ccNeZBsBjoRpz6XX_St1Qf0XVMPmZqAO1xJ+-53C=w@mail.gmail.com>
 <20181119104422.46d4bb29@fsol>
Message-ID: <20181119220319.nzbpaglcatwbj2uj@python.ca>

On 2018-11-19, Antoine Pitrou wrote:
> There are important use cases for the C API where it is desired to have
> fast type-specific access to Python objects such as tuples, ints,
> strings, etc.  This is relied upon by modules such as _json and _pickle,
> and third-party extensions as well.

Thank you for pointing this out.  The feedback from Stefan on what
Cython would like (e.g. more access to functions that are currently
"internal") is useful too.  Keeping our dreams tied to reality
is important. ;-P

It seems to me that we can't "have our cake and eat it too". I.e. on
the one hand hide CPython implementation internals but on the other
hand allow extensions that want to take advantage of those internals
to provide the best performance.

Maybe we could have a multiple levels of API:

A) maximum portability (Py_LIMITED_API)

B) source portability (non-stable ABI, inlined functions)

C) portability but poor performance on non-CPython VMs
   (PySequence_Fast_ITEMS, borrowed refs, etc)

D) non-portability, CPython specific (access to more internals like
   Stefan was asking for).  The extension would have to be
   re-implemented on each VM or provide a pure Python
   alternative.

I think it would be nice if the extension module could explicitly
choose which level of API it wants to use.

It would be interesting to do a census on what extensions are out
there.  If they mostly fall into wanting level "C" then I think this
API overhaul is not going to work out too well.  Level C is mostly
what we have now.  No point in putting the effort into A and B if no
one will use them.

From chris.barker at noaa.gov  Mon Nov 19 19:14:03 2018
From: chris.barker at noaa.gov (Chris Barker)
Date: Mon, 19 Nov 2018 16:14:03 -0800
Subject: [Python-Dev] Need discussion for a PR about memory and objects
In-Reply-To: <20181119103736.690ef0d7@fsol>
References: <20181104104350.GA12859@xps>
 <20181104130314.GU3817@ando.pearwood.info>
 <CADiSq7c4YZfaXZUWZ_J3z4d80MMxuoKcKUyCSaYU=awMN5C5WQ@mail.gmail.com>
 <20181119103736.690ef0d7@fsol>
Message-ID: <CALGmxE+y4gCrEXJZhh7RS_hAQpWhcdmmuKKK4LsWXapQrHoT1w@mail.gmail.com>

On Mon, Nov 19, 2018 at 1:41 AM Antoine Pitrou <solipsis at pitrou.net> wrote:

> I'd rather keep the reference to memory addressing than start doing car
> analogies in the reference documentation.
>

I agree -- and any of the car analogies will probably be only valid in some
jurisdictions, anyway.

I think being a bit more explicit about what properties an ID has, and how
the id() function works, and we may not need an anlogy at all, it's not
that difficult a concept. And methions that in c_python the id is
(currently) the memory address is a good idea for those that will wonder
about it, and if there is enough explanation, folks that don't know about
memory addresses will not get confused.

This is what's in the docs now (3.8.0a0):

"""
Every object has an identity, a type and a value. An object?s identity
never changes once it has been created; you may think of it as the object?s
address in memory. The ?is? operator compares the identity of two objects;
the id() function returns an integer representing its identity.

**CPython implementation detail:** For CPython, id(x) is the memory address
where x is stored.
"""

I suggest something like the following:

"""
Every object has an identity, a type and a value. An object?s identity
uniquely identifies the object. It will remain the same as long as that
object exists. No two different objects will have the same id at the same
time, but the same id may be re-used for future objects once one has been
deleted. The ?is? operator compares the identity of two objects; the id()
function returns an integer representing its identity. ``id(object_a) ==
id(object_b)`` if and only if they are the same object.

**CPython implementation detail:** For CPython, id(x) is the memory address
where x is stored.
"""

-CHB

-- 

Christopher Barker, Ph.D.
Oceanographer

Emergency Response Division
NOAA/NOS/OR&R            (206) 526-6959   voice
7600 Sand Point Way NE   (206) 526-6329   fax
Seattle, WA  98115       (206) 526-6317   main reception

Chris.Barker at noaa.gov
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://mail.python.org/pipermail/python-dev/attachments/20181119/8da6856d/attachment.html>

From v+python at g.nevcal.com  Mon Nov 19 19:39:31 2018
From: v+python at g.nevcal.com (Glenn Linderman)
Date: Mon, 19 Nov 2018 16:39:31 -0800
Subject: [Python-Dev] Need discussion for a PR about memory and objects
In-Reply-To: <CALGmxE+y4gCrEXJZhh7RS_hAQpWhcdmmuKKK4LsWXapQrHoT1w@mail.gmail.com>
References: <20181104104350.GA12859@xps>
 <20181104130314.GU3817@ando.pearwood.info>
 <CADiSq7c4YZfaXZUWZ_J3z4d80MMxuoKcKUyCSaYU=awMN5C5WQ@mail.gmail.com>
 <20181119103736.690ef0d7@fsol>
 <CALGmxE+y4gCrEXJZhh7RS_hAQpWhcdmmuKKK4LsWXapQrHoT1w@mail.gmail.com>
Message-ID: <3573cffd-ea04-3178-0cf3-f0353ce59fed@g.nevcal.com>

On 11/19/2018 4:14 PM, Chris Barker via Python-Dev wrote:
> On Mon, Nov 19, 2018 at 1:41 AM Antoine Pitrou <solipsis at pitrou.net 
> <mailto:solipsis at pitrou.net>> wrote:
>
>     I'd rather keep the reference to memory addressing than start
>     doing car
>     analogies in the reference documentation.
>
>
> I agree -- and any of the car analogies will probably be only valid in 
> some jurisdictions, anyway.
>
> I think being a bit more explicit about what properties an ID has, and 
> how the id() function works, and we may not need an anlogy at all, 
> it's not that difficult a concept. And methions that in c_python the 
> id is (currently) the memory address is a good idea for those that 
> will wonder about it, and if there is enough explanation, folks that 
> don't know about memory addresses will not get confused.
>
> This is what's in the docs now (3.8.0a0):
>
> """
> Every object has an identity, a type and a value. An object?s identity 
> never changes once it has been created; you may think of it as the 
> object?s address in memory. The ?is? operator compares the identity of 
> two objects; the id() function returns an integer representing its 
> identity.
>
> **CPython implementation detail:** For CPython, id(x) is the memory 
> address where x is stored.
> """
>
> I suggest something like the following:
>
> """
> Every object has an identity, a type and a value. An object?s identity 
> uniquely identifies the object. It will remain the same as long as 
> that object exists. No two different objects will have the same id at 
> the same time, but the same id may be re-used for future objects once 
> one has been deleted. The ?is? operator compares the identity of two 
> objects; the id() function returns an integer representing its 
> identity. ``id(object_a) == id(object_b)`` if and only if they are the 
> same object.
>
> **CPython implementation detail:** For CPython, id(x) is the memory 
> address where x is stored.
> """
>

Well re-worded in my opinion.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://mail.python.org/pipermail/python-dev/attachments/20181119/116ab55b/attachment.html>

From bcannon at gmail.com  Mon Nov 19 21:17:03 2018
From: bcannon at gmail.com (Brett Cannon)
Date: Mon, 19 Nov 2018 18:17:03 -0800
Subject: [Python-Dev] Experiment an opt-in new C API for Python? (leave
 current API unchanged)
In-Reply-To: <20181119220319.nzbpaglcatwbj2uj@python.ca>
References: <CA+3bQGGcuo_-fdJwrisGP6+h6CuNzcErSoacaQySEb5h4nOQEQ@mail.gmail.com>
 <CAPJVwBmKHMMKypLDhjhkWHSE7HnHSh_irqaRfCug_+YL4jOtqw@mail.gmail.com>
 <CAGE7PNJeKGiVA5i8=Xrh6bRS7M=AURUPr8TjadQXEhCQuNwbWw@mail.gmail.com>
 <CAPJVwBnHefR1R84gC9Z2LzCZCd0VTV5ZR+m=+ri2spk6e2HZXA@mail.gmail.com>
 <CAGE7PNJWuZBYV0kRRO0n2yiRROkmtmFY7RKfDNsY0dTxY+dFww@mail.gmail.com>
 <CAP1=2W47ccNeZBsBjoRpz6XX_St1Qf0XVMPmZqAO1xJ+-53C=w@mail.gmail.com>
 <20181119104422.46d4bb29@fsol> <20181119220319.nzbpaglcatwbj2uj@python.ca>
Message-ID: <CAP1=2W6XjtG91bOAgdE5sm_prGQA0J6rYY_9u0oULhpcZL8PiA@mail.gmail.com>

On Mon., Nov. 19, 2018, 14:04 Neil Schemenauer <nas-python at arctrix.com
wrote:

> On 2018-11-19, Antoine Pitrou wrote:
> > There are important use cases for the C API where it is desired to have
> > fast type-specific access to Python objects such as tuples, ints,
> > strings, etc.  This is relied upon by modules such as _json and _pickle,
> > and third-party extensions as well.
>
> Thank you for pointing this out.  The feedback from Stefan on what
> Cython would like (e.g. more access to functions that are currently
> "internal") is useful too.  Keeping our dreams tied to reality
> is important. ;-P
>
> It seems to me that we can't "have our cake and eat it too". I.e. on
> the one hand hide CPython implementation internals but on the other
> hand allow extensions that want to take advantage of those internals
> to provide the best performance.
>

No, but those are different APIs as well. E.g. no one is saying CPython has
to do away with any of its API. What I and some others have said is the
CPython API is too broad to be called "universal".


> Maybe we could have a multiple levels of API:
>
> A) maximum portability (Py_LIMITED_API)
>
> B) source portability (non-stable ABI, inlined functions)
>
> C) portability but poor performance on non-CPython VMs
>    (PySequence_Fast_ITEMS, borrowed refs, etc)
>

I don't know own how doable that is as e.g. borrowed refs are not pleasant
to simulate.


> D) non-portability, CPython specific (access to more internals like
>    Stefan was asking for).  The extension would have to be
>    re-implemented on each VM or provide a pure Python
>    alternative.


> I think it would be nice if the extension module could explicitly
> choose which level of API it wants to use.
>

Yes, and I thought we were working towards nesting our header files so you
very clearly opted into your level of compatibility.

In my head there's:
- bare minimum, cross-VM, gets you FFI
- CPython API for more performance that we're willing to maintain
- Everything open for e.g. CPython with no compatibility guarantees

Due note my first point isn't necessarily worrying about crazy performance
to start. I would assume an alternative VM would help make up for this with
a faster runtime where dropping into C is more about FFI than performance
(we all know PyPy, for instance, wished people just wrote more Python code).

Otherwise we're back to the idea of standardizing on some Cython solution
to help make perfect easier without tying oneself to the C API (like
Julia's FFI solution).


> It would be interesting to do a census on what extensions are out
> there.  If they mostly fall into wanting level "C" then I think this
> API overhaul is not going to work out too well.  Level C is mostly
> what we have now.  No point in putting the effort into A and B if no
> one will use them.


It won't until someone can show benefits for switching. This is very much a
chicken-and-egg problem.


_______________________________________________
> Python-Dev mailing list
> Python-Dev at python.org
> https://mail.python.org/mailman/listinfo/python-dev
> Unsubscribe:
> https://mail.python.org/mailman/options/python-dev/brett%40python.org
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://mail.python.org/pipermail/python-dev/attachments/20181119/556ccc4d/attachment.html>

From steve at pearwood.info  Mon Nov 19 22:07:27 2018
From: steve at pearwood.info (Steven D'Aprano)
Date: Tue, 20 Nov 2018 14:07:27 +1100
Subject: [Python-Dev] Need discussion for a PR about memory and objects
In-Reply-To: <CALGmxE+y4gCrEXJZhh7RS_hAQpWhcdmmuKKK4LsWXapQrHoT1w@mail.gmail.com>
References: <20181104104350.GA12859@xps>
 <20181104130314.GU3817@ando.pearwood.info>
 <CADiSq7c4YZfaXZUWZ_J3z4d80MMxuoKcKUyCSaYU=awMN5C5WQ@mail.gmail.com>
 <20181119103736.690ef0d7@fsol>
 <CALGmxE+y4gCrEXJZhh7RS_hAQpWhcdmmuKKK4LsWXapQrHoT1w@mail.gmail.com>
Message-ID: <20181120030725.GB5054@ando.pearwood.info>

Responding to a few points out of order.

On Mon, Nov 19, 2018 at 04:14:03PM -0800, Chris Barker via Python-Dev wrote:

> I think being a bit more explicit about what properties an ID has, and how
> the id() function works, and we may not need an anlogy at all, it's not
> that difficult a concept.
[...]

> I suggest something like the following:
> 
> """
> Every object has an identity, a type and a value. An object?s identity
> uniquely identifies the object. It will remain the same as long as that
> object exists. No two different objects will have the same id at the same
> time, but the same id may be re-used for future objects once one has been
> deleted. The ?is? operator compares the identity of two objects; the id()
> function returns an integer representing its identity. ``id(object_a) ==
> id(object_b)`` if and only if they are the same object.

That looks good to me. However...

> And methions that in c_python the id is
> (currently) the memory address is a good idea for those that will wonder
> about it, and if there is enough explanation, folks that don't know about
> memory addresses will not get confused.

I don't think that the problem is that people don't understand the 
"memory address as ID" implementation. I think the problem is people who 
can't separate the implementation from the interface. jThere is a small 
minority of developers, not just beginners, who insist that 
(paraphrasing) "the id() function returns the object's memory address", 
which leads others asking how to dereference the ID to get access to the 
object.

E.g. I recently saw somebody on Reddit asking how to delete an object 
given its address in Python.

I admit that this is just a minor point of confusion. We're not exactly 
innundated with dozens of requests for pointer arithmetic and PEEK/POKE 
commands *wink* but if we can reduce the confusion even further, that 
would be nice. We've had 20+ years of telling people that the C memory 
address of the object is an implementation detail, and some folks still 
don't get it.

I'd like to that we reduce the emphasis on memory address in the docs. 
Perhaps all the way to zero :-)

As you quoted, we currently we have a note in the docs that says:

  **CPython implementation detail:** For CPython, id(x) is the memory 
  address where x is stored.

I'd like to banish that note to the C-API docs (I'm not sure where), the 
FAQs (which apparently nobody ever reads *wink*) or perhaps just link to 
the source and let those who care read if for themselves.

Instead, I'd like a more comprehensive comment directly in the 
description of id, something like:

   There are no guarantees made for the ID number except as above.
   For example, Python implementations are known to take IDs from a 
   sequential series of integers (1, 2, 3, ...), or use arbitrary 
   implementation-defined values (263459012). Any such integer is
   permitted so long as the ID is constant and unique for the 
   lifespan of the object.



-- 
Steve

From ja.py at farowl.co.uk  Tue Nov 20 03:49:16 2018
From: ja.py at farowl.co.uk (Jeff Allen)
Date: Tue, 20 Nov 2018 08:49:16 +0000
Subject: [Python-Dev] Need discussion for a PR about memory and objects
In-Reply-To: <CALGmxE+y4gCrEXJZhh7RS_hAQpWhcdmmuKKK4LsWXapQrHoT1w@mail.gmail.com>
References: <20181104104350.GA12859@xps>
 <20181104130314.GU3817@ando.pearwood.info>
 <CADiSq7c4YZfaXZUWZ_J3z4d80MMxuoKcKUyCSaYU=awMN5C5WQ@mail.gmail.com>
 <20181119103736.690ef0d7@fsol>
 <CALGmxE+y4gCrEXJZhh7RS_hAQpWhcdmmuKKK4LsWXapQrHoT1w@mail.gmail.com>
Message-ID: <a9706642-47b2-4366-ebb7-7bba602c78e2@farowl.co.uk>

On 20/11/2018 00:14, Chris Barker via Python-Dev wrote:
> On Mon, Nov 19, 2018 at 1:41 AM Antoine Pitrou <solipsis at pitrou.net 
> <mailto:solipsis at pitrou.net>> wrote:
>
>     I'd rather keep the reference to memory addressing than start
>     doing car
>     analogies in the reference documentation.
>
>
> I agree -- and any of the car analogies will probably be only valid in 
> some jurisdictions, anyway.
>
> I think being a bit more explicit about what properties an ID has, and 
> how the id() function works, and we may not need an anlogy at all, 
> it's not that difficult a concept. And methions that in c_python the 
> id is (currently) the memory address is a good idea for those that 
> will wonder about it, and if there is enough explanation, folks that 
> don't know about memory addresses will not get confused.
...
> I suggest something like the following:
>
> """
> Every object has an identity, a type and a value. An object?s identity 
> uniquely identifies the object. It will remain the same as long as 
> that object exists. No two different objects will have the same id at 
> the same time, but the same id may be re-used for future objects once 
> one has been deleted. The ?is? operator compares the identity of two 
> objects; the id() function returns an integer representing its 
> identity. ``id(object_a) == id(object_b)`` if and only if they are the 
> same object.
>
> **CPython implementation detail:** For CPython, id(x) is the memory 
> address where x is stored.
> """
I agree that readers of a language reference should be able to manage 
without the analogies.

I want to suggest that identity and id() are different things.

The notion of identity in Python is what we access in phrases like "two 
different objects" and "the same object" in the text above. For me it 
defies definition, although one may make statements about it. A new 
object, wherever stored, is identically different from all objects 
preceding it.

Any Python has to implement the concept of identity in order to refer, 
without confusion, to objects in structures and bound by names. In 
practice, Python need only identify an object while the object exists in 
the interpreter, and the object exists as long as something refers to it 
in this way. To this extent, the identifier in the implementation need 
not be unique for all time.

The id() function returns an integer approximating this second idea. 
There is no mechanism to reach the object itself from the result, since 
it does not keep the object in existence, and worse, it may now be the 
id of a different object. In defining id(), I think it is confusing to 
imply that this number *is* the identity of the object that provided it.

Jeff Allen
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://mail.python.org/pipermail/python-dev/attachments/20181120/4b1b1b72/attachment.html>

From encukou at gmail.com  Tue Nov 20 04:32:37 2018
From: encukou at gmail.com (Petr Viktorin)
Date: Tue, 20 Nov 2018 10:32:37 +0100
Subject: [Python-Dev] Experiment an opt-in new C API for Python? (leave
 current API unchanged)
In-Reply-To: <CA+3bQGEoUDA_+_oK45oqSFxHTNDNJ8k9Ux-gSSP+hGZgx3WBGQ@mail.gmail.com>
References: <CA+3bQGGcuo_-fdJwrisGP6+h6CuNzcErSoacaQySEb5h4nOQEQ@mail.gmail.com>
 <CAPJVwBmKHMMKypLDhjhkWHSE7HnHSh_irqaRfCug_+YL4jOtqw@mail.gmail.com>
 <CAGE7PNJeKGiVA5i8=Xrh6bRS7M=AURUPr8TjadQXEhCQuNwbWw@mail.gmail.com>
 <CAPJVwBnHefR1R84gC9Z2LzCZCd0VTV5ZR+m=+ri2spk6e2HZXA@mail.gmail.com>
 <CAGE7PNJWuZBYV0kRRO0n2yiRROkmtmFY7RKfDNsY0dTxY+dFww@mail.gmail.com>
 <CAP1=2W47ccNeZBsBjoRpz6XX_St1Qf0XVMPmZqAO1xJ+-53C=w@mail.gmail.com>
 <20181119104422.46d4bb29@fsol>
 <CA+3bQGGJ93-UYZDH9ffe7ryQbBs4vTHa6sc_CGukFutsfef+uw@mail.gmail.com>
 <20181119115342.5a538507@fsol>
 <460193ad-6ae0-c54a-4335-8422268db84e@egenix.com>
 <CA+3bQGEoUDA_+_oK45oqSFxHTNDNJ8k9Ux-gSSP+hGZgx3WBGQ@mail.gmail.com>
Message-ID: <7bac006f-3682-4418-d979-404407ed5659@gmail.com>

On 11/19/18 12:14 PM, Victor Stinner wrote:
> To design a new C API, I see 3 options:
> 
> (1) add more functions to the existing Py_LIMITED_API
> (2) "fork" the current public C API: remove functions and hide as much
> implementation details as possible
> (3) write a new C API from scratch, based on the current C API.
> Something like #define newcapi_Object_GetItem PyObject_GetItem"?
> Sorry, but "#undef <private_function>" doesn't work. Only very few
> functions are defined using "#define ...".
> 
> I dislike (1) because it's too far from what is currently used in
> practice. Moreover, I failed to find anyone who can explain me how the
> C API is used in the wild, which functions are important or not, what
> is the C API, etc.

One big, complex project that now uses the limited API is PySide. They 
do some workarounds, but the limited API works. Here's a writeup of the 
troubles they have with it: 
https://github.com/pyside/pyside2-setup/blob/5.11/sources/shiboken2/libshiboken/pep384impl_doc.rst

> I propose (2). We control how much changes we do at each milestone,
> and we start from the maximum compatibility with current C API. Each
> change can be discussed and experimented to define what is the C API,
> what we want, etc. I'm working on this approach for 1 year, that's why
> many discussions popped up around specific changes :-)

I hope the new C API will be improvements (and clarifications) of the 
stable ABI, rather than a completely new thing.
My ideal would be that Python 4.0 would keep the same API (with 
questionable things emulated & deprecated), but break *ABI*. The "new C 
API" would become that new stable ABI -- and this time it'd be something 
we'd really want to support, without reservations.

One thing that did not work with the stable ABI was that it's "opt-out"; 
I think we can agree that a new one must be "opt-in" from the start.
I'd also like the "new API" to be a *strict subset* of the stable ABI: 
if a new function needs to be added, it should be added to both.

> Some people recently proposed (3) on python-dev. I dislike this option
> because it starts by breaking the backward compatibility. It looks
> like (1), but worse. The goal and the implementation are unclear to
> me.
> 
> --
> 
> Replacing PyDict_GetItem() (specialized call) with PyObject_Dict()
> (generic API) is not part of my short term plan. I wrote it in the
> roadmap, but as I wrote before, each change should be discusssed,
> experimented, benchmarked, etc.
> 
> Victor
> Le lun. 19 nov. 2018 ? 12:02, M.-A. Lemburg <mal at egenix.com> a ?crit :
>>
>> On 19.11.2018 11:53, Antoine Pitrou wrote:
>>> On Mon, 19 Nov 2018 11:28:46 +0100
>>> Victor Stinner <vstinner at redhat.com> wrote:
>>>> Python internals rely on internals to implement further optimizations,
>>>> than modifying an "immutable" tuple, bytes or str object, because you
>>>> can do that at the C level. But I'm not sure that I would like 3rd
>>>> party extensions to rely on such things.
>>>
>>> I'm not even talking about *modifying* tuples or str objects, I'm
>>> talking about *accessing* their value without going through an abstract
>>> API that does slot lookups, indirect function calls and object unboxing.
>>>
>>> For example, people may need a fast way to access the UTF-8
>>> representation of a unicode object.  Without making indirect function
>>> calls, and ideally without making a copy of the data either.  How do
>>> you do that using the generic C API?
>>
>> Something else you need to consider is creating instances of
>> types, e.g. a tuple. In C you will have to be able to put
>> values into the data structure before it is passed outside
>> the function in order to build the tuple.
>>
>> If you remove this possibility to have to copy data all the
>> time, losing the advantages of having a rich C API.
>>   --
>> Marc-Andre Lemburg
>> eGenix.com
>>
>> Professional Python Services directly from the Experts (#1, Nov 19 2018)
>>>>> Python Projects, Coaching and Consulting ...  http://www.egenix.com/
>>>>> Python Database Interfaces ...           http://products.egenix.com/
>>>>> Plone/Zope Database Interfaces ...           http://zope.egenix.com/
>> ________________________________________________________________________
>>
>> ::: We implement business ideas - efficiently in both time and costs :::
>>
>>     eGenix.com Software, Skills and Services GmbH  Pastor-Loeh-Str.48
>>      D-40764 Langenfeld, Germany. CEO Dipl.-Math. Marc-Andre Lemburg
>>             Registered at Amtsgericht Duesseldorf: HRB 46611
>>                 http://www.egenix.com/company/contact/
>>                        http://www.malemburg.com/
>>
>> _______________________________________________
>> Python-Dev mailing list
>> Python-Dev at python.org
>> https://mail.python.org/mailman/listinfo/python-dev
>> Unsubscribe: https://mail.python.org/mailman/options/python-dev/vstinner%40redhat.com
> _______________________________________________
> Python-Dev mailing list
> Python-Dev at python.org
> https://mail.python.org/mailman/listinfo/python-dev
> Unsubscribe: https://mail.python.org/mailman/options/python-dev/encukou%40gmail.com
> 

From njs at pobox.com  Tue Nov 20 06:12:59 2018
From: njs at pobox.com (Nathaniel Smith)
Date: Tue, 20 Nov 2018 03:12:59 -0800
Subject: [Python-Dev] Experiment an opt-in new C API for Python? (leave
 current API unchanged)
In-Reply-To: <7bac006f-3682-4418-d979-404407ed5659@gmail.com>
References: <CA+3bQGGcuo_-fdJwrisGP6+h6CuNzcErSoacaQySEb5h4nOQEQ@mail.gmail.com>
 <CAPJVwBmKHMMKypLDhjhkWHSE7HnHSh_irqaRfCug_+YL4jOtqw@mail.gmail.com>
 <CAGE7PNJeKGiVA5i8=Xrh6bRS7M=AURUPr8TjadQXEhCQuNwbWw@mail.gmail.com>
 <CAPJVwBnHefR1R84gC9Z2LzCZCd0VTV5ZR+m=+ri2spk6e2HZXA@mail.gmail.com>
 <CAGE7PNJWuZBYV0kRRO0n2yiRROkmtmFY7RKfDNsY0dTxY+dFww@mail.gmail.com>
 <CAP1=2W47ccNeZBsBjoRpz6XX_St1Qf0XVMPmZqAO1xJ+-53C=w@mail.gmail.com>
 <20181119104422.46d4bb29@fsol>
 <CA+3bQGGJ93-UYZDH9ffe7ryQbBs4vTHa6sc_CGukFutsfef+uw@mail.gmail.com>
 <20181119115342.5a538507@fsol>
 <460193ad-6ae0-c54a-4335-8422268db84e@egenix.com>
 <CA+3bQGEoUDA_+_oK45oqSFxHTNDNJ8k9Ux-gSSP+hGZgx3WBGQ@mail.gmail.com>
 <7bac006f-3682-4418-d979-404407ed5659@gmail.com>
Message-ID: <CAPJVwBnyksDLe58gvtVNd0g-Og8kY_VediJY8dO7Mf4GzsEE1g@mail.gmail.com>

On Tue, Nov 20, 2018 at 1:34 AM Petr Viktorin <encukou at gmail.com> wrote:
>
> On 11/19/18 12:14 PM, Victor Stinner wrote:
> > To design a new C API, I see 3 options:
> >
> > (1) add more functions to the existing Py_LIMITED_API
> > (2) "fork" the current public C API: remove functions and hide as much
> > implementation details as possible
> > (3) write a new C API from scratch, based on the current C API.
> > Something like #define newcapi_Object_GetItem PyObject_GetItem"?
> > Sorry, but "#undef <private_function>" doesn't work. Only very few
> > functions are defined using "#define ...".
> >
> > I dislike (1) because it's too far from what is currently used in
> > practice. Moreover, I failed to find anyone who can explain me how the
> > C API is used in the wild, which functions are important or not, what
> > is the C API, etc.
>
> One big, complex project that now uses the limited API is PySide. They
> do some workarounds, but the limited API works. Here's a writeup of the
> troubles they have with it:
> https://github.com/pyside/pyside2-setup/blob/5.11/sources/shiboken2/libshiboken/pep384impl_doc.rst

AFAIK the only two projects that use the limited API are
PySide-generated modules and cffi-generated modules. I guess if there
is some cleanup needed to remove stuff that snuck into the limited
API, then that will be fine as long as you make sure they aren't used
by either of those two projects.

For the regular C API, I guess the PyPy folks, and especially Matti
Picus, probably know more than anyone else about what parts are
actually used in the wild, since they've spent way more time digging
into real projects. (Do you want to know about the exact conditions in
which real projects rely on being able to skip calling PyType_Ready on
a statically allocated PyTypeObject? Matti knows...)

> I hope the new C API will be improvements (and clarifications) of the
> stable ABI, rather than a completely new thing.
> My ideal would be that Python 4.0 would keep the same API (with
> questionable things emulated & deprecated), but break *ABI*. The "new C
> API" would become that new stable ABI -- and this time it'd be something
> we'd really want to support, without reservations.

We already break ABI with every feature release ? at least for the
main ABI. The limited ABI supposedly doesn't, but probably does, and
as noted above it has such limited use that it's probably still
possible to fix any stuff that's leaked out accidentally.

-n

-- 
Nathaniel J. Smith -- https://vorpus.org

From bgerrity at ucdavis.edu  Tue Nov 20 04:11:54 2018
From: bgerrity at ucdavis.edu (Brendan Gerrity)
Date: Tue, 20 Nov 2018 04:11:54 -0500
Subject: [Python-Dev] bpo-34532 status
Message-ID: <CAP8YGJ16ukAW56fpNY2i35Jc7kKPsoqfF+ZAgehgVqwWWiL5qA@mail.gmail.com>

Just wanted to check on bpo-34532/pr#9039. The requested changes were
submitted as a commit to the PR.

Best,
Brendan
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://mail.python.org/pipermail/python-dev/attachments/20181120/e0e08b95/attachment.html>

From brett at python.org  Tue Nov 20 13:02:29 2018
From: brett at python.org (Brett Cannon)
Date: Tue, 20 Nov 2018 10:02:29 -0800
Subject: [Python-Dev] bpo-34532 status
In-Reply-To: <CAP8YGJ16ukAW56fpNY2i35Jc7kKPsoqfF+ZAgehgVqwWWiL5qA@mail.gmail.com>
References: <CAP8YGJ16ukAW56fpNY2i35Jc7kKPsoqfF+ZAgehgVqwWWiL5qA@mail.gmail.com>
Message-ID: <CAP1=2W7+ADxbQc0y9e1zUG3BY4Tsv-7n+c6tHLy4biwxNHZi7A@mail.gmail.com>

To provide context, https://bugs.python.org/issue34532 is about making the
Python launcher on Windows not return an error condition when using `py -0`
(and probably `py --list` and `py --list-paths`).

On Tue, 20 Nov 2018 at 08:29, Brendan Gerrity <bgerrity at ucdavis.edu> wrote:

> Just wanted to check on bpo-34532/pr#9039. The requested changes were
> submitted as a commit to the PR.
>
> Best,
> Brendan
>
> _______________________________________________
> Python-Dev mailing list
> Python-Dev at python.org
> https://mail.python.org/mailman/listinfo/python-dev
> Unsubscribe:
> https://mail.python.org/mailman/options/python-dev/brett%40python.org
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://mail.python.org/pipermail/python-dev/attachments/20181120/ad24c91b/attachment.html>

From steve.dower at python.org  Tue Nov 20 16:29:50 2018
From: steve.dower at python.org (Steve Dower)
Date: Tue, 20 Nov 2018 13:29:50 -0800
Subject: [Python-Dev] bpo-34532 status
In-Reply-To: <CAP1=2W7+ADxbQc0y9e1zUG3BY4Tsv-7n+c6tHLy4biwxNHZi7A@mail.gmail.com>
References: <CAP8YGJ16ukAW56fpNY2i35Jc7kKPsoqfF+ZAgehgVqwWWiL5qA@mail.gmail.com>
 <CAP1=2W7+ADxbQc0y9e1zUG3BY4Tsv-7n+c6tHLy4biwxNHZi7A@mail.gmail.com>
Message-ID: <e7bca92d-2507-a605-75e2-1b51b4b75ce5@python.org>

It's merged now. Sorry for not seeing the update (I get far too many 
github notifications/emails to be able to pay attention to them - 
pinging on the issue tracker generally works best).

Cheers,
Steve

On 20Nov2018 1002, Brett Cannon wrote:
> To provide context, https://bugs.python.org/issue34532 is about making 
> the Python launcher on Windows not return an error condition when using 
> `py -0` (and probably `py --list` and `py --list-paths`).
> 
> On Tue, 20 Nov 2018 at 08:29, Brendan Gerrity <bgerrity at ucdavis.edu 
> <mailto:bgerrity at ucdavis.edu>> wrote:
> 
>     Just wanted to check on?bpo-34532/pr#9039. The requested changes
>     were submitted as a commit to the PR.
> 
>     Best,
>     Brendan


From stefan at bytereef.org  Tue Nov 20 17:04:39 2018
From: stefan at bytereef.org (Stefan Krah)
Date: Tue, 20 Nov 2018 23:04:39 +0100
Subject: [Python-Dev] Experiment an opt-in new C API for Python? (leave
 current API unchanged)
In-Reply-To: <CA+3bQGFzBcX25LO_Ert2XVckWB9MG-gMFF9pd2o=y-sc=Gqpuw@mail.gmail.com>
References: <20181119115933.GA4918@bytereef.org>
 <CA+3bQGFzBcX25LO_Ert2XVckWB9MG-gMFF9pd2o=y-sc=Gqpuw@mail.gmail.com>
Message-ID: <20181120220439.GA2765@bytereef.org>


On Mon, Nov 19, 2018 at 04:08:07PM +0100, Victor Stinner wrote:
> Le lun. 19 nov. 2018 ? 13:18, Stefan Krah <stefan at bytereef.org> a ?crit :
> > In practice people desperately *have* to use whatever is there, including
> > functions with underscores that are not even officially in the C-API.
> >
> > I have to use _PyFloat_Pack* in order to be compatible with CPython,
> 
> Oh, I never used this function. These functions are private (name
> prefixed by "_") and excluded from the limited API.
> 
> For me, the limited API should be functions available on all Python
> implementations. Does it make sense to provide PyFloat_Pack4() in
> MicroPython, Jython, IronPython and PyPy? Or is it something more
> specific to CPython? I don't know the answer. If yes, open an issue to
> propose to make this function public?

It depends on what the goal is: If PyPy wants to be able to use as many
C extensions as possible, then yes.

The function is just one example of what people have to use to be 100%
compatible with CPython (or copy these functions and maintain them ...).


Intuitively, it should probably not be part of a limited API, but I never
quite understood the purpose of this API, because I regularly need any
function that I can get my hands on.


> > I need PyUnicode_KIND()
> 
> IMHO this one should not be part of the public API. The only usage
> would be to micro-optimize, but such API is very specific to one
> Python implementation. For example, PyPy doesn't use "compact string"
> but UTF-8 internally. If you use PyUnicode_KIND(), your code becomes
> incompatible with PyPy.
> 
> What is your use case?

Reading typed strings directly into an array with minimal overhead.


> I would prefer to expose the "_PyUnicodeWriter" API than PyUnicode_KIND().
> 
> > need PyUnicode_AsUTF8AndSize(),
> 
> Again, that's a micro-optimization and it's very specific to CPython:
> result cached in the "immutable" str object. I don't want to put it in
> a public API. PyUnicode_AsUTF8String() is better since it doesn't
> require an internal cache.
> 
> > I *wish* there were PyUnicode_AsAsciiAndSize().
> 
> PyUnicode_AsASCIIString() looks good to me. Sadly, it doesn't return
> the length, but usually the length is not needed.

Yes, these are all just examples.  It's also very useful to be able to
do PyLong_Type.tp_as_number->nb_multiply or grab as_integer_ratio from
the float PyMethodDef.

The latter two cases are for speed reasons but also because sometimes
you *don't* want a method from a subclass (Serhiy was very good in
finding corner cases :-).


Most C modules that I've seen have some internals. Psycopg2:

PyDateTime_DELTA_GET_MICROSECONDS
PyDateTime_DELTA_GET_DAYS
PyDateTime_DELTA_GET_SECONDS
PyList_GET_ITEM
Bytes_GET_SIZE
Py_BEGIN_ALLOW_THREADS
Py_END_ALLOW_THREADS

floatobject.h and longintrepr.h are also popular.


Stefan Krah




From vstinner at redhat.com  Tue Nov 20 17:17:05 2018
From: vstinner at redhat.com (Victor Stinner)
Date: Tue, 20 Nov 2018 23:17:05 +0100
Subject: [Python-Dev] Experiment an opt-in new C API for Python? (leave
 current API unchanged)
In-Reply-To: <20181120220439.GA2765@bytereef.org>
References: <20181119115933.GA4918@bytereef.org>
 <CA+3bQGFzBcX25LO_Ert2XVckWB9MG-gMFF9pd2o=y-sc=Gqpuw@mail.gmail.com>
 <20181120220439.GA2765@bytereef.org>
Message-ID: <CA+3bQGFeQ7WcZkGNEtgJVTm=kmytivs6FKh-UVV8hsrDX-Lx4A@mail.gmail.com>

Le mar. 20 nov. 2018 ? 23:08, Stefan Krah <stefan at bytereef.org> a ?crit :
> Intuitively, it should probably not be part of a limited API, but I never
> quite understood the purpose of this API, because I regularly need any
> function that I can get my hands on.
> (...)
> Reading typed strings directly into an array with minimal overhead.

IMHO performance and hiding implementation details are exclusive. You
should either use the C API with impl. details for best performances,
or use a "limited" C API for best compatibility.

Since I would like to not touch the C API with impl. details, you can
imagine to have two compilation modes: one for best performances on
CPython, one for best compatibility (ex: compatible with PyPy). I'm
not sure how the "compilation mode" will be selected.

Victor

From v+python at g.nevcal.com  Tue Nov 20 21:02:57 2018
From: v+python at g.nevcal.com (Glenn Linderman)
Date: Tue, 20 Nov 2018 18:02:57 -0800
Subject: [Python-Dev] Experiment an opt-in new C API for Python? (leave
 current API unchanged)
In-Reply-To: <CA+3bQGFeQ7WcZkGNEtgJVTm=kmytivs6FKh-UVV8hsrDX-Lx4A@mail.gmail.com>
References: <20181119115933.GA4918@bytereef.org>
 <CA+3bQGFzBcX25LO_Ert2XVckWB9MG-gMFF9pd2o=y-sc=Gqpuw@mail.gmail.com>
 <20181120220439.GA2765@bytereef.org>
 <CA+3bQGFeQ7WcZkGNEtgJVTm=kmytivs6FKh-UVV8hsrDX-Lx4A@mail.gmail.com>
Message-ID: <bcd37afd-0e4a-4d83-b17c-75efe81a5230@g.nevcal.com>

On 11/20/2018 2:17 PM, Victor Stinner wrote:
> Le mar. 20 nov. 2018 ? 23:08, Stefan Krah <stefan at bytereef.org> a ?crit :
>> Intuitively, it should probably not be part of a limited API, but I never
>> quite understood the purpose of this API, because I regularly need any
>> function that I can get my hands on.
>> (...)
>> Reading typed strings directly into an array with minimal overhead.
> IMHO performance and hiding implementation details are exclusive. You
> should either use the C API with impl. details for best performances,
> or use a "limited" C API for best compatibility.

The "limited" C API concept would seem to be quite sufficient for 
extensions that want to extend Python functionality to include new 
system calls, etc. (pywin32, pyMIDI, pySide, etc.) whereas the numpy and 
decimal might want best performance.

> Since I would like to not touch the C API with impl. details, you can
> imagine to have two compilation modes: one for best performances on
> CPython, one for best compatibility (ex: compatible with PyPy). I'm
> not sure how the "compilation mode" will be selected.

The nicest interface from a compilation point of view would be to have 
two #include files: One to import the limited API, and one to import the 
performance API. Importing both should be allowed and should work.

If you import the performance API, you have to learn more, and be more 
careful.

Of course, there might be appropriate subsets of each API, having 
multiple include files, to avoid including everything, but that is a 
refinement.

>
> Victor
> _______________________________________________
> Python-Dev mailing list
> Python-Dev at python.org
> https://mail.python.org/mailman/listinfo/python-dev
> Unsubscribe: https://mail.python.org/mailman/options/python-dev/v%2Bpython%40g.nevcal.com

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://mail.python.org/pipermail/python-dev/attachments/20181120/86fc64c2/attachment.html>

From njs at pobox.com  Wed Nov 21 01:33:27 2018
From: njs at pobox.com (Nathaniel Smith)
Date: Tue, 20 Nov 2018 22:33:27 -0800
Subject: [Python-Dev] Experiment an opt-in new C API for Python? (leave
 current API unchanged)
In-Reply-To: <bcd37afd-0e4a-4d83-b17c-75efe81a5230@g.nevcal.com>
References: <20181119115933.GA4918@bytereef.org>
 <CA+3bQGFzBcX25LO_Ert2XVckWB9MG-gMFF9pd2o=y-sc=Gqpuw@mail.gmail.com>
 <20181120220439.GA2765@bytereef.org>
 <CA+3bQGFeQ7WcZkGNEtgJVTm=kmytivs6FKh-UVV8hsrDX-Lx4A@mail.gmail.com>
 <bcd37afd-0e4a-4d83-b17c-75efe81a5230@g.nevcal.com>
Message-ID: <CAPJVwB=1F6Oh=QgDPXXhgOz6YiGxYh9WS4Ojp5UuSY5Kc7_YZg@mail.gmail.com>

On Tue, Nov 20, 2018 at 6:05 PM Glenn Linderman <v+python at g.nevcal.com> wrote:
>
> On 11/20/2018 2:17 PM, Victor Stinner wrote:
>> IMHO performance and hiding implementation details are exclusive. You
>> should either use the C API with impl. details for best performances,
>> or use a "limited" C API for best compatibility.
>
> The "limited" C API concept would seem to be quite sufficient for extensions that want to extend Python functionality to include new system calls, etc. (pywin32, pyMIDI, pySide, etc.) whereas the numpy and decimal might want best performance.

To make things more complicated: numpy and decimal are in a category
of modules where if you want them to perform well on JIT-based VMs,
then there's no possible C API that can achieve that. To get the
benefits of a JIT on code using numpy or decimal, the JIT has to be
able to see into their internals to do inlining etc., which means they
can't be written in C at all [1], at which point the C API becomes
irrelevant.

It's not clear to me how this affects any of the discussion in
CPython, since supporting JITs might not be part of the goal of a new
C API, and I'm not sure how many packages fall between the
numpy/decimal side and the pure-ffi side.

-n

[1] Well, there's also the option of teaching your Python JIT to
handle LLVM bitcode as a source language, which is the approach that
Graal is experimenting with. It seems completely wacky to me to hope
you could write a C API emulation layer like PyPy's cpyext, and
compile that + C extension code to LLVM bitcode, translate the LLVM
bitcode to JVM bytecode, inline the whole mess into your Python JIT,
and then fold everything away to produce something reasonable. But I
could be wrong, and Oracle is throwing a lot of money at Graal so I
guess we'll find out.

-- 
Nathaniel J. Smith -- https://vorpus.org

From v+python at g.nevcal.com  Wed Nov 21 02:28:44 2018
From: v+python at g.nevcal.com (Glenn Linderman)
Date: Tue, 20 Nov 2018 23:28:44 -0800
Subject: [Python-Dev] Experiment an opt-in new C API for Python? (leave
 current API unchanged)
In-Reply-To: <CAPJVwB=1F6Oh=QgDPXXhgOz6YiGxYh9WS4Ojp5UuSY5Kc7_YZg@mail.gmail.com>
References: <20181119115933.GA4918@bytereef.org>
 <CA+3bQGFzBcX25LO_Ert2XVckWB9MG-gMFF9pd2o=y-sc=Gqpuw@mail.gmail.com>
 <20181120220439.GA2765@bytereef.org>
 <CA+3bQGFeQ7WcZkGNEtgJVTm=kmytivs6FKh-UVV8hsrDX-Lx4A@mail.gmail.com>
 <bcd37afd-0e4a-4d83-b17c-75efe81a5230@g.nevcal.com>
 <CAPJVwB=1F6Oh=QgDPXXhgOz6YiGxYh9WS4Ojp5UuSY5Kc7_YZg@mail.gmail.com>
Message-ID: <0f594899-192c-a6cc-7f91-ddd2772b6187@g.nevcal.com>

On 11/20/2018 10:33 PM, Nathaniel Smith wrote:
> On Tue, Nov 20, 2018 at 6:05 PM Glenn Linderman <v+python at g.nevcal.com> wrote:
>> On 11/20/2018 2:17 PM, Victor Stinner wrote:
>>> IMHO performance and hiding implementation details are exclusive. You
>>> should either use the C API with impl. details for best performances,
>>> or use a "limited" C API for best compatibility.
>> The "limited" C API concept would seem to be quite sufficient for extensions that want to extend Python functionality to include new system calls, etc. (pywin32, pyMIDI, pySide, etc.) whereas the numpy and decimal might want best performance.
> To make things more complicated: numpy and decimal are in a category
> of modules where if you want them to perform well on JIT-based VMs,
> then there's no possible C API that can achieve that. To get the
> benefits of a JIT on code using numpy or decimal, the JIT has to be
> able to see into their internals to do inlining etc., which means they
> can't be written in C at all [1], at which point the C API becomes
> irrelevant.
>
> It's not clear to me how this affects any of the discussion in
> CPython, since supporting JITs might not be part of the goal of a new
> C API, and I'm not sure how many packages fall between the
> numpy/decimal side and the pure-ffi side.
>
> -n
>
> [1] Well, there's also the option of teaching your Python JIT to
> handle LLVM bitcode as a source language, which is the approach that
> Graal is experimenting with. It seems completely wacky to me to hope
> you could write a C API emulation layer like PyPy's cpyext, and
> compile that + C extension code to LLVM bitcode, translate the LLVM
> bitcode to JVM bytecode, inline the whole mess into your Python JIT,
> and then fold everything away to produce something reasonable. But I
> could be wrong, and Oracle is throwing a lot of money at Graal so I
> guess we'll find out.
>
Interesting, thanks for the introduction to wacky. I was quite content 
with the idea that numpy, and other modules that would choose to use the 
unlimited API, would be sacrificing portability to non-CPython 
implementations... except by providing a Python equivalent (decimal, and 
some others do that, IIRC).

Regarding JIT in general, though, it would seem that "precompiled" 
extensions like numpy would not need to be re-compiled by the JIT.

But if it does, then the JIT better understand/support C syntax, but JVM 
JITs probably don't! so that leads to the scenario you describe.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://mail.python.org/pipermail/python-dev/attachments/20181120/f154403e/attachment.html>

